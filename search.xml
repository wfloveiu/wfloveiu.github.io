<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>vLLM中的Executor与Worker</title>
      <link href="/2024/07/31/vLLM%E4%B8%AD%E7%9A%84Executor%E4%B8%8EWorker/"/>
      <url>/2024/07/31/vLLM%E4%B8%AD%E7%9A%84Executor%E4%B8%8EWorker/</url>
      
        <content type="html"><![CDATA[<h1 id="vLLM中的Executor与Worker"><a href="#vLLM中的Executor与Worker" class="headerlink" title="vLLM中的Executor与Worker"></a>vLLM中的Executor与Worker</h1><p>在<code>executor</code>文件夹下定义不同类型的执行器，如NeuronExecutor、CPUExecutor、RayGPUExecutor、GPUExecutor</p><p>在<code>class LLMEngine</code>的<code>from_engine_args()</code>中确定使用的执行器类名称。其中，<code>parallel_config.world_size=pipeline_parallel_size*self.tensor_parallel_size</code>,即当存在PP并行或者TP并行时<code>world_size</code>就大于1，就需要使用RayGPUExecutor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize the cluster and specify the executor class.</span></span><br><span class="line"><span class="keyword">if</span> engine_config.device_config.device_type == <span class="string">&quot;neuron&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> vllm.executor.neuron_executor <span class="keyword">import</span> NeuronExecutor</span><br><span class="line">    executor_class = NeuronExecutor</span><br><span class="line"><span class="keyword">elif</span> engine_config.device_config.device_type == <span class="string">&quot;cpu&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> vllm.executor.cpu_executor <span class="keyword">import</span> CPUExecutor</span><br><span class="line">    executor_class = CPUExecutor</span><br><span class="line"><span class="keyword">elif</span> engine_config.parallel_config.worker_use_ray:</span><br><span class="line">    initialize_ray_cluster(engine_config.parallel_config)</span><br><span class="line">    <span class="keyword">from</span> vllm.executor.ray_gpu_executor <span class="keyword">import</span> RayGPUExecutor</span><br><span class="line">    executor_class = RayGPUExecutor</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">assert</span> engine_config.parallel_config.world_size == <span class="number">1</span>, (</span><br><span class="line">        <span class="string">&quot;Ray is required if parallel_config.world_size &gt; 1.&quot;</span>)</span><br><span class="line">    <span class="keyword">from</span> vllm.executor.gpu_executor <span class="keyword">import</span> GPUExecutor</span><br><span class="line">    executor_class = GPUExecutor</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>之后通过<code>engine = cls()</code>方式创建engine，在init()中创建model_executor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.model_executor = executor_class(</span><br><span class="line">            model_config=model_config,</span><br><span class="line">            cache_config=cache_config,</span><br><span class="line">            parallel_config=parallel_config,</span><br><span class="line">            scheduler_config=scheduler_config,</span><br><span class="line">            device_config=device_config,</span><br><span class="line">            lora_config=lora_config,</span><br><span class="line">            vision_language_config=vision_language_config,</span><br><span class="line">            speculative_config=speculative_config,</span><br><span class="line">            load_config=load_config,</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>接下来针对于常用的GPUExector和RayGPUExecutor来学习</p><h2 id="ExecutorBase"><a href="#ExecutorBase" class="headerlink" title="ExecutorBase"></a>ExecutorBase</h2><p>基类中给出了执行器的定义：将模型在特定的硬件设备上执行，如CPU, GPU, Neuron或者是多设备</p><p>着重关注<code>_init_executor</code>、<code>determine_num_available_blocks</code>、<code>initialize_cache</code>、<code>execute_model</code>的实现</p><h2 id="GPUExecutor"><a href="#GPUExecutor" class="headerlink" title="GPUExecutor"></a>GPUExecutor</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_executor</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the worker and load the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If speculative decoding is enabled, we instead create the speculative</span></span><br><span class="line"><span class="string">    worker.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> self.speculative_config <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        self._init_non_spec_worker()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self._init_spec_worker()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_init_non_spec_worker</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">assert</span> self.parallel_config.world_size == <span class="number">1</span>, (</span><br><span class="line">        <span class="string">&quot;GPUExecutor only supports single GPU.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    self.driver_worker = self._create_worker()</span><br><span class="line">    self.driver_worker.init_device()</span><br><span class="line">    self.driver_worker.load_model()            </span><br></pre></td></tr></table></figure><p>通常情况下是创建非特殊的worker。首先实例化driver_worker，然后初始化设备和加载模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_create_worker</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                   local_rank: <span class="built_in">int</span> = <span class="number">0</span>,</span></span><br><span class="line"><span class="params">                   rank: <span class="built_in">int</span> = <span class="number">0</span>,</span></span><br><span class="line"><span class="params">                   distributed_init_method: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    wrapper = WorkerWrapperBase(</span><br><span class="line">        worker_module_name=<span class="string">&quot;vllm.worker.worker&quot;</span>,</span><br><span class="line">        worker_class_name=<span class="string">&quot;Worker&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    wrapper.init_worker(**self._get_worker_kwargs(local_rank, rank,</span><br><span class="line">                                                  distributed_init_method))</span><br><span class="line">    <span class="keyword">return</span> wrapper.worker</span><br></pre></td></tr></table></figure><p>对于单GPU的情况，其rank就是0，同理distributed_init_method也是None。 worker_class_name&#x3D;”Worker”指定类名。wrapper.init_worker是对wrapper中worker的初始化，其实例化worker为worker_class_name指定的类对象。</p><p>至于为什么要搞一个WorkerWrapperBase类包裹worker，vllm给的注释中说是为了<strong>懒惰地初始化</strong>……</p><p>由于Worker类属于另一个重要结构，后续介绍。</p><p>GPUExecutor类对、<code>determine_num_available_blocks</code>、<code>initialize_cache</code>、<code>execute_model</code>的实现也是调用driver_worker中对应函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">determine_num_available_blocks</span>(<span class="params">self</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Determine the number of available KV blocks by invoking the</span></span><br><span class="line"><span class="string">    underlying worker.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> self.driver_worker.determine_num_available_blocks()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_cache</span>(<span class="params">self, num_gpu_blocks: <span class="built_in">int</span>, num_cpu_blocks</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the KV cache by invoking the underlying worker.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># <span class="doctag">NOTE:</span> This is logged in the executor because there can be &gt;1 worker</span></span><br><span class="line">    <span class="comment"># with other executors. We could log in the engine level, but work</span></span><br><span class="line">    <span class="comment"># remains to abstract away the device for non-GPU configurations.</span></span><br><span class="line">    logger.info(<span class="string">&quot;# GPU blocks: %d, # CPU blocks: %d&quot;</span>, num_gpu_blocks,</span><br><span class="line">                num_cpu_blocks)</span><br><span class="line"></span><br><span class="line">    self.driver_worker.initialize_cache(num_gpu_blocks, num_cpu_blocks)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">execute_model</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        execute_model_req: ExecuteModelRequest</span>) -&gt; <span class="type">List</span>[SamplerOutput]:</span><br><span class="line">    output = self.driver_worker.execute_model(execute_model_req)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="RayGPUExecutor"><a href="#RayGPUExecutor" class="headerlink" title="RayGPUExecutor"></a>RayGPUExecutor</h2><p>通常单卡无法做推理任务，此时就要使用并行方式。VLLM使用Ray来做分布式计算</p><blockquote><p>Ray 是一个开源的统一框架，用于扩展机器学习等人工智能和 Python 应用程序。它为并行处理提供了计算层</p></blockquote><p><strong>首先，在<code>from_engine_args()</code>调用<code>initialize_ray_cluster</code></strong></p><p>27行的ray.init做对ray引擎的初始化，并默认将dashboard运行在8265端口。在placement_group不存在时，直接跳转else。num_gpus_in_cluster是当前集群中可用的GPU数，它不能少于world_size所需。</p><p>58、59创建<strong>placement group</strong>，每一个bundle包含一个GPU</p><blockquote><p>A <strong>placement group</strong> reserves the resources from the cluster. 从集群中预定资源</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_ray_cluster</span>(<span class="params"></span></span><br><span class="line"><span class="params">    parallel_config: ParallelConfig,</span></span><br><span class="line"><span class="params">    ray_address: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the distributed cluster with Ray.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    it will connect to the Ray cluster and create a placement group</span></span><br><span class="line"><span class="string">    for the workers, which includes the specification of the resources</span></span><br><span class="line"><span class="string">    for each distributed worker.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        parallel_config: The configurations for parallel execution.</span></span><br><span class="line"><span class="string">        ray_address: The address of the Ray cluster. If None, uses</span></span><br><span class="line"><span class="string">            the default Ray cluster address.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> ray <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> ImportError(</span><br><span class="line">            <span class="string">&quot;Ray is not installed. Please install Ray to use distributed &quot;</span></span><br><span class="line">            <span class="string">&quot;serving.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Connect to a ray cluster. 初始化Ray引擎</span></span><br><span class="line">    <span class="keyword">if</span> is_hip(): <span class="comment">#针对于AMD显卡</span></span><br><span class="line">        ray.init(address=ray_address,</span><br><span class="line">                 ignore_reinit_error=<span class="literal">True</span>,</span><br><span class="line">                 num_gpus=parallel_config.world_size)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ray.init(address=ray_address, ignore_reinit_error=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> parallel_config.placement_group:</span><br><span class="line">        <span class="comment"># Placement group is already set.</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create placement group for worker processes</span></span><br><span class="line">    current_placement_group = ray.util.get_current_placement_group()</span><br><span class="line">    <span class="keyword">if</span> current_placement_group:</span><br><span class="line">        <span class="comment"># We are in a placement group</span></span><br><span class="line">        bundles = current_placement_group.bundle_specs</span><br><span class="line">        <span class="comment"># Verify that we can use the placement group.</span></span><br><span class="line">        gpu_bundles = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> bundle <span class="keyword">in</span> bundles:</span><br><span class="line">            bundle_gpus = bundle.get(<span class="string">&quot;GPU&quot;</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> bundle_gpus &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(</span><br><span class="line">                    <span class="string">&quot;Placement group bundle cannot have more than 1 GPU.&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> bundle_gpus:</span><br><span class="line">                gpu_bundles += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> parallel_config.world_size &gt; gpu_bundles:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;The number of required GPUs exceeds the total number of &quot;</span></span><br><span class="line">                <span class="string">&quot;available GPUs in the placement group.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_gpus_in_cluster = ray.cluster_resources().get(<span class="string">&quot;GPU&quot;</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> parallel_config.world_size &gt; num_gpus_in_cluster:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;The number of required GPUs exceeds the total number of &quot;</span></span><br><span class="line">                <span class="string">&quot;available GPUs in the cluster.&quot;</span>)</span><br><span class="line">        <span class="comment"># Create a new placement group</span></span><br><span class="line">        placement_group_specs = ([&#123;<span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125;] * parallel_config.world_size)</span><br><span class="line">        current_placement_group = ray.util.placement_group(</span><br><span class="line">            placement_group_specs)</span><br><span class="line">        <span class="comment"># Wait until PG is ready - this will block until all</span></span><br><span class="line">        <span class="comment"># requested resources are available, and will timeout</span></span><br><span class="line">        <span class="comment"># if they cannot be provisioned.</span></span><br><span class="line">        ray.get(current_placement_group.ready(), timeout=<span class="number">1800</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set the placement group in the parallel config</span></span><br><span class="line">    parallel_config.placement_group = current_placement_group</span><br></pre></td></tr></table></figure><p>接着就是在实例化RayGPUExecutor对象，它继承了DistributedGPUExecutor，DistributedGPUExecutor又继承了GPUExecutor。</p><p>在17行创建并行的GPUworker</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_executor</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">assert</span> (<span class="keyword">not</span> self.speculative_config</span><br><span class="line">            ), <span class="string">&quot;Speculative decoding not yet supported for RayGPU backend.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> self.parallel_config.worker_use_ray</span><br><span class="line">    placement_group = self.parallel_config.placement_group</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Disable Ray usage stats collection.</span></span><br><span class="line">    ray_usage = os.environ.get(<span class="string">&quot;RAY_USAGE_STATS_ENABLED&quot;</span>, <span class="string">&quot;0&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> ray_usage != <span class="string">&quot;1&quot;</span>:</span><br><span class="line">        os.environ[<span class="string">&quot;RAY_USAGE_STATS_ENABLED&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the parallel GPU workers.</span></span><br><span class="line">    self._init_workers_ray(placement_group)</span><br><span class="line"></span><br><span class="line">    self.forward_dag = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> USE_RAY_COMPILED_DAG:</span><br><span class="line">        self.forward_dag = self._compiled_ray_dag()</span><br></pre></td></tr></table></figure><p>在第6行的循环中，对placement_group中每个bundle，使用<code>PlacementGroupSchedulingStrategy</code>生成资源调度策略；<code>ray.remote</code>传入资源调度策略，生成远程对象，<code>(RayWorkerWrapper).remote</code>实例化远程对象(并未真正初始化)</p><p>25行获取work所在node的IP地址，与运行服务的主机IP对比，目的是设置一个driverwork。</p><p>这里需要强调两点，</p><p>一，self.workers和self.driver_dummy_worker都是RayWorkerWrapper，它继承自WorkerWrapperBase，wrapper意为包装器，正如注释所述，设置这样一个包裹在worker类之外的类是为了延迟初始化worker。因此需要区分初始化包装器和初始化包装器中真正worker。</p><p>二，在设置driver时，driver_dummy_worker被直接赋值为remote类型的worker(不过因为IP和主节点IP一致，其实还是本地worker)，而driver_worker被设置成普通的RayWorkerWrapper，<strong>个人理解是：driver_worker被设置成普通的RayWorkerWrapper，其使用的GPU资源是本地node的；remote worker使用的资源也还是在本地node，因此二者没有实质上区别</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">def</span> <span class="title function_">_init_workers_ray</span>(<span class="params">self, placement_group: <span class="string">&quot;PlacementGroup&quot;</span>,</span></span><br><span class="line"><span class="params">                        **ray_remote_kwargs</span>):</span><br><span class="line">   ......</span><br><span class="line">      self.driver_dummy_worker: <span class="type">Optional</span>[RayWorkerWrapper] = <span class="literal">None</span></span><br><span class="line">      <span class="comment"># The remaining workers are the actual ray actors.</span></span><br><span class="line">      self.workers: <span class="type">List</span>[RayWorkerWrapper] = []</span><br><span class="line">      <span class="comment"># Create the workers.</span></span><br><span class="line">      driver_ip = get_ip()</span><br><span class="line">      <span class="keyword">for</span> bundle_id, bundle <span class="keyword">in</span> <span class="built_in">enumerate</span>(placement_group.bundle_specs):</span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> bundle.get(<span class="string">&quot;GPU&quot;</span>, <span class="number">0</span>):</span><br><span class="line">              <span class="keyword">continue</span></span><br><span class="line">          scheduling_strategy = PlacementGroupSchedulingStrategy(</span><br><span class="line">              placement_group=placement_group,</span><br><span class="line">              placement_group_capture_child_tasks=<span class="literal">True</span>,</span><br><span class="line">              placement_group_bundle_index=bundle_id,</span><br><span class="line">          )</span><br><span class="line">          worker = ray.remote(</span><br><span class="line">              num_cpus=<span class="number">0</span>,</span><br><span class="line">              num_gpus=num_gpus,</span><br><span class="line">              scheduling_strategy=scheduling_strategy,</span><br><span class="line">              **ray_remote_kwargs,</span><br><span class="line">          )(RayWorkerWrapper).remote(</span><br><span class="line">              worker_module_name=<span class="string">&quot;vllm.worker.worker&quot;</span>,</span><br><span class="line">              worker_class_name=<span class="string">&quot;Worker&quot;</span>,</span><br><span class="line">              trust_remote_code=self.model_config.trust_remote_code,</span><br><span class="line">          )</span><br><span class="line"></span><br><span class="line">          worker_ip = ray.get(worker.get_node_ip.remote())</span><br><span class="line">          <span class="keyword">if</span> worker_ip == driver_ip <span class="keyword">and</span> self.driver_dummy_worker <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">              <span class="comment"># If the worker is on the same node as the driver, we use it</span></span><br><span class="line">              <span class="comment"># as the resource holder for the driver process.</span></span><br><span class="line">              self.driver_dummy_worker = worker</span><br><span class="line">              self.driver_worker = RayWorkerWrapper(</span><br><span class="line">                  worker_module_name=<span class="string">&quot;vllm.worker.worker&quot;</span>,</span><br><span class="line">                  worker_class_name=<span class="string">&quot;Worker&quot;</span>,</span><br><span class="line">                  trust_remote_code=self.model_config.trust_remote_code,</span><br><span class="line">              )</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              <span class="comment"># Else, added to the list of workers.</span></span><br><span class="line">              self.workers.append(worker)</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># Get the set of GPU IDs used on each node.</span></span><br><span class="line">      worker_node_and_gpu_ids = self._run_workers(<span class="string">&quot;get_node_and_gpu_ids&quot;</span>,</span><br><span class="line">                                                  use_dummy_driver=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      node_workers = defaultdict(<span class="built_in">list</span>) <span class="comment"># key:node节点 value:运行在该节点上的worker索引</span></span><br><span class="line">      node_gpus = defaultdict(<span class="built_in">list</span>) <span class="comment"># key:node节点 value:该节点中被使用的GPU编号</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i, (node_id, gpu_ids) <span class="keyword">in</span> <span class="built_in">enumerate</span>(worker_node_and_gpu_ids):</span><br><span class="line">          node_workers[node_id].append(i)</span><br><span class="line">          node_gpus[node_id].extend(gpu_ids)</span><br><span class="line">      <span class="keyword">for</span> node_id, gpu_ids <span class="keyword">in</span> node_gpus.items():</span><br><span class="line">          node_gpus[node_id] = <span class="built_in">sorted</span>(gpu_ids)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">      <span class="comment"># Initialize the actual workers inside worker wrapper.</span></span><br><span class="line">      init_worker_all_kwargs = [</span><br><span class="line">          self._get_worker_kwargs(</span><br><span class="line">              local_rank=node_workers[node_id].index(rank), <span class="comment">#获取当前 rank 在 node_workers[node_id] 列表中的索引，表示该 Worker 在本地节点的排名</span></span><br><span class="line">              rank=rank, <span class="comment">#全局排名，即 Worker 在整个集群中的索引。</span></span><br><span class="line">              distributed_init_method=distributed_init_method,</span><br><span class="line">          ) <span class="keyword">for</span> rank, (node_id, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(worker_node_and_gpu_ids)</span><br><span class="line">      ]</span><br><span class="line">      self._run_workers(<span class="string">&quot;init_worker&quot;</span>, all_kwargs=init_worker_all_kwargs)</span><br><span class="line"></span><br><span class="line">      self._run_workers(<span class="string">&quot;init_device&quot;</span>)</span><br><span class="line">      self._run_workers(<span class="string">&quot;load_model&quot;</span>,</span><br><span class="line">                        max_concurrent_workers=self.parallel_config.</span><br><span class="line">                        max_parallel_loading_workers)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后三行调用统一的执行函数的接口，传入要执行的函数名：init_worker、init_device、load_model。在_run_workers中，会先在ray workers中启动要执行的函数，然后在driver worker中执行函数，最后合并输出</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以理解为三层，上层是Executor层，中层是Wrapper层，下层是Worker层。而对于init_device、load_model等具体的模型操作都是在Worker中控制</p><h1 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h1><p>在上一部分中，我们按调用关系分析了两个我认为常用的Executor：GPUExecutor和RayGPUExecutor。他们对于模型的具体执行和调度是通过Worker类实现的。本节我们接着来分析Worker类。</p><p>在Executor的init中，对于Worker的操作包括：init_worker、init_device、load_model。</p><ul><li>init_worker先实例化了一个ModelRunner的对象；接着Uninitialized cache engine，cache engine与KV cache管理相关；并维护gpu_cache管理KV cache的存储</li><li>init_device没有需要关注的点</li><li>load_model调用了model_runner.load_model()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    model_config: ModelConfig,</span></span><br><span class="line"><span class="params">    parallel_config: ParallelConfig,</span></span><br><span class="line"><span class="params">    scheduler_config: SchedulerConfig,</span></span><br><span class="line"><span class="params">    device_config: DeviceConfig,</span></span><br><span class="line"><span class="params">    cache_config: CacheConfig,</span></span><br><span class="line"><span class="params">    load_config: LoadConfig,</span></span><br><span class="line"><span class="params">    local_rank: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    rank: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    distributed_init_method: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">    lora_config: <span class="type">Optional</span>[LoRAConfig] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    vision_language_config: <span class="type">Optional</span>[VisionLanguageConfig] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    is_driver_worker: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   ......</span><br><span class="line">    self.model_runner = ModelRunner(</span><br><span class="line">        model_config,</span><br><span class="line">        parallel_config,</span><br><span class="line">        scheduler_config,</span><br><span class="line">        device_config,</span><br><span class="line">        load_config=load_config,</span><br><span class="line">        lora_config=self.lora_config,</span><br><span class="line">        kv_cache_dtype=self.cache_config.cache_dtype,</span><br><span class="line">        is_driver_worker=is_driver_worker,</span><br><span class="line">        vision_language_config=vision_language_config,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># Uninitialized cache engine. Will be initialized by</span></span><br><span class="line">    <span class="comment"># initialize_cache.</span></span><br><span class="line">    self.cache_engine: CacheEngine</span><br><span class="line">    self.gpu_cache: <span class="type">List</span>[torch.Tensor]</span><br></pre></td></tr></table></figure><p>对于world_size&#x3D;1即使用1个GPU推理时，load_model没有值得注意的点。但是我比较好奇对于多卡的TP情况下，模型参数是如何均匀分配到不同的GPU中。这部分的代码在model_loader文件夹，<strong>看不太懂，先挖个坑吧</strong></p><p>下一节来分析KV相关的初始化，代码起始于class LLMEngine-&gt;init()-&gt;self._initialize_kv_caches()</p>]]></content>
      
      
      <categories>
          
          <category> vLLM源码阅读 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cmu 10-414 HW2</title>
      <link href="/2024/07/27/cmu%2010-414%20HW2/"/>
      <url>/2024/07/27/cmu%2010-414%20HW2/</url>
      
        <content type="html"><![CDATA[<h1 id="cmu-10-414-HW2"><a href="#cmu-10-414-HW2" class="headerlink" title="cmu 10-414 HW2"></a>cmu 10-414 HW2</h1><h2 id="Question-2"><a href="#Question-2" class="headerlink" title="Question 2"></a>Question 2</h2><h3 id="Xavier-uniform"><a href="#Xavier-uniform" class="headerlink" title="Xavier uniform"></a>Xavier uniform</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 均匀分布 U(-a, a)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xavier_uniform</span>(<span class="params">fan_in, fan_out, gain=<span class="number">1.0</span>, **kwargs</span>):</span><br><span class="line">    a = gain * math.sqrt(<span class="number">6</span> / (fan_in + fan_out))</span><br><span class="line">    out = rand(fan_in, fan_out, low=-a, high=a)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="Xavier-normal"><a href="#Xavier-normal" class="headerlink" title="Xavier normal"></a>Xavier normal</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正太分布 N(0, std)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xavier_normal</span>(<span class="params">fan_in, fan_out, gain=<span class="number">1.0</span>, **kwargs</span>):</span><br><span class="line">    std = gain * math.sqrt(<span class="number">2</span> / (fan_in + fan_out))</span><br><span class="line">    out = randn(fan_in, fan_out, mean=<span class="number">0</span>, std=std)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="Kaiming-uniform"><a href="#Kaiming-uniform" class="headerlink" title="Kaiming uniform"></a>Kaiming uniform</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 均匀分布 U(-bound, bound)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kaiming_uniform</span>(<span class="params">fan_in, fan_out, nonlinearity=<span class="string">&quot;relu&quot;</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">assert</span> nonlinearity == <span class="string">&quot;relu&quot;</span>, <span class="string">&quot;Only relu supported currently&quot;</span></span><br><span class="line">    gain = math.sqrt(<span class="number">2</span>)</span><br><span class="line">    bound = gain * math.sqrt(<span class="number">3</span> / fan_in)</span><br><span class="line">    out = rand(fan_in, fan_out, low=-bound, high=bound)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="Kaiming-normal"><a href="#Kaiming-normal" class="headerlink" title="Kaiming normal"></a>Kaiming normal</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">kaiming_normal</span>(<span class="params">fan_in, fan_out, nonlinearity=<span class="string">&quot;relu&quot;</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">assert</span> nonlinearity == <span class="string">&quot;relu&quot;</span>, <span class="string">&quot;Only relu supported currently&quot;</span></span><br><span class="line">    gain = math.sqrt(<span class="number">2</span>)</span><br><span class="line">    std = gain / math.sqrt(fan_in)</span><br><span class="line">    out = randn(fan_in, fan_out, mean=<span class="number">0</span>, std=std)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h2 id="Question-2-1"><a href="#Question-2-1" class="headerlink" title="Question 2"></a>Question 2</h2><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Linear</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, in_features, out_features, bias=<span class="literal">True</span>, device=<span class="literal">None</span>, dtype=<span class="string">&quot;float32&quot;</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.in_features = in_features</span><br><span class="line">        self.out_features = out_features</span><br><span class="line">        self.have_bias = bias</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># weight和bias需要定义成Parameter类型</span></span><br><span class="line">        self.weight = Parameter(init.kaiming_uniform(in_features, out_features,device = device, dtype = dtype))</span><br><span class="line">        <span class="keyword">if</span> self.have_bias:</span><br><span class="line">            self.bias = Parameter(init.kaiming_uniform(out_features, <span class="number">1</span>, device = device, dtype = dtype).reshape((<span class="number">1</span>, out_features)))</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.have_bias:</span><br><span class="line">            bias = ops.broadcast_to(self.bias, (X.shape[<span class="number">0</span>], self.out_features))</span><br><span class="line">            <span class="keyword">return</span> ops.matmul(X, self.weight) + bias</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> ops.matmul(X, self.weight)</span><br></pre></td></tr></table></figure><h3 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Sequential</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *modules</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.modules = modules</span><br><span class="line">        <span class="comment"># print(type(modules))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="built_in">input</span> = x</span><br><span class="line">        <span class="keyword">for</span> module <span class="keyword">in</span> self.modules:</span><br><span class="line">            <span class="built_in">input</span> = module(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span></span><br></pre></td></tr></table></figure><h3 id="LogSumExp"><a href="#LogSumExp" class="headerlink" title="LogSumExp"></a>LogSumExp</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LogSumExp</span>(<span class="title class_ inherited__">TensorOp</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, axes: <span class="type">Optional</span>[<span class="built_in">tuple</span>] = <span class="literal">None</span></span>):</span><br><span class="line">        self.axes = axes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, Z</span>): <span class="comment"># 再次记住，在进行compute的时候输入输出是array，要使用array_api中的函数</span></span><br><span class="line">        max_z_f = array_api.<span class="built_in">max</span>(Z, axis=self.axes, keepdims=<span class="literal">False</span>) <span class="comment">#和Z的维度一致，每一行中每个元素都是这一行的最大值</span></span><br><span class="line">        max_z_t = array_api.<span class="built_in">max</span>(Z, axis=self.axes, keepdims=<span class="literal">True</span>) <span class="comment"># 公式最后的那个maxz</span></span><br><span class="line">        tmp = array_api.<span class="built_in">sum</span>(array_api.exp(Z - max_z_t),axis=self.axes, keepdims=<span class="literal">False</span>)</span><br><span class="line">        out = array_api.log(tmp) + max_z_f</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 疑问：maxz对z的梯度为0吗，为什么不计算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, out_grad, node</span>):</span><br><span class="line">        <span class="built_in">input</span> = node.inputs[<span class="number">0</span>].cached_data</span><br><span class="line">        max_val_t = array_api.<span class="built_in">max</span>(<span class="built_in">input</span>, axis=self.axes, keepdims=<span class="literal">True</span>)</span><br><span class="line">        exp_val = array_api.exp(<span class="built_in">input</span> - max_val_t)</span><br><span class="line">        sum_val = array_api.<span class="built_in">sum</span>(exp_val, axis=self.axes, keepdims=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># log_val = array_api.log(sum_val)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#把log中看成整体，先求对log的梯度</span></span><br><span class="line">        grad_log = out_grad.cached_data / sum_val </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求sum的梯度，和summation一样</span></span><br><span class="line">        shape = <span class="built_in">list</span>(node.inputs[<span class="number">0</span>].shape)</span><br><span class="line">        axes = self.axes</span><br><span class="line">        <span class="keyword">if</span> axes <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">           axes = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(shape))) <span class="comment">#axes为None是对所有维度求和，相当于axes=(0,1,..)</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> axes:</span><br><span class="line">            shape[_] = <span class="number">1</span></span><br><span class="line">        grad_sum = array_api.broadcast_to(array_api.reshape(grad_log, shape), node.inputs[<span class="number">0</span>].shape)</span><br><span class="line">        <span class="comment"># broadcast_to(reshape(grad_log, shape), node.inputs[0].shape)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求exp的梯度</span></span><br><span class="line">        grad_exp = grad_sum * exp_val</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> Tensor(grad_exp)</span><br></pre></td></tr></table></figure><h3 id="SoftmaxLoss"><a href="#SoftmaxLoss" class="headerlink" title="SoftmaxLoss"></a>SoftmaxLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SoftmaxLoss</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits: Tensor, y: Tensor</span>):</span><br><span class="line">        softmax = ops.logsumexp(logits, axes=(<span class="number">1</span>,))</span><br><span class="line">        </span><br><span class="line">        shape =  logits.shape</span><br><span class="line">        batch_size = shape[<span class="number">0</span>]</span><br><span class="line">        num_class = shape[<span class="number">1</span>]</span><br><span class="line">        y_one_hot = init.one_hot(num_class, y)</span><br><span class="line">        I = ops.summation(logits * y_one_hot, axes=(<span class="number">1</span>,))</span><br><span class="line">        <span class="comment"># print(I)</span></span><br><span class="line">        <span class="keyword">return</span> ops.summation(softmax - I) / batch_size</span><br></pre></td></tr></table></figure><h3 id="LayerNorm1d"><a href="#LayerNorm1d" class="headerlink" title="LayerNorm1d"></a>LayerNorm1d</h3><p>为什么需要Normalization？</p><blockquote><p>深度神经网络模型的训练为什么会很困难？其中一个重要的原因是，深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。Google 将这一现象总结为 Internal Covariate Shift，简称 ICS. </p></blockquote><blockquote><p>大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning &#x2F; domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同，即：对所有𝑥∈𝑋,𝑃𝑠(𝑌|𝑋&#x3D;𝑥)&#x3D;𝑃𝑡(𝑌|𝑋&#x3D;𝑥) 但是𝑃𝑠(𝑋)≠𝑃𝑡(𝑋) 大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">开始时计算E时，想直接使用.data来计算，不想创建复杂的计算图。后来意识到这计算过程就是需要创建计算图的。乐</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm1d</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span>, device=<span class="literal">None</span>, dtype=<span class="string">&quot;float32&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.eps = eps</span><br><span class="line">        <span class="comment"># 初始化参数</span></span><br><span class="line">        self.weight = Parameter(init.ones(dim, device=device, dtype=dtype))</span><br><span class="line">        self.bias = Parameter(init.zeros(dim, device=device, dtype=dtype))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        features = x.shape[<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算均值</span></span><br><span class="line">        sum_x = ops.summation(x, <span class="number">1</span>) <span class="comment">#计算完后维度降低了,原来是(batch_size, features)现在是(batch_size,)</span></span><br><span class="line">        mean_x = ops.divide_scalar(sum_x, features)</span><br><span class="line">        mean_x_reshape = ops.reshape(mean_x, (-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        E = ops.broadcast_to(mean_x_reshape, x.shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算标准差</span></span><br><span class="line">        V_inner = ops.power_scalar(x-E, <span class="number">2</span>)</span><br><span class="line">        V_sum = ops.summation(V_inner, <span class="number">1</span>)   <span class="comment"># (batch_size,)</span></span><br><span class="line">        V_mean = ops.divide_scalar(V_sum, features)</span><br><span class="line">        V = ops.add_scalar(V_mean, self.eps)</span><br><span class="line">        sqrt_Var = ops.power_scalar(V, <span class="number">1</span>/<span class="number">2</span>)    <span class="comment"># (batch_size,)</span></span><br><span class="line">        sqrt_Var_reshape = ops.reshape(sqrt_Var, (-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        sqrt_Var_reshape_brocst = ops.broadcast_to(sqrt_Var_reshape, x.shape) <span class="comment"># (batch_size,feature)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算X</span></span><br><span class="line">        X  = (x - E) / sqrt_Var_reshape_brocst</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># weight和bias的维度都是dim即features</span></span><br><span class="line">        broadcast_weight = ops.broadcast_to(ops.reshape(self.weight, (<span class="number">1</span>, -<span class="number">1</span>)), x.shape)</span><br><span class="line">        broadcast_bias = ops.broadcast_to(ops.reshape(self.bias, (<span class="number">1</span>,-<span class="number">1</span>)), x.shape)</span><br><span class="line">        </span><br><span class="line">        out = broadcast_weight * X + broadcast_bias</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="BatchNorm1d"><a href="#BatchNorm1d" class="headerlink" title="BatchNorm1d"></a>BatchNorm1d</h3><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202407241018831.png" alt="image-20240724101503540"></p><p>LayerNormalize是在一个sample中对所有dimension进行的。而BatchNormalize是针对一个dim将minibatch中该dim所有的值进行规范</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202407241019761.png" alt="image-20240724101916737"></p><p>公式分两步：</p><ul><li>中间的计算<strong>使得第 𝑙 层的输入每个特征的分布均值为0，方差为1。</strong></li><li>引入可学习的参数w和b，引入的目的是为了恢复数据本身的表达能力，对规范化后的数据进行线性变换</li></ul><p>在训练模型时，在每一层计算的 𝜇 与 𝜎2 都是基于当前batch中的训练数据；而当做预测时，一批预测只有一个或者很少样本，计算出的𝜇 与 𝜎2 一定有偏差。如何解决？</p><p>保留每组mini-batch训练数据在网络中每一层的 𝜇𝑏𝑎𝑡𝑐ℎ 与 𝜎𝑏𝑎𝑡𝑐ℎ2 。预测时使用整个样本的统计量来对预测数据进行归一化。即<strong>额外计算每层网络的运行时均值和方差</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BatchNorm1d</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.1</span>, device=<span class="literal">None</span>, dtype=<span class="string">&quot;float32&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.momentum = momentum</span><br><span class="line">        </span><br><span class="line">        self.weight = Parameter(init.ones(dim, device=device, dtype=dtype))</span><br><span class="line">        self.bias = Parameter(init.zeros(dim, device=device, dtype=dtype))</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        下边两个并不是Parameter，因为他们不是权重，在最后一个测试时发现</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.running_mean = init.zeros(dim, device=device, dtype=dtype) <span class="comment">#运行时每一dim上的均值方差</span></span><br><span class="line">        self.running_var = init.ones(dim, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        broadcast_weight = ops.broadcast_to(ops.reshape(self.weight, (<span class="number">1</span>, -<span class="number">1</span>)), x.shape)</span><br><span class="line">        broadcast_bias = ops.broadcast_to(ops.reshape(self.bias, (<span class="number">1</span>,-<span class="number">1</span>)), x.shape)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.training:    </span><br><span class="line">        <span class="comment"># 计算当前batch的均值</span></span><br><span class="line">            sum_x = ops.summation(x, <span class="number">0</span>) <span class="comment">#(batch_size, features)-&gt;(features)</span></span><br><span class="line">            mean_x = ops.divide_scalar(sum_x, batch_size)</span><br><span class="line">            broadcast_mean = ops.broadcast_to(mean_x, x.shape)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算当前batch的标准差</span></span><br><span class="line">            pow_Var = ops.power_scalar(x-broadcast_mean, <span class="number">2</span>)</span><br><span class="line">            sum_Var = ops.summation(pow_Var, <span class="number">0</span>) <span class="comment">#(batch_size, features)-&gt;(features)</span></span><br><span class="line">            Var = ops.divide_scalar(sum_Var, batch_size)</span><br><span class="line">            Var_add_eps = ops.power_scalar(ops.add_scalar(Var, self.eps), <span class="number">1</span>/<span class="number">2</span>)</span><br><span class="line">            broadcast_var = ops.broadcast_to(Var_add_eps, x.shape)</span><br><span class="line">            </span><br><span class="line">            out = broadcast_weight * (x - broadcast_mean) / broadcast_var + broadcast_bias</span><br><span class="line">            </span><br><span class="line">            self.running_mean = (<span class="number">1</span> - self.momentum) * self.running_mean + self.momentum * mean_x</span><br><span class="line">            self.running_var = (<span class="number">1</span> - self.momentum) * self.running_var + self.momentum * Var</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            broadcast_running_mean = ops.broadcast_to(ops.reshape(self.running_mean, (<span class="number">1</span>,-<span class="number">1</span>)), x.shape)</span><br><span class="line">            running_var_add_eps = ops.power_scalar(ops.add_scalar(self.running_var, self.eps), <span class="number">1</span>/<span class="number">2</span>)</span><br><span class="line">            broadcast_running_var = ops.broadcast_to(ops.reshape(running_var_add_eps, (<span class="number">1</span>,-<span class="number">1</span>)), x.shape)</span><br><span class="line">            out = broadcast_weight * (x-broadcast_running_mean) / broadcast_running_var + broadcast_bias</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dropout</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            mask = init.randb(*x.shape, p = <span class="number">1</span>- self.p) / (<span class="number">1</span> - self.p)</span><br><span class="line">            x = x * mask</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="Residual"><a href="#Residual" class="headerlink" title="Residual"></a>Residual</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fn: Module</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> self.fn(x) + x</span><br></pre></td></tr></table></figure><h2 id="Question3"><a href="#Question3" class="headerlink" title="Question3"></a>Question3</h2><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>有几个需要注意的</p><ul><li>u是字典，key是Param，value是该Param上一次计算时的梯度。</li><li>weight_decay表明需要考虑L2regularization，即真正的梯度是param.grad.data + weight_decay * W，这才是(1-β)后的那个梯度</li><li>因为写完后报错float64和float32不一致，所以将grad的dtype改成param的dtype</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SGD</span>(<span class="title class_ inherited__">Optimizer</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params, lr=<span class="number">0.01</span>, momentum=<span class="number">0.0</span>, weight_decay=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(params) <span class="comment"># params是包含多个需要进行多次迭代计算的Param</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.momentum = momentum</span><br><span class="line">        self.u = &#123;&#125; <span class="comment"># 字典，key是Param，value是该Param上一次计算时的梯度</span></span><br><span class="line">        self.weight_decay = weight_decay</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">            grad  = self.u.get(param, <span class="number">0</span>) * self.momentum + (<span class="number">1</span>-self.momentum) * (param.grad.data + self.weight_decay * param.data)</span><br><span class="line">            grad = ndl.Tensor(grad, dtype = param.dtype)</span><br><span class="line">            self.u[param] = grad</span><br><span class="line">            param.data =  param.data - self.lr * grad</span><br></pre></td></tr></table></figure><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>增加<code> if param.grad is not None:</code>判断条件是因为报错<code>param.grad</code>是<code>NoneType</code>的情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Adam</span>(<span class="title class_ inherited__">Optimizer</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        params,</span></span><br><span class="line"><span class="params">        lr=<span class="number">0.01</span>,</span></span><br><span class="line"><span class="params">        beta1=<span class="number">0.9</span>,</span></span><br><span class="line"><span class="params">        beta2=<span class="number">0.999</span>,</span></span><br><span class="line"><span class="params">        eps=<span class="number">1e-8</span>,</span></span><br><span class="line"><span class="params">        weight_decay=<span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(params)</span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.beta1 = beta1</span><br><span class="line">        self.beta2 = beta2</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.weight_decay = weight_decay</span><br><span class="line">        self.t = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.m = &#123;&#125;</span><br><span class="line">        self.v = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">        self.t += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">            <span class="keyword">if</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                grad_with_L2rgl = param.grad.data + self.weight_decay * param.data</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                grad_with_L2rgl = self.weight_decay * param.data</span><br><span class="line">            new_m = self.beta1 * self.m.get(param, <span class="number">0</span>) + (<span class="number">1</span>-self.beta1) * grad_with_L2rgl.data</span><br><span class="line">            new_v = self.beta2 * self.v.get(param, <span class="number">0</span>) + (<span class="number">1</span>-self.beta2) * grad_with_L2rgl.data * grad_with_L2rgl.data</span><br><span class="line">            self.m[param] = new_m</span><br><span class="line">            self.v[param] = new_v</span><br><span class="line">            m_hat = new_m.data / (<span class="number">1</span> - self.beta1 ** self.t)</span><br><span class="line">            v_hat = new_v.data / (<span class="number">1</span> - self.beta2 ** self.t)</span><br><span class="line">            out = param.data - self.lr * m_hat / (ndl.ops.power_scalar(v_hat, <span class="number">1</span>/<span class="number">2</span>) + self.eps)</span><br><span class="line">            out = ndl.Tensor(out, dtype=param.dtype)</span><br><span class="line">            param.data = out</span><br></pre></td></tr></table></figure><h2 id="Question4"><a href="#Question4" class="headerlink" title="Question4"></a>Question4</h2><h3 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RandomFlipHorizontal</span>(<span class="title class_ inherited__">Transform</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p = <span class="number">0.5</span></span>):</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, img</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Horizonally flip an image, specified as an H x W x C NDArray.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            img: H x W x C NDArray of an image</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            H x W x C ndarray corresponding to image flipped with probability self.p</span></span><br><span class="line"><span class="string">        Note: use the provided code to provide randomness, for easier testing</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        flip_img = np.random.rand() &lt; self.p</span><br><span class="line">        <span class="keyword">if</span> flip_img:</span><br><span class="line">            img = img[:,::-<span class="number">1</span>,:]</span><br><span class="line">        <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RandomCrop</span>(<span class="title class_ inherited__">Transform</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, padding=<span class="number">3</span></span>):</span><br><span class="line">        self.padding = padding</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, img</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; Zero pad and then randomly crop an image.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">             img: H x W x C NDArray of an image</span></span><br><span class="line"><span class="string">        Return </span></span><br><span class="line"><span class="string">            H x W x C NAArray of cliped image</span></span><br><span class="line"><span class="string">        Note: generate the image shifted by shift_x, shift_y specified below</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        shift_x, shift_y = np.random.randint(low=-self.padding, high=self.padding+<span class="number">1</span>, size=<span class="number">2</span>) <span class="comment"># [-self.padding, self.padding]</span></span><br><span class="line">        H, W, C = img.shape</span><br><span class="line">        pad = np.zeros((H+<span class="number">2</span>*self.padding, W+<span class="number">2</span>*self.padding, C))</span><br><span class="line">        pad[self.padding:self.padding+H,self.padding:self.padding+W,:] = img</span><br><span class="line">        x = shift_x + self.padding</span><br><span class="line">        y = shift_y + self.padding</span><br><span class="line">        img = pad[x:x+H, y:y+W,:]</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="MNISTDataset"><a href="#MNISTDataset" class="headerlink" title="MNISTDataset"></a>MNISTDataset</h3><p><code>Dataset</code>的作用是对于给定的数据路径，读取其中的数据</p><ul><li><code>parse_mnist</code>是从hw0复制来的，但是由于上边的转换函数我们发现对于一个sample是H* W* C，因此输出的X的维度应该是(sample_numbles, H, W, C)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MNISTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        image_filename: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        label_filename: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        transforms: <span class="type">Optional</span>[<span class="type">List</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        self.images, self.labels = parse_mnist(image_filename, label_filename)</span><br><span class="line">        self.transforms = transforms</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>) -&gt; <span class="built_in">object</span>:</span><br><span class="line">        img = self.images[index]</span><br><span class="line">        <span class="keyword">return</span> self.apply_transforms(img), self.labels[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> self.images.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># copy from hw0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_mnist</span>(<span class="params">image_filename, label_filename</span>):</span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(image_filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> img_f:</span><br><span class="line">        img_f.read(<span class="number">4</span>) <span class="comment">#skip magic number</span></span><br><span class="line">        num_images = <span class="built_in">int</span>.from_bytes(img_f.read(<span class="number">4</span>), <span class="string">&#x27;big&#x27;</span>) <span class="comment"># stored by high(big) endian</span></span><br><span class="line">        rows = <span class="built_in">int</span>.from_bytes(img_f.read(<span class="number">4</span>), <span class="string">&#x27;big&#x27;</span>)</span><br><span class="line">        cols = <span class="built_in">int</span>.from_bytes(img_f.read(<span class="number">4</span>), <span class="string">&#x27;big&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        image_data = img_f.read(num_images * rows * cols)</span><br><span class="line">        X = np.frombuffer(image_data, dtype=np.uint8).astype(np.float32)</span><br><span class="line">        X = X.reshape(num_images, rows, cols, <span class="number">1</span>) <span class="comment">#(sample_numbles, H, W, C)</span></span><br><span class="line">        X /= <span class="number">255.0</span> <span class="comment"># normalize to [0,1]</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(label_filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> lb_f:</span><br><span class="line">        lb_f.read(<span class="number">4</span>)</span><br><span class="line">        num_labels = <span class="built_in">int</span>.from_bytes(lb_f.read(<span class="number">4</span>), <span class="string">&#x27;big&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        lable_data = lb_f.read(num_labels)</span><br><span class="line">        y = np.frombuffer(lable_data, dtype=np.uint8)</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure><h3 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h3><p>给定Dataset，将数据按batch_size进行分批，并通过iter和next实现迭代。每次训练输入一批数据。需要注意一个坑：shuffle表示数据集中的sample是否需要打乱。开始时我直接在init()函数中判断，如果为true，直接做数据的打乱，而在iter函数中直接<code>return self</code>代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.shuffle:</span><br><span class="line">self.ordering = np.array_split(np.arange(<span class="built_in">len</span>(dataset)), </span><br><span class="line">                                           <span class="built_in">range</span>(batch_size, <span class="built_in">len</span>(dataset), batch_size))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">self.ordering = np.array_split(np.random.permutation(<span class="built_in">len</span>(self.dataset)), </span><br><span class="line">                                           <span class="built_in">range</span>(self.batch_size, <span class="built_in">len</span>(self.dataset), self.batch_size))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><p>而这么做的问题是，一旦在init中打乱，那么当做多epoch的训练时，对于不同的epoch来说，其ordering中的minibatch是一样的，因为只打乱了一次。</p><p>因此不能再init中打乱，而需要在iter中打乱。这样在每个epoch中，对minibatch的迭代开始时调用一次iter，到下一个epoch时，对minibatch迭代会再次调用iter，保证不同epoch中minibatch都不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataLoader</span>:</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Data loader. Combines a dataset and a sampler, and provides an iterable over</span></span><br><span class="line"><span class="string">    the given dataset.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataset (Dataset): dataset from which to load the data.</span></span><br><span class="line"><span class="string">        batch_size (int, optional): how many samples per batch to load</span></span><br><span class="line"><span class="string">            (default: ``1``).</span></span><br><span class="line"><span class="string">        shuffle (bool, optional): set to ``True`` to have the data reshuffled</span></span><br><span class="line"><span class="string">            at every epoch (default: ``False``).</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line">    dataset: Dataset</span><br><span class="line">    batch_size: <span class="type">Optional</span>[<span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        dataset: Dataset,</span></span><br><span class="line"><span class="params">        batch_size: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line"></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.shuffle:</span><br><span class="line">            self.ordering = np.array_split(np.arange(<span class="built_in">len</span>(dataset)), </span><br><span class="line">                                           <span class="built_in">range</span>(batch_size, <span class="built_in">len</span>(dataset), batch_size))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            self.ordering = np.array_split(np.random.permutation(<span class="built_in">len</span>(self.dataset)), </span><br><span class="line">                                           <span class="built_in">range</span>(self.batch_size, <span class="built_in">len</span>(self.dataset), self.batch_size))</span><br><span class="line">        self.idx = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        self.idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.idx &gt;= <span class="built_in">len</span>(self.ordering):</span><br><span class="line">            self.idx = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration()</span><br><span class="line">        samples = self.dataset[self.ordering[self.idx]]</span><br><span class="line">        samples = [Tensor(s) <span class="keyword">for</span> s <span class="keyword">in</span> samples]</span><br><span class="line">        <span class="keyword">return</span> samples</span><br></pre></td></tr></table></figure><h2 id="Question-5"><a href="#Question-5" class="headerlink" title="Question 5"></a>Question 5</h2><h3 id="ResidualBlock"><a href="#ResidualBlock" class="headerlink" title="ResidualBlock"></a>ResidualBlock</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ResidualBlock</span>(<span class="params">dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=<span class="number">0.1</span></span>):</span><br><span class="line">    main = nn.Sequential(</span><br><span class="line">        nn.Linear(dim, hidden_dim),</span><br><span class="line">        norm(hidden_dim),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(drop_prob),</span><br><span class="line">        nn.Linear(hidden_dim, dim),</span><br><span class="line">        norm(dim),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(nn.Residual(main), nn.ReLU())</span><br></pre></td></tr></table></figure><h3 id="MLPResNet"><a href="#MLPResNet" class="headerlink" title="MLPResNet"></a>MLPResNet</h3><p>作业的图中是没用Flatten的，但是输入的X的dim是(batch_size, H, W, C), 而第一个W的维度是(dim, hidden_dim),这里的dim&#x3D;H* W* 1。因此要给X进行Flatten</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">MLPResNet</span>(<span class="params"></span></span><br><span class="line"><span class="params">    dim,</span></span><br><span class="line"><span class="params">    hidden_dim=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">    num_blocks=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">    num_classes=<span class="number">10</span>,</span></span><br><span class="line"><span class="params">    norm=nn.BatchNorm1d,</span></span><br><span class="line"><span class="params">    drop_prob=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    layers = []</span><br><span class="line">    layers.append(nn.Flatten())</span><br><span class="line">    layers.append(nn.Linear(dim, hidden_dim))</span><br><span class="line">    layers.append(nn.ReLU())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">        layers.append(ResidualBlock(hidden_dim, hidden_dim // <span class="number">2</span>, norm, drop_prob))</span><br><span class="line">    layers.append(nn.Linear(hidden_dim, num_classes))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure><h3 id="Epoch"><a href="#Epoch" class="headerlink" title="Epoch"></a>Epoch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">epoch</span>(<span class="params">dataloader, model, opt=<span class="literal">None</span></span>): <span class="comment"># opt是优化器，如SGD， Adam</span></span><br><span class="line">    np.random.seed(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">if</span> opt <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model.train()</span><br><span class="line">    loss_fuc = nn.SoftmaxLoss()</span><br><span class="line">    acc_num = <span class="number">0</span></span><br><span class="line">    losses = []</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> dataloader:</span><br><span class="line">        out = model(X)</span><br><span class="line">        loss = loss_fuc(out, y)</span><br><span class="line">        <span class="keyword">if</span> opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss.backward() <span class="comment">#计算节点梯度</span></span><br><span class="line">            opt.step() <span class="comment">#权重更新</span></span><br><span class="line">            </span><br><span class="line">        losses.append(loss.numpy())</span><br><span class="line">        acc_num += (out.numpy().argmax(axis=<span class="number">1</span>) == y.numpy()).<span class="built_in">sum</span>()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - acc_num / <span class="built_in">len</span>(dataloader.dataset), np.mean(losses)</span><br></pre></td></tr></table></figure><h3 id="Train-Mnist"><a href="#Train-Mnist" class="headerlink" title="Train Mnist"></a>Train Mnist</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_mnist</span>(<span class="params"></span></span><br><span class="line"><span class="params">    batch_size=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">    epochs=<span class="number">10</span>,</span></span><br><span class="line"><span class="params">    optimizer=ndl.optim.Adam,</span></span><br><span class="line"><span class="params">    lr=<span class="number">0.001</span>,</span></span><br><span class="line"><span class="params">    weight_decay=<span class="number">0.001</span>,</span></span><br><span class="line"><span class="params">    hidden_dim=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">    data_dir=<span class="string">&quot;data&quot;</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    np.random.seed(<span class="number">4</span>)</span><br><span class="line">    <span class="comment">#  Initialize tranning dataloader</span></span><br><span class="line">    trainning_dataset = ndl.data.MNISTDataset(</span><br><span class="line">        os.path.join(data_dir, <span class="string">&quot;train-images-idx3-ubyte.gz&quot;</span>),</span><br><span class="line">        os.path.join(data_dir, <span class="string">&quot;train-labels-idx1-ubyte.gz&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    trainning_data_loader = ndl.data.DataLoader(trainning_dataset, batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#  Initialize test dataloader</span></span><br><span class="line">    test_dataset = ndl.data.MNISTDataset(</span><br><span class="line">        os.path.join(data_dir, <span class="string">&quot;t10k-images-idx3-ubyte.gz&quot;</span>),</span><br><span class="line">        os.path.join(data_dir, <span class="string">&quot;t10k-labels-idx1-ubyte.gz&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    test_data_loader = ndl.data.DataLoader(test_dataset, batch_size)</span><br><span class="line"></span><br><span class="line">    shape = test_data_loader.dataset.images.shape</span><br><span class="line">    dim = shape[<span class="number">1</span>] * shape[<span class="number">2</span>]</span><br><span class="line">    <span class="built_in">print</span>(dim)</span><br><span class="line">    model = MLPResNet(dim=dim, hidden_dim=hidden_dim)</span><br><span class="line"></span><br><span class="line">    opt = optimizer(model.parameters(), lr=lr, weight_decay=weight_decay)</span><br><span class="line"></span><br><span class="line">    train_err,train_loss = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    test_err,test_loss = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        train_err, train_loss = epoch(trainning_data_loader, model, opt)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch %d: Train err: %f, Train loss: %f&quot;</span> % (</span><br><span class="line">            i, train_err, train_loss</span><br><span class="line">        ))</span><br><span class="line">    test_err, test_loss = epoch(test_data_loader, model)</span><br><span class="line">    <span class="keyword">return</span> train_err, train_loss, test_err, test_loss</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> cmu10-414 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cmu10-414阶段性总结</title>
      <link href="/2024/07/22/cmu10-414%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/"/>
      <url>/2024/07/22/cmu10-414%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="cmu10-414知识点总结-HW2"><a href="#cmu10-414知识点总结-HW2" class="headerlink" title="cmu10-414知识点总结(HW2)"></a>cmu10-414知识点总结(HW2)</h1><h2 id="重要代码块"><a href="#重要代码块" class="headerlink" title="重要代码块"></a>重要代码块</h2><p>HW2分支的代码结构如下</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202407221551271.png" alt="image-20240722155125198"></p><h3 id="inin-py"><a href="#inin-py" class="headerlink" title="inin.py"></a><strong>inin</strong>.py</h3><p><code>__inin__.py</code>中定义<strong>needle对外暴露的模块、类、函数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from . import ops</span><br><span class="line">from .ops import *</span><br><span class="line">from .autograd import Tensor, cpu, all_devices</span><br><span class="line"></span><br><span class="line">from . import init</span><br><span class="line">from .init import ones, zeros, zeros_like, ones_like</span><br><span class="line"></span><br><span class="line">from . import data</span><br><span class="line">from . import nn</span><br><span class="line">from . import optim</span><br></pre></td></tr></table></figure><p>第一二行含义，可以通过needle.ops.summation或者needle.summation调用summation函数</p><h3 id="optim-py"><a href="#optim-py" class="headerlink" title="optim.py"></a>optim.py</h3><p>定义了一些待实现的优化器</p><h3 id="autograd-py"><a href="#autograd-py" class="headerlink" title="autograd.py"></a>autograd.py</h3><p>定义了Op、Value、Tensor核心数据结构</p><p>对于TensorOp，它继承了Op，有3个重要函数(属性)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, *args: <span class="type">Tuple</span>[NDArray]</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Calculate forward pass of operator.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        input: np.ndarray</span></span><br><span class="line"><span class="string">            A list of input arrays to the function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        output: nd.array</span></span><br><span class="line"><span class="string">            Array output of the operation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br></pre></td></tr></table></figure><p>输入输出都是array</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self, out_grad: <span class="string">&quot;Value&quot;</span>, node: <span class="string">&quot;Value&quot;</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Union</span>[<span class="string">&quot;Value&quot;</span>, <span class="type">Tuple</span>[<span class="string">&quot;Value&quot;</span>]]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute partial adjoint for each input value for a given output adjoint.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    out_grad: Value</span></span><br><span class="line"><span class="string">        The adjoint wrt to the output value.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    node: Value</span></span><br><span class="line"><span class="string">        The value node of forward evaluation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    input_grads: Value or Tuple[Value]</span></span><br><span class="line"><span class="string">        A list containing partial gradient adjoints to be propagated to</span></span><br><span class="line"><span class="string">        each of the input node.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>输入输出实际都是Tensor。计算这个op对input的偏导数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *args</span>):</span><br><span class="line">    <span class="comment"># print(self)</span></span><br><span class="line">    <span class="keyword">return</span> Tensor.make_from_op(self, args)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_from_op</span>(<span class="params">op: Op, inputs: <span class="type">List</span>[<span class="string">&quot;Value&quot;</span>]</span>):</span><br><span class="line">    <span class="comment"># print(op)</span></span><br><span class="line">    <span class="comment"># print(inputs)</span></span><br><span class="line">    tensor = Tensor.__new__(Tensor)</span><br><span class="line">    tensor._init(op, inputs)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> LAZY_MODE:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tensor.requires_grad:</span><br><span class="line">            <span class="keyword">return</span> tensor.detach()</span><br><span class="line">        tensor.realize_cached_data()</span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">realize_cached_data</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run compute to realize the cached data&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># avoid recomputation</span></span><br><span class="line">    <span class="keyword">if</span> self.cached_data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> self.cached_data</span><br><span class="line">    <span class="comment"># note: data implicitly calls realized cached data</span></span><br><span class="line">    <span class="comment"># op.compute的输入输出都是NDarray类型</span></span><br><span class="line">    self.cached_data = self.op.compute(</span><br><span class="line">        *[x.realize_cached_data() <span class="keyword">for</span> x <span class="keyword">in</span> self.inputs]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> self.cached_data</span><br></pre></td></tr></table></figure><p><code>__call__</code>函数可以将一个对象当成一个函数使用，当使用“summation”计算a某些维度上的和时，</p><p>先通过<code>Summation(axes)(a)</code>创建一个对象，并传入参数a。此时将对象当作函数使用，调用<code>__call__</code>。在<code>make_from_op</code>中创建一个新的tensor，并将其op和input设置为Summation和a。通过<code>realize_cached_data()</code>中调用op.compute()来计算其<code>cached_data</code></p><p>对于Value类，关注其属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Value</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;A value in the computational graph.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># trace of computational graph</span></span><br><span class="line">    op: <span class="type">Optional</span>[Op]</span><br><span class="line">    inputs: <span class="type">List</span>[<span class="string">&quot;Value&quot;</span>]</span><br><span class="line">    <span class="comment"># The following fields are cached fields for</span></span><br><span class="line">    <span class="comment"># dynamic computation</span></span><br><span class="line">    cached_data: NDArray</span><br><span class="line">    requires_grad: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure><p><code>inputs</code>是计算节点的输入，最多是2个</p><p><code>cached_data</code>是这个计算节点将<code>inputs</code>通过<code>op</code>计算后的结果</p><p><code>requires_grad</code>是否需要梯度，因为常数值不需要计算梯度</p><p>对于Tensor类，新增了<code>grad: &quot;Tensor&quot;</code>属性(注意梯度也是Tensor类型)，关注其函数</p><p>首先是<code>__init__()</code>，当使用<code>Tensor([2,3,4])</code>初始化时调用该函数。<code>make_from_op()</code>的用法上文说过。</p><p>A.data的作用是创建一个和A的<code>cached_data</code>一样的Tensor，但是不具有A的op、inputs等计算图中的关系，即独立于A所在的计算图。<code>@data.setter</code>的作用是当设置修改data的数据时调用这个函数，直接将<code>A.cache_data</code>设置为<code>value.cache_data</code> 。  </p><p>即<code>A.data = A.data + B.data</code>的流程是：</p><ul><li>A和B分别调用detach()创建一个与之cached_data一致的独立于计算图的无梯度Tensor</li><li>二者相加(Tensor类对一些基本的运算做了重载，后文说明)</li><li>因为这里要修改data的值，因此调用setter下的函数，将A的cached_data设置为相加后的Tensor的cached_data</li></ul><p>设置这样的一个属性的目的是：</p><blockquote><p>假如我们要计算多轮迭代之后的一个Tensor的梯度。只要最后的结果</p><p>grad &#x3D; ndl.Tensor([1, 1, 1], dtype&#x3D;”float32”)</p><p>lr &#x3D; 0.1</p><p>for i in range(5):</p><p>​w &#x3D; w + (-lr) * grad</p><p>上边写法会在多轮的”+”构建一个计算图，占用很大存储空间，但是我们只要最后的结果。</p><p>而用上data属性后，如下的计算方式无需创建额外的Tensor</p><p>for i in range(5):</p><p>​w.data &#x3D; w.data + (-lr) * grad.data</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property </span><span class="comment">#将方法转换成属性，通过.data返问</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> self.detach()</span><br><span class="line"></span><br><span class="line"><span class="meta">@data.setter</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">self, value</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(value, Tensor)</span><br><span class="line">    <span class="keyword">assert</span> value.dtype == self.dtype, <span class="string">&quot;%s %s&quot;</span> % (</span><br><span class="line">        value.dtype,</span><br><span class="line">        self.dtype,</span><br><span class="line">    )</span><br><span class="line">    self.cached_data = value.realize_cached_data()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detach</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a new tensor that shares the data but detaches from the graph.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> Tensor.make_const(self.realize_cached_data())</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_const</span>(<span class="params">data, requires_grad=<span class="literal">False</span></span>): </span><br><span class="line">    tensor = Tensor.__new__(Tensor)</span><br><span class="line">    tensor._init(</span><br><span class="line">        <span class="literal">None</span>,</span><br><span class="line">        [],</span><br><span class="line">        cached_data=data</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(data, Tensor)</span><br><span class="line">        <span class="keyword">else</span> data.realize_cached_data(),</span><br><span class="line">        requires_grad=requires_grad,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> tensor</span><br></pre></td></tr></table></figure><p>当要进行反向传播时，通过backward函数计算<strong>计算图</strong>中节点梯度。使用方式A.backward()。</p><p>在backward中调用<code>compute_gradient_of_variables()</code>函数，先通过<code>find_topo_sort()</code>使用拓扑排序计算由output_tensor结束的计算图的拓扑排序结果，进行reversed的目的是我们计算梯度的过程是从后往前算的</p><h3 id="ops-ops-mathematic-py"><a href="#ops-ops-mathematic-py" class="headerlink" title="ops-&gt;ops_mathematic.py"></a>ops-&gt;ops_mathematic.py</h3><p>实现了一些算子类的前向计算与梯度计算，继承自TensorOp</p><h3 id="ops-ops-logarithmatic-py"><a href="#ops-ops-logarithmatic-py" class="headerlink" title="ops-&gt;ops_logarithmatic.py"></a>ops-&gt;ops_logarithmatic.py</h3><h3 id="init-init-initializers-py"><a href="#init-init-initializers-py" class="headerlink" title="init-&gt;init_initializers.py"></a>init-&gt;init_initializers.py</h3><p>定义了几个权重的初始化类，用于初始化权重</p><h2 id="归一化-Normalization-与正则化-Regularization"><a href="#归一化-Normalization-与正则化-Regularization" class="headerlink" title="归一化(Normalization)与正则化(Regularization)"></a>归一化(Normalization)与正则化(Regularization)</h2><p>归一化是特征缩放的一种形式，是把数据压缩到一个区间内，比如[0,1]。本节有BatchNorm和LayerNorm。</p><p>正则化是为了解决过拟合问题。有L2正则化和L1正则化。权重的大小会影响训练的复杂性。因此可以，使大的权重小一点。</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202407241705501.png" alt="image-20240724170512416"></p><p>如图L2正则化修改优化的目标函数，使在计算梯度前先将权重进行收缩</p>]]></content>
      
      
      <categories>
          
          <category> cmu10-414 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用qemu运行内核并使用Redis-benchmark测试迁移</title>
      <link href="/2024/01/07/%E4%BD%BF%E7%94%A8qemu%E8%BF%90%E8%A1%8C%E5%86%85%E6%A0%B8%E5%B9%B6%E4%BD%BF%E7%94%A8Redis-benchmark%E6%B5%8B%E8%AF%95%E8%BF%81%E7%A7%BB/"/>
      <url>/2024/01/07/%E4%BD%BF%E7%94%A8qemu%E8%BF%90%E8%A1%8C%E5%86%85%E6%A0%B8%E5%B9%B6%E4%BD%BF%E7%94%A8Redis-benchmark%E6%B5%8B%E8%AF%95%E8%BF%81%E7%A7%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="使用qemu运行内核并使用Redis-benchmark测试迁移"><a href="#使用qemu运行内核并使用Redis-benchmark测试迁移" class="headerlink" title="使用qemu运行内核并使用Redis-benchmark测试迁移"></a>使用qemu运行内核并使用Redis-benchmark测试迁移</h1><p>前情提要：本来在实体机上想进行测试程序检验NUMA节点间的迁移，因为CPU型号问题无法开启NUMA（只有一个NUMA节点）。遂采用师兄的方法：使用qemu虚拟机来运行内核。</p><p>下边给出配置过程</p><h2 id="编译内核镜像"><a href="#编译内核镜像" class="headerlink" title="编译内核镜像"></a>编译内核镜像</h2><p>1、先提前安装一些包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update &amp;&amp; sudo apt upgrade</span><br><span class="line">sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison</span><br></pre></td></tr></table></figure><p>2、下载kernel</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone 自己的kernel地址</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make menuconfg</span><br></pre></td></tr></table></figure><p>3、修改.config</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim ./.config</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将下边两行注释</span></span><br><span class="line">CONFIG_DEBUG_INFO=y  </span><br><span class="line">CONFIG_DEBUG_INFO_BTF=y</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将下边一行引号内改为空</span></span><br><span class="line">CONFIG_SYSTEM_TRUSTED_KEYS=&quot;debian/canonical-certs.pem&quot;</span><br><span class="line">CONFIG_SYSTEM_REVOCATION_KEYS=&quot;debian/canonical-revoked-certs.pem&quot;</span><br></pre></td></tr></table></figure><p>4、编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j 32</span><br></pre></td></tr></table></figure><p>5、安装qemu</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install qemu-system-x86</span><br></pre></td></tr></table></figure><h2 id="基于ubuntu-base构建根文件系统"><a href="#基于ubuntu-base构建根文件系统" class="headerlink" title="基于ubuntu base构建根文件系统"></a>基于ubuntu base构建根文件系统</h2><p>之前使用busybox会导致其中没有我们需要的bash指令，随使用ubuntu base</p><p>1、下载ubuntu base</p><p>去清华镜像源或者<a href="https://cdimage.ubuntu.com/ubuntu-base/releases/">ubuntu官网</a>，我这里选择的是22.04下的<code>ubuntu-base-23.04-base-amd64.tar.gz</code>（因为我的ubuntu系统是22.04）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/download</span><br><span class="line">wget https://cdimage.ubuntu.com/ubuntu-base/releases/23.04/release/ubuntu-base-23.04-base-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>2、创建image镜像（此处起名为ubuntu_rootfs.ext4）</p><p>下面给出我的方法，在download目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dd if=/dev/zero of=ubuntu_rootfs.ext4 bs=1G count=30 # 创建30G容量的镜像文件</span><br><span class="line">mkfs.ext4 ubuntu_rootfs.ext4  #格式化为ext4的文件系统</span><br></pre></td></tr></table></figure><p>3、创建目录作为镜像文件的挂载点，将镜像文件挂在上去</p><p>在download目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir rootfs</span><br><span class="line">sudo mount ubuntu_rootfs.ext4 rootfs/</span><br></pre></td></tr></table></figure><p>4、将ubuntu base解压到rootfs下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf  ubuntu-base-22.04-base-amd64.tar.gz -C rootfs</span><br></pre></td></tr></table></figure><p>5、拷贝主机中的网络配置信息到镜像中，方便后续用apt安装软件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/resolv.conf rootfs/etc</span><br></pre></td></tr></table></figure><p>6、创建<code>mount.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">mnt() &#123;</span><br><span class="line">echo &quot;MOUNTING&quot;</span><br><span class="line">sudo mount -t proc /proc $&#123;2&#125;proc</span><br><span class="line">sudo mount -t sysfs /sys $&#123;2&#125;sys</span><br><span class="line">sudo mount -o bind /dev $&#123;2&#125;dev</span><br><span class="line">sudo mount -o bind /dev/pts $&#123;2&#125;dev/pts</span><br><span class="line">sudo chroot $&#123;2&#125;</span><br><span class="line">&#125;</span><br><span class="line">umnt() &#123;</span><br><span class="line">echo &quot;UNMOUNTING&quot;</span><br><span class="line">sudo umount $&#123;2&#125;proc</span><br><span class="line">sudo umount $&#123;2&#125;sys</span><br><span class="line">sudo umount $&#123;2&#125;dev/pts</span><br><span class="line">sudo umount $&#123;2&#125;dev</span><br><span class="line">sudo umount $&#123;2&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if [ &quot;$1&quot; == &quot;-m&quot; ] &amp;&amp; [ -n &quot;$2&quot; ] ;</span><br><span class="line">then</span><br><span class="line">mnt $1 $2</span><br><span class="line">elif [ &quot;$1&quot; == &quot;-u&quot; ] &amp;&amp; [ -n &quot;$2&quot; ];</span><br><span class="line">then</span><br><span class="line">umnt $1 $2</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>7、执行挂载任务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mount.sh -m rootfs/</span><br></pre></td></tr></table></figure><p>其中的指令<code>chroot</code>将<code>rootfs</code>暂时设置为根目录，并启动终端。</p><p>8、安装必要的软件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apt update &amp;&amp; apt upgrade</span><br><span class="line">apt install git vim init linux-image-kvm ......</span><br><span class="line">apt install redis-server   #安装redis服务器</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装redis-benchmark</span></span><br><span class="line">wget http://download.redis.io/releases/redis-6.0.9.tar.gz</span><br><span class="line">tar xzf redis-6.0.9.tar.gz</span><br><span class="line">cd redis-6.0.9/src</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">redis-benchmark --help #检测是否安装成功</span><br></pre></td></tr></table></figure><p>这些软件都将会安装到ubuntu_rootfs.ext4镜像中</p><p>9、设置密码等</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">update-initramfs -u</span><br><span class="line">echo root:root | chpasswd</span><br><span class="line">echo ttyS0 &gt; /etc/securetty</span><br><span class="line">systemctl enable serial-getty@ttyS0.service</span><br></pre></td></tr></table></figure><p>10、退出卸载镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mount.sh -u rootfs/</span><br></pre></td></tr></table></figure><p>此后我们使用qemu启动这个镜像文件</p><p>特殊说明：我们使用qemu启动内核和之后，在里边是无法下载安装东西的，因为没有配置网络这些。因此比如当我们需要安装<code>redis</code>时，需要执行7、8、10即可</p><p>输入<code>exit</code>退出<code>chroot</code></p><h2 id="使用qemu启动"><a href="#使用qemu启动" class="headerlink" title="使用qemu启动"></a>使用qemu启动</h2><p>1、配置启动qemu的脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">ubuntuBaseImage=&quot;/home/wufang/download/ubuntu_rootfs.ext4&quot;  </span><br><span class="line">kernelDir=.</span><br><span class="line"></span><br><span class="line">sudo qemu-system-x86_64 \</span><br><span class="line">    -enable-kvm\</span><br><span class="line">    -machine pc,nvdimm=on -s\</span><br><span class="line">    -m 2G,slots=4,maxmem=32G \</span><br><span class="line">    -nographic -kernel $kernelDir/vmlinux \</span><br><span class="line">    -smp cores=4,threads=1,sockets=2 \</span><br><span class="line">    -hda $ubuntuBaseImage \</span><br><span class="line">    -object memory-backend-ram,id=mem0,size=1G  \</span><br><span class="line">    -object memory-backend-ram,id=mem1,size=1G  \</span><br><span class="line">    -numa node,memdev=mem0,cpus=0-3,nodeid=0 \</span><br><span class="line">    -numa node,memdev=mem1,cpus=4-7,nodeid=1 \</span><br><span class="line">    -numa node,nodeid=2 -numa node,nodeid=3 \</span><br><span class="line">    -object memory-backend-ram,id=nvdimm1,size=4G\</span><br><span class="line">    -device nvdimm,memdev=nvdimm1,id=nv1,unarmed=off,node=2 \</span><br><span class="line">    -object memory-backend-ram,id=nvdimm2,size=4G\</span><br><span class="line">    -device nvdimm,memdev=nvdimm2,id=nv2,unarmed=off,node=3 \</span><br><span class="line">    -append &quot;console=ttyS0 crashkernel=712M root=/dev/sda rootfstype=ext4 rw loglevel=8&quot;\</span><br><span class="line">    -net nic -net tap,ifname=tap0,script=no,downscript=no</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./my_config.sh</span><br></pre></td></tr></table></figure><h2 id="使用redis-benchmark测试"><a href="#使用redis-benchmark测试" class="headerlink" title="使用redis-benchmark测试"></a>使用redis-benchmark测试</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-benchmark -h 127.0.0.1 -p 6379  -n 10000000 -r 1000000 -c 200 -d 32 -t ping,set,get</span><br></pre></td></tr></table></figure><ul><li>-n：测试包数量</li><li>-r：随机key数量</li><li>-c：客户端连接数</li><li>-t：执行具体的测试命令合集</li></ul><p>统计数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/vmstat | grep numa</span><br></pre></td></tr></table></figure><p>指令结果含义为如下：</p><ul><li>numa_hit：成功的本地内存访问次数</li><li>numa_miss：表示无法从本地节点获取页面的失败次数，需要从其它节点获取</li><li>numa_foreign：表示页面分配给一个节点，但是被从其它节点访问的次数</li><li>numa_interleave：通过内存交错的方式分配的页面数量</li></ul><p>编写脚本测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">STRS=(</span><br><span class="line">  &quot;numa_hit&quot;</span><br><span class="line">  &quot;numa_miss&quot;</span><br><span class="line">  &quot;numa_foreign&quot;</span><br><span class="line">  &quot;numa_interleave&quot;</span><br><span class="line">  &quot;numa_local&quot;</span><br><span class="line">  &quot;numa_other&quot;</span><br><span class="line">  &quot;numa_pte_updates&quot;</span><br><span class="line">  &quot;numa_huge_pte_updates&quot;</span><br><span class="line">  &quot;numa_hint_faults&quot;</span><br><span class="line">  &quot;numa_hint_faults_local&quot;</span><br><span class="line">  &quot;numa_pages_migrated&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">output_file=&quot;output.txt&quot; </span><br><span class="line"></span><br><span class="line">for ((epooch=1; epooch&lt;50; epooch++))</span><br><span class="line">do</span><br><span class="line"></span><br><span class="line">        declare -a PRE_VALUES</span><br><span class="line">        declare -a END_VALUES</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        PRE_TEST=$(cat /proc/vmstat | grep numa)</span><br><span class="line">        IFS=$&#x27;\n&#x27; read -rd &#x27;&#x27; -a PRE_TEST_ARRAY &lt;&lt;&lt;&quot;$PRE_TEST&quot;</span><br><span class="line">        for key in &quot;$&#123;PRE_TEST_ARRAY[@]&#125;&quot;;</span><br><span class="line">        do</span><br><span class="line">                value=$(echo &quot;$key&quot; | awk &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">                PRE_VALUES+=(&quot;$value&quot;)</span><br><span class="line">        done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        redis-benchmark -h 127.0.0.1 -p 6379 -n 1000000 -r 200000 -c 10000 -d 32 -t ping,set,get &amp;</span><br><span class="line">        pid=$!</span><br><span class="line">        wait &quot;$pid&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        END_TEST=$(cat /proc/vmstat | grep numa)</span><br><span class="line">        IFS=$&#x27;\n&#x27; read -rd &#x27;&#x27; -a END_TEST_ARRAY &lt;&lt;&lt;&quot;$END_TEST&quot;</span><br><span class="line"></span><br><span class="line">        for key in &quot;$&#123;END_TEST_ARRAY[@]&#125;&quot;;</span><br><span class="line">        do</span><br><span class="line">                value=$(echo &quot;$key&quot; | awk &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">                END_VALUES+=(&quot;$value&quot;)</span><br><span class="line">        done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for ((i=0; i&lt;$&#123;#STRS[@]&#125;; i++))</span><br><span class="line">        do</span><br><span class="line">                diff=$((END_VALUES[i] - PRE_VALUES[i]))</span><br><span class="line">                echo -n &quot;$diff &quot; &gt;&gt; &quot;$output_file&quot;</span><br><span class="line">                echo &quot;$&#123;END_VALUES[i]&#125; $&#123;PRE_VALUES[i]&#125; $diff&quot;</span><br><span class="line">        done</span><br><span class="line"></span><br><span class="line">        echo &gt;&gt; &quot;$output_file&quot;</span><br><span class="line">        echo &quot;The $epooch epo is over&quot;</span><br><span class="line">        unset PRE_VALUES</span><br><span class="line">        unset END_VALUES</span><br><span class="line">        unset PRE_TEST_ARRAY</span><br><span class="line">        unset END_TEST_ARRAY</span><br><span class="line">        sleep 60</span><br><span class="line">done</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux内核 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux物理内存分配(源码阅读2)</title>
      <link href="/2023/12/31/Linux%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D(%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB2)/"/>
      <url>/2023/12/31/Linux%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D(%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB2)/</url>
      
        <content type="html"><![CDATA[<p>首先，还是给出参考文献：<a href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247487111&idx=1&sn=e57371f9c3e6910f4f4721aa0787e537&chksm=ce77c8c0f90041d67b2d344d413a2573f3662a1a64a802b41d4618982fcbff1617d9a5da9f7b&scene=178&cur_album_id=2559805446807928833&poc_token=HH42jmWjzYC8XLG-QvRoCInlL45ANFw7eWIJAKJo">参考博客</a></p><h2 id="每CPU页框高速缓存"><a href="#每CPU页框高速缓存" class="headerlink" title="每CPU页框高速缓存"></a>每CPU页框高速缓存</h2><p>因为内存经常请求单个页框，因此为了提升性能，在伙伴系统之外又定义了一个per-CPU高速缓存</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">zone</span>&#123;</span></span><br><span class="line">    <span class="comment">// 实现每CPU页框的高速缓存。里面包含每个CPU的单页框的链表</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">per_cpu_pages</span>__<span class="title">percpu</span> *<span class="title">per_cpu_pageset</span>;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">per_cpu_pages</span> &#123;</span></span><br><span class="line"><span class="type">int</span> count;</span><br><span class="line"><span class="type">int</span> high;</span><br><span class="line"><span class="comment">// 当需要增加或者减少高速缓存页框时，操作的页框个数</span></span><br><span class="line"><span class="type">int</span> batch;</span><br><span class="line"><span class="comment">// 空闲期间的批量释放因子</span></span><br><span class="line"><span class="type">short</span> free_factor;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_NUMA</span></span><br><span class="line"><span class="type">short</span> expire;<span class="comment">/* When 0, remote pagesets are drained */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 每种迁移类型为一个链表</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">lists</span>[<span class="title">NR_PCP_LISTS</span>];</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中的<code>NR_PCP_LISTS</code>被定义为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> NR_PCP_LISTS (MIGRATE_PCPTYPES * (PAGE_ALLOC_COSTLY_ORDER + 1 + NR_PCP_THP))</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">MIGRATE_PCPTYPES为页面迁移类型，包括MIGRATE_UNMOVABLE,MIGRATE_MOVABLE,MIGRATE_RECLAIMABLE,</span></span><br><span class="line"><span class="comment">PAGE_ALLOC_COSTLY_ORDER 3</span></span><br><span class="line"><span class="comment">NR_PCP_THP 0</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h2 id="伙伴系统"><a href="#伙伴系统" class="headerlink" title="伙伴系统"></a>伙伴系统</h2><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312311546874.png" alt="640"></p><p>每个管理区<code>zone</code>都有自己的伙伴系统管理属于这个管理区的页框。在一个管理区中，伙伴系统一共维护着包含1,2,4,8,16,…,512,1024个连续页框的链表。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_ORDER 11</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">zone</span>&#123;</span></span><br><span class="line">    <span class="comment">// 相同大小的连续页框连接形成一个链表</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">free_area</span> <span class="title">free_area</span>[<span class="title">MAX_ORDER</span>];</span> <span class="comment">// 11个free_area，分别对应1,2,4,16,...,1024</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">free_area</span> &#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">list_head</span><span class="title">free_list</span>[<span class="title">MIGRATE_TYPES</span>];</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span>nr_free;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>伙伴系统中，<strong>相同大小的连续页框连接形成一个链表，在链表的每个节点中，又有以<code>MIGRATE_TYPES</code>区分的小链表</strong>，</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312291118186.png" alt="image-20231229111822073"></p><p>其MIGRATE_TYPES为页框类型，基本有如下：</p><ul><li><strong>MIGRATE_UNMOVABLE：</strong>页框内容不可移动,在内存中位置必须固定，无法移动到其他地方，核心内核分配的大部分页面都属于这一类。</li><li><strong>MIGRATE_RECLAIMABLE：</strong>页框内容可回收,不能直接移动，但是可以回收，因为还可以从某些源重建页面，比如映射文件的数据属于这种类别，kswapd会按照一定的规则，周期性的回收这类页面。</li><li><strong>MIGRATE_MOVABLE：</strong>页框内容可移动，属于用户空间应用程序的页属于此类页面，它们是通过页表映射的，因此我们只需要更新页表项，并把数据复制到新位置就可以了，当然要注意，一个页面可能被多个进程共享，对应着多个页表项。</li><li><strong>MIGRATE_PCPTYPES：</strong>用来表示每CPU页框高速缓存的数据结构中的链表的迁移类型数目。</li><li><strong>MIGRATE_CMA：</strong> 预留一段的内存给驱动使用，但当驱动不用的时候，伙伴系统可以分配给用户进程用作匿名内存或者页缓存。而当驱动需要使用时，就将进程占用的内存通过回收或者迁移的方式将之前占用的预留内存腾出来，供驱动使用。</li><li><strong>MIGRATE_ISOLATE：</strong>不能从这个链表分配页框，因为这个链表专门用于NUMA结点移动物理内存页，将物理内存页内容移动到使用这个页最频繁的CPU。</li></ul><p>在分配时，可能会出现某种类型的页面被耗尽不满足要求，因此需要如下对不同类型的页框进行优先级定义</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 当某种类型的空闲页面耗尽不满足需要数目时的优先级列表</span></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> fallbacks[MIGRATE_TYPES][<span class="number">3</span>] = &#123;</span><br><span class="line">[MIGRATE_UNMOVABLE]   = &#123; MIGRATE_RECLAIMABLE, MIGRATE_MOVABLE,   MIGRATE_TYPES &#125;,</span><br><span class="line">[MIGRATE_MOVABLE]     = &#123; MIGRATE_RECLAIMABLE, MIGRATE_UNMOVABLE, MIGRATE_TYPES &#125;,</span><br><span class="line">[MIGRATE_RECLAIMABLE] = &#123; MIGRATE_UNMOVABLE,   MIGRATE_MOVABLE,   MIGRATE_TYPES &#125;,</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_CMA</span></span><br><span class="line">[MIGRATE_CMA]         = &#123; MIGRATE_TYPES &#125;, <span class="comment">/* Never used */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_MEMORY_ISOLATION</span></span><br><span class="line">[MIGRATE_ISOLATE]     = &#123; MIGRATE_TYPES &#125;, <span class="comment">/* Never used */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>以MIGRATE_RECLAIMABLE为例，如果我需要申请这种页框，当然会优先从这类页框的链表中获取，如果没有，我会依次尝试从MIGRATE_UNMOVABLE -&gt; MIGRATE_MOVABLE -&gt; MIGRATE_RESERVE链进行分配。</p><h2 id="内核物理内存分配"><a href="#内核物理内存分配" class="headerlink" title="内核物理内存分配"></a>内核物理内存分配</h2><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">struct page *alloc_pages(gfp_t gfp, unsigned int order);</span><br><span class="line">#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)</span><br></pre></td></tr></table></figure><p><code>alloc_pages</code> 函数用于向底层伙伴系统申请 2 的 order 次幂个连续物理内存页组成的内存块，该函数返回值是一个 struct page 类型的指针用于指向申请的内存块中<strong>第一个物理内存页</strong>。返回值是<strong>页的物理内存地址</strong>，<code>alloc_page</code>用于分配单个页，其实就是把order指定为0。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">long</span> __get_free_pages(<span class="type">gfp_t</span> gfp_mask, <span class="type">unsigned</span> <span class="type">int</span> order)</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page</span>;</span></span><br><span class="line"></span><br><span class="line">page = alloc_pages(gfp_mask &amp; ~__GFP_HIGHMEM, order); <span class="comment">// 不能使用高端内存，因为高端内存不能 直接映射</span></span><br><span class="line"><span class="keyword">if</span> (!page)</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> (<span class="type">unsigned</span> <span class="type">long</span>) page_address(page); <span class="comment">// page_address对直接映射区的物理内存转换成虚拟内存</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>__get_free_pages</code>函数的功能和<code>alloc_pages</code>一样，只是返回的是<strong>页的虚拟地址</strong>。在其函数内部就是调用的<code>alloc_pages</code>,并调用<code>page_address</code>把页的物理地址转换成页的虚拟地址。</p><p>无论是 <code>alloc_pages</code> 也好还是 &#96;__get_free_pages&#96;&#96; 也好，它们申请到的内存页中包含的数据在一开始都不是空白的，而是内核<strong>随机产生的信息</strong>。</p><p>内核又提供了一个函数 get_zeroed_page，这个函数会将从伙伴系统中申请到内存页<strong>全部初始化填充为 0</strong> ，这在<strong>分配物理内存页给用户空间使用</strong>的时候非常有用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">long</span> <span class="title function_">get_zeroed_page</span><span class="params">(<span class="type">gfp_t</span> gfp_mask)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> __get_free_pages(gfp_mask | __GFP_ZERO, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内核还提供了一个 __get_dma_pages 函数，专门用于从 DMA 内存区域分配适用于 DMA 的物理内存页。其底层也是依赖于 __get_free_pages 函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> __get_dma_pages(gfp_mask, order)  __get_free_pages((gfp_mask) | GFP_DMA, (order))</span></span><br></pre></td></tr></table></figure><h3 id="内存释放"><a href="#内存释放" class="headerlink" title="内存释放"></a>内存释放</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __free_pages(<span class="keyword">struct</span> page *page, <span class="type">unsigned</span> <span class="type">int</span> order); <span class="comment">// 使用释放区域第一个page的物理地址</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">free_pages</span><span class="params">(<span class="type">unsigned</span> <span class="type">long</span> addr, <span class="type">unsigned</span> <span class="type">int</span> order)</span>; <span class="comment">// 使用虚拟地址</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 每次释放一个页</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __free_page(page) __free_pages((page), 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> free_page(addr) free_pages((addr), 0)</span></span><br></pre></td></tr></table></figure><h2 id="规范物理内存分配行为的掩码gfp-mask"><a href="#规范物理内存分配行为的掩码gfp-mask" class="headerlink" title="规范物理内存分配行为的掩码gfp_mask"></a>规范物理内存分配行为的掩码gfp_mask</h2><p>在进行物理内存分配的时候，需要对分配行为做出很多的设定与规范，使用<code>gfp_mask</code>掩码来规范。</p><p>以下是对掩码的定义,在<code>include/linux/gfp.h</code>中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">___GFP_DMA ： 0x01u = 00000001（二进制）</span></span><br><span class="line"><span class="comment">___GFP_HIGHMEM ： 0x02u = 00000010（二进制）</span></span><br><span class="line"><span class="comment">___GFP_DMA32 ： 0x04u = 00000100（二进制）</span></span><br><span class="line"><span class="comment">___GFP_MOVABLE ： 0x08u = 00001000（二进制）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">// 下边四个是限制内核的物理分配区域</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_DMA0x01u   <span class="comment">// 可以从DMA区域获得内存</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_HIGHMEM0x02u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_DMA320x04u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_MOVABLE0x08u</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 限制分配行为</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_RECLAIMABLE0x10u    <span class="comment">// 分配的页面是可以回收的</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_HIGH 0x20u  <span class="comment">// 内存分配请求的优先级是最高的，内核迫切需要内存，不允许失败</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_IO0x40u  <span class="comment">//分配时可以发起磁盘IO操作，即可以将不常用的内存也置换到SWAP分区</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_FS0x80u <span class="comment">// 允许内核执行底层文件系统操作</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_ZERO0x100u <span class="comment">//在内核分配内存成功之后，将内存页初始化填充字节 0 </span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_ATOMIC0x200u <span class="comment">// 不允许睡眠，必须原子性地分配</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_DIRECT_RECLAIM0x400u <span class="comment">// 内核在进行内存分配的时候，可以进行直接内存回收</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">___GFP_KSWAPD_RECLAIM表示内核在分配内存的时候，如果剩余内存容量在 _watermark[WMARK_MIN] 与 _watermark[WMARK_LOW] 之间时，内核就会唤醒 kswapd 进程开始异步内存回收</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_KSWAPD_RECLAIM0x800u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_WRITE0x1000u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_NOWARN0x2000u <span class="comment">// 分配失败时，抑制内核的分配失败报告</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_RETRY_MAYFAIL0x4000u <span class="comment">// 内存分配失败时，允许重试</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_NOFAIL0x8000u  <span class="comment">// 分配不允许失败，分配失败时一直重试直到成功</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_NORETRY0x10000u  <span class="comment">// 内存分配失败时，不允许重试</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">___GFP_MEMALLOC 允许内核在分配内存时可以从所有内存区域中获取内存，包括从紧急预留内存中获取。但使用该标示时需要保证进程在获得内存之后会很快的释放掉内存不会过长时间的占用，尤其要警惕避免过多的消耗紧急预留内存区域中的内存</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_MEMALLOC0x20000u </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_COMP0x40000u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_NOMEMALLOC  0x80000u <span class="comment">//禁止从紧急预留内存获得内存,优先级高于___GFP_MEMALLOC</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> ___GFP_HARDWALL 限制了内核分配内存的行为只能在当前进程分配到的CPU所关联的NUMA节点上进行分配，如果进程可以在所有的CPU上运行，（那就可以在所有的NUMA节点运行，这个设置就没有意义）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_HARDWALL0x100000u</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">___GFP_THISNODE 限制了内核分配内存的行为，只能在当前 NUMA 节点或者在指定 NUMA 节点中分配内存，如果内存分配失败不允许从其他备用 NUMA 节点中分配内存。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_THISNODE0x200000u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_ACCOUNT0x400000u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_ZEROTAGS0x800000u</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ___GFP_SKIP_KASAN_POISON0x1000000u</span></span><br></pre></td></tr></table></figure><p>将这些宏定义的值转为二进制就看到，每一种占一个bit位。使用掩码的时候做位运算即可</p><p><strong>没有<code>zone_normal</code>是因为默认的分配就是<code>zone_normal</code>。</strong></p><p>同样在<code>/include/linux/gfp.h</code>中定义了<code>gfp_zone</code>函数<strong>，函数返回此次内存分配中的最高的物理内存区域</strong>。较为新的5.14版本中相关代码可读性很差。</p><p>在2.6.24版本中，</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">enum</span> zone_type <span class="title function_">gfp_zone</span><span class="params">(<span class="type">gfp_t</span> flags)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> base = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_NUMA</span></span><br><span class="line"><span class="keyword">if</span> (flags &amp; __GFP_THISNODE)</span><br><span class="line"> base = MAX_NR_ZONES;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ZONE_DMA</span></span><br><span class="line"><span class="keyword">if</span> (flags &amp; __GFP_DMA)   <span class="comment">// flag中设置了__GFP_DMA,就只能在在ZONE_DMA中分配内存</span></span><br><span class="line"><span class="keyword">return</span> base + ZONE_DMA;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ZONE_DMA32</span></span><br><span class="line"><span class="keyword">if</span> (flags &amp; __GFP_DMA32) <span class="comment">// 同上</span></span><br><span class="line"><span class="keyword">return</span> base + ZONE_DMA32;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//如果要使用MOVABLE区域，那么在设置flag时，__GFP_HIGHMEM和__GFP_MOVABLE都要设置上</span></span><br><span class="line"><span class="keyword">if</span> ((flags &amp; (__GFP_HIGHMEM | __GFP_MOVABLE)) ==</span><br><span class="line">(__GFP_HIGHMEM | __GFP_MOVABLE)) </span><br><span class="line"><span class="keyword">return</span> base + ZONE_MOVABLE;</span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_HIGHMEM</span></span><br><span class="line"><span class="keyword">if</span> (flags &amp; __GFP_HIGHMEM) <span class="comment">// 只设置了__GFP_HIGHMEM</span></span><br><span class="line"><span class="keyword">return</span> base + ZONE_HIGHMEM;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"> <span class="comment">// 默认从 normal 区域中分配内存</span></span><br><span class="line"> <span class="keyword">return</span> base + ZONE_NORMAL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内核将一些常用的gfp_t掩码组合提前准备好了</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_ATOMIC (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_KERNEL (__GFP_RECLAIM | __GFP_IO | __GFP_FS)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_NOWAIT (__GFP_KSWAPD_RECLAIM)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_NOIO (__GFP_RECLAIM)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_NOFS (__GFP_RECLAIM | __GFP_IO)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_USER (__GFP_RECLAIM | __GFP_IO | __GFP_FS | __GFP_HARDWALL)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_DMA  __GFP_DMA</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_DMA32 __GFP_DMA32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GFP_HIGHUSER (GFP_USER | __GFP_HIGHMEM)</span></span><br></pre></td></tr></table></figure><ul><li><code>GFP_ATOMIC</code>表示分配行为是原子的，是高优先级的。如果内存空间不够，则会从紧急预留内存中分配。</li><li><code>GFP_KERNEL</code>设置之后内核的分配内存行为可能会阻塞睡眠，可以允许内核置换出一些不活跃的内存页到磁盘中。</li><li><code>GFP_NOIO</code> 和 <code>GFP_NOFS</code> 分别禁止内核在分配内存时进行磁盘 IO 和 文件系统 IO 操作。</li><li><code>GFP_HIGHUSER</code> 用于给用户空间分配高端内存。因为在用户虚拟空间中，都是通过页表来访问非直接映射的高端内存区域</li></ul><h2 id="物理内存分配内核源码实现"><a href="#物理内存分配内核源码实现" class="headerlink" title="物理内存分配内核源码实现"></a>物理内存分配内核源码实现</h2><h3 id="内存分配行为标识掩码"><a href="#内存分配行为标识掩码" class="headerlink" title="内存分配行为标识掩码"></a>内存分配行为标识掩码</h3><p>在内核文件 <code>/mm/internal.h</code> 中定义了影响内核分配行为的标识</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_WMARK_MIN     WMARK_MIN</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_WMARK_LOW     WMARK_LOW</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_WMARK_HIGH    WMARK_HIGH</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_NO_WATERMARKS 0x04 <span class="comment">/* don&#x27;t check watermarks at all */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_HARDER         0x10 <span class="comment">/* try to alloc harder */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_HIGH       0x20 <span class="comment">/* __GFP_HIGH set */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_CPUSET         0x40 <span class="comment">/* check for correct cpuset */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOC_KSWAPD        0x800 <span class="comment">/* allow waking of kswapd, __GFP_KSWAPD_RECLAIM set */</span></span></span><br></pre></td></tr></table></figure><ul><li><strong>ALLOC_NO_WATERMARKS：</strong> 表示在内存分配过程中完全不会考虑min、low、high三个水位线的影响。</li><li><strong>ALLOC_WMARK_HIGH：</strong> 表示在内存分配的时候，当前物理内存区域 zone 中剩余内存页的数量至少要达到 _watermark[WMARK_HIGH] 水位线，才能进行内存的分配。</li><li>ALLOC_WMARK_LOW 和 ALLOC_WMARK_MIN 要表达的内存分配语义也是一样，当前物理内存区域 zone 中剩余内存页的数量至少要达到水位线 _watermark[WMARK_LOW]  或者 _watermark[WMARK_MIN]，才能进行内存的分配。</li><li><strong>ALLOC_HARDER：</strong> 表示在内存分配的时候，会放宽内存分配规则的限制，所谓的放宽规则就是降低 _watermark[WMARK_MIN] 水位线，努力使内存分配最大可能成功。</li><li><strong>ALLOC_HIGH：</strong>当我们在 gfp_t 掩码中设置了 ___GFP_HIGH 时，ALLOC_HIGH 标识才起作用，该标识表示当前内存分配请求是高优先级的，内核急切的需要内存</li><li><strong>ALLOC_CPUSET：</strong> 表示内存只能在当前进程所允许运行的 CPU 所关联的 NUMA 节点中进行分配。</li><li><strong>ALLOC_KSWAPD：</strong> 表示允许唤醒 NUMA 节点中的 KSWAPD 进程，异步进行内存回收。</li></ul><h3 id="内存分配的心脏-alloc-pages"><a href="#内存分配的心脏-alloc-pages" class="headerlink" title="内存分配的心脏 __alloc_pages"></a>内存分配的心脏 __alloc_pages</h3><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312311647985" alt="图片"></p><p>内存分配的任务最终会落在 <code>alloc_pages</code> 这个接口函数中，在 <code>alloc_pages</code> 中会调用 <code>alloc_pages_node</code> 进而调用 alloc_pages_node 函数，最终通过 <code>alloc_pages</code> 函数正式进入内核内存分配。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> *__<span class="title">alloc_pages</span>(<span class="title">gfp_t</span> <span class="title">gfp</span>, <span class="title">unsigned</span> <span class="title">int</span> <span class="title">order</span>, <span class="title">int</span> <span class="title">preferred_nid</span>,</span></span><br><span class="line"><span class="class"><span class="title">nodemask_t</span> *<span class="title">nodemask</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page</span>;</span></span><br><span class="line"><span class="comment">// 内存区域中的剩余内存需要在 WMARK_LOW 水位线之上才能进行内存分配，否则失败（初次尝试快速内存分配）</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> alloc_flags = ALLOC_WMARK_LOW;</span><br><span class="line"><span class="type">gfp_t</span> alloc_gfp; <span class="comment">/* The gfp_t that was actually used for allocation */</span></span><br><span class="line"><span class="comment">// alloc_context用于保存在分配过程中的一些不可变的参数，比如nodemask、页面迁移类型、最高可分配的内存区域，这些</span></span><br><span class="line"><span class="comment">//在分配过程中只用初始化一次（不会变的），而像zonelist、prefer_zone等在初始化之后，可能会在__alloc_pages_slowpath()中改变</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">alloc_context</span> <span class="title">ac</span> =</span> &#123; &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// order只能从0-10,unlikely告诉编译器这个判断不经常发生，用于编译优化</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(order &gt;= MAX_ORDER)) &#123; </span><br><span class="line">WARN_ON_ONCE(!(gfp &amp; __GFP_NOWARN));</span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 表示在内存分配期间进程可以休眠阻塞</span></span><br><span class="line">gfp &amp;= gfp_allowed_mask;</span><br><span class="line"><span class="comment">// 使用函数，设置内存分配时允不允许进行io操作、允不允许进行文件系统的操作、允不允许使用可移动内存</span></span><br><span class="line"><span class="comment">// 并修改gfp中对应的标志位</span></span><br><span class="line">gfp = current_gfp_context(gfp);</span><br><span class="line">alloc_gfp = gfp;</span><br><span class="line"><span class="comment">// 初始化 alloc_context，并为接下来的快速内存分配设置相关 gfp</span></span><br><span class="line"><span class="keyword">if</span> (!prepare_alloc_pages(gfp, order, preferred_nid, nodemask, &amp;ac,</span><br><span class="line">&amp;alloc_gfp, &amp;alloc_flags))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    </span><br><span class="line">alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 内存分配快速路径：第一次尝试从底层伙伴系统分配内存，注意此时是在 WMARK_LOW 水位线之上分配内存</span></span><br><span class="line">page = get_page_from_freelist(alloc_gfp, order, alloc_flags, &amp;ac);</span><br><span class="line"><span class="keyword">if</span> (likely(page))</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">alloc_gfp = gfp;</span><br><span class="line">ac.spread_dirty_pages = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">ac.nodemask = nodemask;</span><br><span class="line"></span><br><span class="line">page = __alloc_pages_slowpath(alloc_gfp, order, &amp;ac);</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line"><span class="keyword">if</span> (memcg_kmem_enabled() &amp;&amp; (gfp &amp; __GFP_ACCOUNT) &amp;&amp; page &amp;&amp;</span><br><span class="line">    unlikely(__memcg_kmem_charge_page(page, gfp, order) != <span class="number">0</span>)) &#123;</span><br><span class="line">__free_pages(page, order);</span><br><span class="line">page = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trace_mm_page_alloc(page, order, alloc_gfp, ac.migratetype);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__alloc_pages);</span><br></pre></td></tr></table></figure><p>上述代码的整体逻辑如下：</p><ul><li><p>首先尝试在内存水位线VMARK_LOW之上进行一次内存分配，对应<code>unsigned int alloc_flags = ALLOC_WMARK_LOW</code></p></li><li><p>校验本次内存分配指定伙伴系统的分配阶 order 的有效性,对应<code>if (unlikely(order &gt;= MAX_ORDER))</code></p></li><li><p>调用 prepare_alloc_pages 初始化 alloc_context ，用于在不同内存分配辅助函数中传递内存分配参数。为接下来即将进行的快速内存分配做准备。</p></li><li><p>调用 get_page_from_freelist 方法首次尝试在伙伴系统中进行内存分配</p></li><li><p>当快速内存分配失败之后，情况就会变得非常复杂，内核将不得不做更多的工作，比如开启 kswapd 进程异步内存回收，更极端的情况则需要进行直接内存回收，或者直接内存整理以获取更多的空闲连续内存。这一切的复杂逻辑全部封装在 __alloc_pages_slowpath 函数中。</p></li></ul><p>整个过程中，有三个重要函数：</p><p><code>prepare_alloc_pages</code>函数用于初始化内存分配策略。</p><p><code>alloc_pages_slowpath</code>函数在初次快速分配失败后，进行慢速分配</p><p><code>get_page_from_freelist</code>函数用于在伙伴系统中进行内存分配。</p><p>本次博客先介绍前两个函数</p><h3 id="prepare-alloc-pages函数"><a href="#prepare-alloc-pages函数" class="headerlink" title="prepare_alloc_pages函数"></a>prepare_alloc_pages函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">prepare_alloc_pages</span><span class="params">(<span class="type">gfp_t</span> gfp_mask, <span class="type">unsigned</span> <span class="type">int</span> order,</span></span><br><span class="line"><span class="params"><span class="type">int</span> preferred_nid, <span class="type">nodemask_t</span> *nodemask,</span></span><br><span class="line"><span class="params"><span class="keyword">struct</span> alloc_context *ac, <span class="type">gfp_t</span> *alloc_gfp,</span></span><br><span class="line"><span class="params"><span class="type">unsigned</span> <span class="type">int</span> *alloc_flags)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 从gfp_mask中获取内存分配最高优先级的区域zone</span></span><br><span class="line">ac-&gt;highest_zoneidx = gfp_zone(gfp_mask);  </span><br><span class="line"><span class="comment">// 从 NUMA 节点的备用节点链表中一次性获取允许进行内存分配的所有内存区域</span></span><br><span class="line">ac-&gt;zonelist = node_zonelist(preferred_nid, gfp_mask);</span><br><span class="line">ac-&gt;nodemask = nodemask;</span><br><span class="line">ac-&gt;migratetype = gfp_migratetype(gfp_mask);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cpusets_enabled()) &#123;</span><br><span class="line">*alloc_gfp |= __GFP_HARDWALL;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * When we are in the interrupt context, it is irrelevant</span></span><br><span class="line"><span class="comment"> * to the current task context. It means that any node ok.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (in_task() &amp;&amp; !ac-&gt;nodemask)</span><br><span class="line">ac-&gt;nodemask = &amp;cpuset_current_mems_allowed;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">*alloc_flags |= ALLOC_CPUSET;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fs_reclaim_acquire(gfp_mask);</span><br><span class="line">fs_reclaim_release(gfp_mask);</span><br><span class="line"><span class="comment">// 如果设置了允许直接内存回收，那么内存分配进程则可能会导致休眠被重新调度 </span></span><br><span class="line">might_sleep_if(gfp_mask &amp; __GFP_DIRECT_RECLAIM);</span><br><span class="line"><span class="comment">// 提前判断本次内存分配是否能够成功，如果不能则尽早失败</span></span><br><span class="line"><span class="keyword">if</span> (should_fail_alloc_page(gfp_mask, order))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">*alloc_flags = gfp_to_alloc_flags_cma(gfp_mask, *alloc_flags);</span><br><span class="line"></span><br><span class="line">ac-&gt;spread_dirty_pages = (gfp_mask &amp; __GFP_WRITE);</span><br><span class="line"></span><br><span class="line">ac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,</span><br><span class="line">ac-&gt;highest_zoneidx, ac-&gt;nodemask);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>prepare_alloc_pages 主要的任务就是在快速内存分配开始之前，做一些准备初始化的工作，其中最核心的就是从指定 NUMA 节点中，根据  gfp_mask 掩码中的内存区域修饰符获取可以进行内存分配的所有内存区域 zone （包括其他备用 NUMA 节点中包含的内存区域）。</p><h3 id="alloc-pages-slowpath函数"><a href="#alloc-pages-slowpath函数" class="headerlink" title="alloc_pages_slowpath函数"></a>alloc_pages_slowpath函数</h3><p><code>alloc_pages_slowpath</code> 函数非常的复杂，其中包含了内存分配的各种异常情况的处理，并且会根据前边介绍的 <code>GFP_</code>，<code>ALLOC</code> 等各种内存分配策略掩码进行不同分支的处理，这样就变得非常的庞大而繁杂。</p><p>其基本逻辑如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="class"><span class="keyword">struct</span> <span class="title">page</span> *</span></span><br><span class="line"><span class="class">__<span class="title">alloc_pages_slowpath</span>(<span class="title">gfp_t</span> <span class="title">gfp_mask</span>, <span class="title">unsigned</span> <span class="title">int</span> <span class="title">order</span>,</span></span><br><span class="line"><span class="class">                        <span class="keyword">struct</span> <span class="title">alloc_context</span> *<span class="title">ac</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">        ......... 初始化慢速内存分配路径下的相关参数 .......</span><br><span class="line"></span><br><span class="line">retry_cpuset:</span><br><span class="line"></span><br><span class="line">        ......... 调整内存分配策略 alloc_flags 采用更加激进方式获取内存 ......</span><br><span class="line">        ......... 此时内存分配主要是在进程所允许运行的 CPU 相关联的 NUMA 节点上 ......</span><br><span class="line">        ......... 内存水位线下调至 WMARK_MIN ...........</span><br><span class="line">        ......... 唤醒所有 kswapd 进程进行异步内存回收  ...........</span><br><span class="line">        ......... 触发直接内存整理 direct_compact 来获取更多的连续空闲内存 ......</span><br><span class="line"></span><br><span class="line">retry:</span><br><span class="line"></span><br><span class="line">        ......... 进一步调整内存分配策略 alloc_flags 使用更加激进的非常手段进行内存分配 ...........</span><br><span class="line">        ......... 在内存分配时忽略内存水位线 ...........</span><br><span class="line">        ......... 触发直接内存回收 direct_reclaim ...........</span><br><span class="line">        ......... 再次触发直接内存整理 direct_compact ...........</span><br><span class="line">        ......... 最后的杀手锏触发 OOM 机制  ...........</span><br><span class="line"></span><br><span class="line">nopage:</span><br><span class="line">        ......... 经过以上激进的内存分配手段仍然无法满足内存分配就会来到这里 ......</span><br><span class="line">        ......... 如果设置了 __GFP_NOFAIL 不允许内存分配失败，则不停重试上述内存分配过程 ......</span><br><span class="line"></span><br><span class="line">fail:</span><br><span class="line">        ......... 内存分配失败，输出告警信息 ........</span><br><span class="line"></span><br><span class="line">      warn_alloc(gfp_mask, ac-&gt;nodemask,</span><br><span class="line">            <span class="string">&quot;page allocation failure: order:%u&quot;</span>, order);</span><br><span class="line">got_pg:</span><br><span class="line">        ......... 内存分配成功，返回新申请的内存块 ........</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>源代码分析</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="class"><span class="keyword">struct</span> <span class="title">page</span> *</span></span><br><span class="line"><span class="class">__<span class="title">alloc_pages_slowpath</span>(<span class="title">gfp_t</span> <span class="title">gfp_mask</span>, <span class="title">unsigned</span> <span class="title">int</span> <span class="title">order</span>,</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">alloc_context</span> *<span class="title">ac</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">初始化慢速内存分配路径下的相关参数</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">bool</span> can_direct_reclaim = gfp_mask &amp; __GFP_DIRECT_RECLAIM;</span><br><span class="line"><span class="comment">//order大于3时，即分配8个页面时，认为这个分配是costly的，后续会根据 costly_order决定是否触发 OOM </span></span><br><span class="line"><span class="type">const</span> <span class="type">bool</span> costly_order = order &gt; PAGE_ALLOC_COSTLY_ORDER;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page</span> =</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="comment">// 内存分配标识符</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> alloc_flags;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">当内存严重不足的时候，内核会开启直接内存回收 direct_reclaim，</span></span><br><span class="line"><span class="comment">参数 did_some_progress 表示经过一次直接内存回收之后，内核回收了多少个内存页</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> did_some_progress;</span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">compact_priority</span> <span class="title">compact_priority</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">compact_result</span> <span class="title">compact_result</span>;</span></span><br><span class="line"><span class="type">int</span> compaction_retries;</span><br><span class="line">    <span class="comment">// 记录重试的次数，超过16次就内存分配失败</span></span><br><span class="line"><span class="type">int</span> no_progress_loops;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> cpuset_mems_cookie;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> zonelist_iter_cookie;</span><br><span class="line">    <span class="comment">// 临时保存调整后的内存分配策略</span></span><br><span class="line"><span class="type">int</span> reserve_flags;</span><br><span class="line">    <span class="comment">/* 当ATOMIC和DIRECT_RECLAIM同时设置时，取消对ATOMIC的设置</span></span><br><span class="line"><span class="comment">    因为接下来的直接内存回收非常耗时可能会导致进程阻塞睡眠，不适用原子__GFP_ATOMIC</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="keyword">if</span> (WARN_ON_ONCE((gfp_mask &amp; (__GFP_ATOMIC|__GFP_DIRECT_RECLAIM)) ==</span><br><span class="line">(__GFP_ATOMIC|__GFP_DIRECT_RECLAIM)))</span><br><span class="line">gfp_mask &amp;= ~__GFP_ATOMIC;</span><br><span class="line"></span><br><span class="line">restart:</span><br><span class="line">compaction_retries = <span class="number">0</span>;</span><br><span class="line">no_progress_loops = <span class="number">0</span>;</span><br><span class="line">compact_priority = DEF_COMPACT_PRIORITY;</span><br><span class="line">cpuset_mems_cookie = read_mems_allowed_begin();</span><br><span class="line">zonelist_iter_cookie = zonelist_iter_begin();</span><br><span class="line"><span class="comment">// 在慢速内存分配路径下需要重新设置更加激进的内存分配策略，采用更大的代价来分配内存</span></span><br><span class="line">alloc_flags = gfp_to_alloc_flags(gfp_mask);</span><br><span class="line"><span class="comment">// 重新按照新的设置按照内存区域优先级计算 zonelist 的迭代起点（最高优先级的 zone）</span></span><br><span class="line">ac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,</span><br><span class="line">ac-&gt;highest_zoneidx, ac-&gt;nodemask);</span><br><span class="line"><span class="keyword">if</span> (!ac-&gt;preferred_zoneref-&gt;zone)</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line"><span class="comment">// 唤醒所有的 kswapd 进程异步回收内存</span></span><br><span class="line"><span class="keyword">if</span> (alloc_flags &amp; ALLOC_KSWAPD) </span><br><span class="line">wake_all_kswapds(order, gfp_mask, ac);</span><br><span class="line"><span class="comment">// 在对alloc_flags调整后，重新尝试页面分配</span></span><br><span class="line">page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*配大内存来说 costly_order = true (超过 8 个内存页)，需要首先进行内存整理，这样内核可以避免直接内存回收从而获取更多的连续空闲内存页；</span></span><br><span class="line"><span class="comment">    对于需要分配不可移动的高阶内存的情况，也需要先进行内存整理，防止永久内存碎片*/</span></span><br><span class="line"><span class="keyword">if</span> (can_direct_reclaim &amp;&amp;</span><br><span class="line">(costly_order ||</span><br><span class="line">   (order &gt; <span class="number">0</span> &amp;&amp; ac-&gt;migratetype != MIGRATE_MOVABLE))</span><br><span class="line">&amp;&amp; !gfp_pfmemalloc_allowed(gfp_mask)) &#123;</span><br><span class="line">        <span class="comment">// 进行直接内存整理，获取更多的连续空间内存防止内存碎片</span></span><br><span class="line">page = __alloc_pages_direct_compact(gfp_mask, order,</span><br><span class="line">alloc_flags, ac,</span><br><span class="line">INIT_COMPACT_PRIORITY,</span><br><span class="line">&amp;compact_result);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (costly_order &amp;&amp; (gfp_mask &amp; __GFP_NORETRY)) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (compact_result == COMPACT_SKIPPED ||</span><br><span class="line">    compact_result == COMPACT_DEFERRED)</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line">compact_priority = INIT_COMPACT_PRIORITY;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">retry:</span><br><span class="line"><span class="keyword">if</span> (alloc_flags &amp; ALLOC_KSWAPD)  <span class="comment">// 确保所有 kswapd 进程不要意外进入睡眠状态</span></span><br><span class="line">wake_all_kswapds(order, gfp_mask, ac);</span><br><span class="line"><span class="comment">// 忽略掉内存水位线，继续修改 alloc_flags 保存在 reserve_flags 中</span></span><br><span class="line">reserve_flags = __gfp_pfmemalloc_flags(gfp_mask);</span><br><span class="line"><span class="keyword">if</span> (reserve_flags)</span><br><span class="line">alloc_flags = gfp_to_alloc_flags_cma(gfp_mask, reserve_flags);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!(alloc_flags &amp; ALLOC_CPUSET) || reserve_flags) &#123;</span><br><span class="line">ac-&gt;nodemask = <span class="literal">NULL</span>;</span><br><span class="line">ac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,</span><br><span class="line">ac-&gt;highest_zoneidx, ac-&gt;nodemask);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Attempt with potentially adjusted zonelist and alloc_flags */</span></span><br><span class="line">page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断允不允许直接回收</span></span><br><span class="line"><span class="keyword">if</span> (!can_direct_reclaim)</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 避免直接回收的递归</span></span><br><span class="line"><span class="keyword">if</span> (current-&gt;flags &amp; PF_MEMALLOC)</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 尝试直接内存回收</span></span><br><span class="line">page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,</span><br><span class="line">&amp;did_some_progress);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果还是没有足够的内存可供分配的话，那么内核会再次进行直接内存整理 direct_compact</span></span><br><span class="line">page = __alloc_pages_direct_compact(gfp_mask, order, alloc_flags, ac,</span><br><span class="line">compact_priority, &amp;compact_result);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Do not loop if specifically requested */</span></span><br><span class="line"><span class="keyword">if</span> (gfp_mask &amp; __GFP_NORETRY) <span class="comment">// 内存分配失败时，不允许重试</span></span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 当此次分配超过8个页时，就不会触发OOM，除非没有设置__GFP_RETRY_MAYFAIL</span></span><br><span class="line"><span class="keyword">if</span> (costly_order &amp;&amp; !(gfp_mask &amp; __GFP_RETRY_MAYFAIL))</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">如果内核已经重试了MAX_RECLAIM_RETRIES(16)次仍然失败，则放弃重试，执行后续OOM</span></span><br><span class="line"><span class="comment">如果内核将所有可选内存区域中的所有可回收页面全部回收之后，仍然无法满足内存分配，那么放弃重试，执行后续OOM</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">if</span> (should_reclaim_retry(gfp_mask, order, ac, alloc_flags,</span><br><span class="line"> did_some_progress &gt; <span class="number">0</span>, &amp;no_progress_loops))</span><br><span class="line"><span class="keyword">goto</span> retry;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果经过回收后，did_some_progress = 0,则没有必要进行内存整理的重试了</span></span><br><span class="line"><span class="keyword">if</span> (did_some_progress &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">should_compact_retry(ac, order, alloc_flags,</span><br><span class="line">compact_result, &amp;compact_priority,</span><br><span class="line">&amp;compaction_retries))</span><br><span class="line"><span class="keyword">goto</span> retry;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Deal with possible cpuset update races or zonelist updates to avoid</span></span><br><span class="line"><span class="comment"> * a unnecessary OOM kill.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (check_retry_cpuset(cpuset_mems_cookie, ac) ||</span><br><span class="line">    check_retry_zonelist(zonelist_iter_cookie))</span><br><span class="line"><span class="keyword">goto</span> restart;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进行 OOM，选择一个得分最高的进程，释放其占用的内存 </span></span><br><span class="line">page = __alloc_pages_may_oom(gfp_mask, order, ac, &amp;did_some_progress);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Avoid allocations with no watermarks from looping endlessly */</span></span><br><span class="line"><span class="keyword">if</span> (tsk_is_oom_victim(current) &amp;&amp;</span><br><span class="line">    (alloc_flags &amp; ALLOC_OOM ||</span><br><span class="line">     (gfp_mask &amp; __GFP_NOMEMALLOC)))</span><br><span class="line"><span class="keyword">goto</span> nopage;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只要 oom 产生了作用并释放了内存 did_some_progress &gt; 0 就不断的进行重试</span></span><br><span class="line"><span class="keyword">if</span> (did_some_progress) &#123;</span><br><span class="line">no_progress_loops = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">goto</span> retry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">nopage:</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Deal with possible cpuset update races or zonelist updates to avoid</span></span><br><span class="line"><span class="comment"> * a unnecessary OOM kill.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (check_retry_cpuset(cpuset_mems_cookie, ac) ||</span><br><span class="line">    check_retry_zonelist(zonelist_iter_cookie))</span><br><span class="line"><span class="keyword">goto</span> restart;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Make sure that __GFP_NOFAIL request doesn&#x27;t leak out and make sure</span></span><br><span class="line"><span class="comment"> * we always retry</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//流程走到这里表明内核已经尝试了包括 OOM 在内的所有回收内存的动作。</span></span><br><span class="line"><span class="comment">// 但是这些措施依然无法满足内存分配的需求，看上去内存分配到这里就应该失败了。</span></span><br><span class="line"><span class="comment">// 但是如果设置了 __GFP_NOFAIL 表示不允许内存分配失败，那么接下来就会进入 if 分支进行处理</span></span><br><span class="line"><span class="keyword">if</span> (gfp_mask &amp; __GFP_NOFAIL) &#123;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * All existing users of the __GFP_NOFAIL are blockable, so warn</span></span><br><span class="line"><span class="comment"> * of any new users that actually require GFP_NOWAIT</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (WARN_ON_ONCE(!can_direct_reclaim))</span><br><span class="line"><span class="keyword">goto</span> fail;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * PF_MEMALLOC request from this context is rather bizarre</span></span><br><span class="line"><span class="comment"> * because we cannot reclaim anything and only can loop waiting</span></span><br><span class="line"><span class="comment"> * for somebody to do a work for us</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">WARN_ON_ONCE(current-&gt;flags &amp; PF_MEMALLOC);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * non failing costly orders are a hard requirement which we</span></span><br><span class="line"><span class="comment"> * are not prepared for much so let&#x27;s warn about these users</span></span><br><span class="line"><span class="comment"> * so that we can identify them and convert them to something</span></span><br><span class="line"><span class="comment"> * else.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">WARN_ON_ONCE(order &gt; PAGE_ALLOC_COSTLY_ORDER);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Help non-failing allocations by giving them access to memory</span></span><br><span class="line"><span class="comment"> * reserves but do not use ALLOC_NO_WATERMARKS because this</span></span><br><span class="line"><span class="comment"> * could deplete whole memory reserves which would just make</span></span><br><span class="line"><span class="comment"> * the situation worse</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 尝试进行跨NUMA节点的内存分配</span></span><br><span class="line">page = __alloc_pages_cpuset_fallback(gfp_mask, order, ALLOC_HARDER, ac);</span><br><span class="line"><span class="keyword">if</span> (page)</span><br><span class="line"><span class="keyword">goto</span> got_pg;</span><br><span class="line"> <span class="comment">/* </span></span><br><span class="line"><span class="comment">在进行内存分配重试流程之前，使用cond_resched()让 CPU 重新调度到其他进程上</span></span><br><span class="line"><span class="comment">        运行一会其他进程，因为毕竟此时内存已经严重不足</span></span><br><span class="line"><span class="comment">        立马重试的话只能浪费过多时间在搜索空闲内存上，导致其他进程处于饥饿状态。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">cond_resched();</span><br><span class="line"><span class="keyword">goto</span> retry;</span><br><span class="line">&#125;</span><br><span class="line">fail:</span><br><span class="line">warn_alloc(gfp_mask, ac-&gt;nodemask,</span><br><span class="line"><span class="string">&quot;page allocation failure: order:%u&quot;</span>, order);</span><br><span class="line">got_pg:</span><br><span class="line"><span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">prepare_alloc_pages</span><span class="params">(<span class="type">gfp_t</span> gfp_mask, <span class="type">unsigned</span> <span class="type">int</span> order,</span></span><br><span class="line"><span class="params"><span class="type">int</span> preferred_nid, <span class="type">nodemask_t</span> *nodemask,</span></span><br><span class="line"><span class="params"><span class="keyword">struct</span> alloc_context *ac, <span class="type">gfp_t</span> *alloc_gfp,</span></span><br><span class="line"><span class="params"><span class="type">unsigned</span> <span class="type">int</span> *alloc_flags)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 从gfp_mask中获取内存分配最高优先级的区域zone</span></span><br><span class="line">ac-&gt;highest_zoneidx = gfp_zone(gfp_mask);  </span><br><span class="line"><span class="comment">// 从 NUMA 节点的备用节点链表中一次性获取允许进行内存分配的所有内存区域</span></span><br><span class="line">ac-&gt;zonelist = node_zonelist(preferred_nid, gfp_mask);</span><br><span class="line">ac-&gt;nodemask = nodemask;</span><br><span class="line">ac-&gt;migratetype = gfp_migratetype(gfp_mask);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cpusets_enabled()) &#123;</span><br><span class="line">*alloc_gfp |= __GFP_HARDWALL;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * When we are in the interrupt context, it is irrelevant</span></span><br><span class="line"><span class="comment"> * to the current task context. It means that any node ok.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (in_task() &amp;&amp; !ac-&gt;nodemask)</span><br><span class="line">ac-&gt;nodemask = &amp;cpuset_current_mems_allowed;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">*alloc_flags |= ALLOC_CPUSET;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fs_reclaim_acquire(gfp_mask);</span><br><span class="line">fs_reclaim_release(gfp_mask);</span><br><span class="line"><span class="comment">// 如果设置了允许直接内存回收，那么内存分配进程则可能会导致休眠被重新调度 </span></span><br><span class="line">might_sleep_if(gfp_mask &amp; __GFP_DIRECT_RECLAIM);</span><br><span class="line"><span class="comment">// 提前判断本次内存分配是否能够成功，如果不能则尽早失败</span></span><br><span class="line"><span class="keyword">if</span> (should_fail_alloc_page(gfp_mask, order))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">*alloc_flags = gfp_to_alloc_flags_cma(gfp_mask, *alloc_flags);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Dirty zone balancing only done in the fast path */</span></span><br><span class="line">ac-&gt;spread_dirty_pages = (gfp_mask &amp; __GFP_WRITE);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The preferred zone is used for statistics but crucially it is</span></span><br><span class="line"><span class="comment"> * also used as the starting point for the zonelist iterator. It</span></span><br><span class="line"><span class="comment"> * may get reset for allocations that ignore memory policies.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">ac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,</span><br><span class="line">ac-&gt;highest_zoneidx, ac-&gt;nodemask);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中相关的几个函数：</p><p><strong><code>gfp_to_alloc_flags</code>函数更改分配策略</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">unsigned</span> <span class="type">int</span></span><br><span class="line"><span class="title function_">gfp_to_alloc_flags</span><span class="params">(<span class="type">gfp_t</span> gfp_mask)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> alloc_flags = ALLOC_WMARK_MIN | ALLOC_CPUSET;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * __GFP_HIGH is assumed to be the same as ALLOC_HIGH</span></span><br><span class="line"><span class="comment"> * and __GFP_KSWAPD_RECLAIM is assumed to be the same as ALLOC_KSWAPD</span></span><br><span class="line"><span class="comment"> * to save two branches.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">BUILD_BUG_ON(__GFP_HIGH != (__force <span class="type">gfp_t</span>) ALLOC_HIGH);</span><br><span class="line">BUILD_BUG_ON(__GFP_KSWAPD_RECLAIM != (__force <span class="type">gfp_t</span>) ALLOC_KSWAPD);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The caller may dip into page reserves a bit more if the caller</span></span><br><span class="line"><span class="comment"> * cannot run direct reclaim, or if the caller has realtime scheduling</span></span><br><span class="line"><span class="comment"> * policy or is asking for __GFP_HIGH memory.  GFP_ATOMIC requests will</span></span><br><span class="line"><span class="comment"> * set both ALLOC_HARDER (__GFP_ATOMIC) and ALLOC_HIGH (__GFP_HIGH).</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">alloc_flags |= (__force <span class="type">int</span>)</span><br><span class="line">(gfp_mask &amp; (__GFP_HIGH | __GFP_KSWAPD_RECLAIM));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果内存分配是原子的话，则在内存不够的时候，可以从紧急预留内存中分配</span></span><br><span class="line"><span class="keyword">if</span> (gfp_mask &amp; __GFP_ATOMIC) &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">__GFP_NOMEMALLOC表示禁止从紧急预留的内存中分配，优先级比__GFP_MEMALLOC高，</span></span><br><span class="line"><span class="comment"> 因此这里是与__GFP_NOMEMALLOC做与操作</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">if</span> (!(gfp_mask &amp; __GFP_NOMEMALLOC))</span><br><span class="line">alloc_flags |= ALLOC_HARDER; <span class="comment">//后续根据 ALLOC_HARDER 标识会降低 WMARK_LOW 水位线</span></span><br><span class="line"> <span class="comment">// 这种情况下为了内存分配的成功，会去除掉 CPUSET 的限制，可以在所有 NUMA 节点上分配内存</span></span><br><span class="line">alloc_flags &amp;= ~ALLOC_CPUSET;</span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">// 如果当前进程是实时任务（可能不太可能发生的情况），并且在任务的上下文中,设置header</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (unlikely(rt_task(current)) &amp;&amp; in_task())</span><br><span class="line">alloc_flags |= ALLOC_HARDER;</span><br><span class="line"></span><br><span class="line">alloc_flags = gfp_to_alloc_flags_cma(gfp_mask, alloc_flags);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> alloc_flags;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong><code>__gfp_pfmemalloc_flags</code>函数</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">int</span> __gfp_pfmemalloc_flags(<span class="type">gfp_t</span> gfp_mask)</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 如果不允许从紧急预留内存中分配，就不改变alloc_flag</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(gfp_mask &amp; __GFP_NOMEMALLOC)) </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 如果允许从紧急预留内存中分配，则后面的内存分配会忽略内存水位线的限制</span></span><br><span class="line"><span class="keyword">if</span> (gfp_mask &amp; __GFP_MEMALLOC)</span><br><span class="line"><span class="keyword">return</span> ALLOC_NO_WATERMARKS;</span><br><span class="line"><span class="comment">// 当前进程处于软中断上下文并且进程设置了 PF_MEMALLOC 标识</span></span><br><span class="line"><span class="keyword">if</span> (in_serving_softirq() &amp;&amp; (current-&gt;flags &amp; PF_MEMALLOC))</span><br><span class="line"><span class="keyword">return</span> ALLOC_NO_WATERMARKS;</span><br><span class="line"><span class="comment">// 当前进程不在任何中断上下文中</span></span><br><span class="line"><span class="keyword">if</span> (!in_interrupt()) &#123;</span><br><span class="line"><span class="keyword">if</span> (current-&gt;flags &amp; PF_MEMALLOC)</span><br><span class="line"><span class="keyword">return</span> ALLOC_NO_WATERMARKS;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (oom_reserves_allowed(current)) <span class="comment">// 当前进程允许进行 OOM</span></span><br><span class="line"><span class="keyword">return</span> ALLOC_OOM;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内存分配流程图：</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312311639085.png" alt="640 (2)"></p>]]></content>
      
      
      <categories>
          
          <category> Linux内核 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟内存管理(源码阅读1)</title>
      <link href="/2023/12/25/Linux%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86(%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB1)/"/>
      <url>/2023/12/25/Linux%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86(%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB1)/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么使用虚拟内存"><a href="#为什么使用虚拟内存" class="headerlink" title="为什么使用虚拟内存"></a>为什么使用虚拟内存</h2><p>一句话：引入虚拟内存后，进程与进程之间的虚拟内存地址空间是相互隔离，互不干扰的。</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251453156.png" alt="640"></p><h2 id="虚拟内存地址格式"><a href="#虚拟内存地址格式" class="headerlink" title="虚拟内存地址格式"></a>虚拟内存地址格式</h2><p>都以4K为基本页框大小</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251455900.png" alt="image-20231225145536867"></p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251455383.png" alt="image-20231225145517347"></p><h2 id="进程的虚拟内存空间"><a href="#进程的虚拟内存空间" class="headerlink" title="进程的虚拟内存空间"></a>进程的虚拟内存空间</h2><h3 id="用户空间"><a href="#用户空间" class="headerlink" title="用户空间"></a>用户空间</h3><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251458277.png" alt="640 (1)"></p><ul><li>用于存放进程程序二进制文件中的机器指令的代码段</li><li>用于存放程序二进制文件中定义的全局变量和静态变量的数据段和 BSS 段。其中数据段中为指定了初始值的全局变量和静态变量；BSS段中为为指定初始值的全局变量和静态变量（初始化为0）</li><li>用于在程序运行过程中动态申请内存的堆。堆空间中地址的增长方向是从低地址到高地址增长。</li><li>用于存放动态链接库以及内存映射区域的文件映射与匿名映射区。</li><li>用于存放函数调用过程中的局部变量和函数参数的栈。</li></ul><h3 id="虚拟内存空间分布"><a href="#虚拟内存空间分布" class="headerlink" title="虚拟内存空间分布"></a>虚拟内存空间分布</h3><p>虚拟内存空间包括用户态和内核态。</p><h4 id="32位机器"><a href="#32位机器" class="headerlink" title="32位机器"></a>32位机器</h4><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251503730.png" alt="640 (2)"></p><p>用户态虚拟内存空间中的代码段并不是从 0x0000 0000 地址开始的，而是从 0x0804 8000 地址开始。</p><p>0x0000 0000 到 0x0804 8000 这段虚拟内存地址是一段不可访问的保留区，因为在大多数操作系统中，数值比较小的地址通常被认为不是一个合法的地址，这块小地址是不允许访问的。比如在 C 语言中我们通常会将一些无效的指针设置为 NULL，指向这块不允许访问的地址。</p><p>BSS 段的上边就是我们经常使用到的堆空间，从图中的红色箭头我们可以知道在<strong>堆空间中地址的增长方向是从低地址到高地址增长</strong>。</p><p>内核中使用 start_brk 标识堆的起始位置，brk 标识堆当前的结束位置。当堆申请新的内存空间时，只需要将 brk 指针增加对应的大小，回收地址时减少对应的大小即可。比如当我们通过 malloc 向内核申请很小的一块内存时（128K 之内），就是通过改变 brk 位置实现的。</p><p>堆空间的上边是一段待分配区域，用于扩展堆空间的使用。</p><p>接下来就来到了文件映射与匿名映射区域。<strong>在文件映射与匿名映射区的地址增长方向是从高地址向低地址增长</strong>。</p><p>接下来用户态虚拟内存空间的最后一块区域就是栈空间了，在这里会保存函数运行过程所需要的局部变量以及函数参数等函数调用信息。<strong>栈空间中的地址增长方向是从高地址向低地址增长</strong>。</p><p>在内核中使用 start_stack 标识栈的起始位置，RSP 寄存器中保存栈顶指针 stack pointer，RBP 寄存器中保存的是栈基地址。在栈空间的下边也有一段待分配区域用于扩展栈空间。</p><h4 id="64位机器"><a href="#64位机器" class="headerlink" title="64位机器"></a>64位机器</h4><p>虽然64位机器的指针寻址范围是2^64,但是在目前的 64 位系统下只使用了 <strong>48 位来描述虚拟内存空间</strong>，寻址范围为  2^48 ，所能表达的虚拟内存空间为 256TB。</p><p>其中低 128 T 表示用户态虚拟内存空间，虚拟内存地址范围为：0x0000 0000 0000 0000  - 0x0000 7FFF FFFF F000 。</p><p>高 128 T 表示内核态虚拟内存空间，虚拟内存地址范围为：0xFFFF 8000 0000 0000  - 0xFFFF FFFF FFFF FFFF 。</p><p>这样一来就在用户态虚拟内存空间与内核态虚拟内存空间之间形成了一段 0x0000 7FFF FFFF F000  -  0xFFFF 8000 0000 0000  的地址空洞，我们把这个空洞叫做 canonical address 空洞</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251733199.png" alt="640 (4)"></p><p>如上图，还可以看到：在代码段跟数据段的中间还有一段不可以读写的保护段，它的作用是防止程序在读写数据段的时候越界访问到代码段，这个保护段可以让越界访问行为直接崩溃，防止它继续往下运行。</p><h3 id="内核空间"><a href="#内核空间" class="headerlink" title="内核空间"></a>内核空间</h3><p>内核态虚拟内存空间是所有进程共享的，不同进程进入内核态之后看到的虚拟内存空间全部是一样的。</p><p>直接看参考文献第7节吧：<a href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247486732&idx=1&sn=435d5e834e9751036c96384f6965b328&chksm=ce77cb4bf900425d33d2adfa632a4684cf7a63beece166c1ffedc4fdacb807c9413e8c73f298&token=1468822011&lang=zh_CN&scene=21#wechat_redirect">参考文献</a></p><h2 id="进程虚拟内存空间的管理"><a href="#进程虚拟内存空间的管理" class="headerlink" title="进程虚拟内存空间的管理"></a>进程虚拟内存空间的管理</h2><p>内核中的进程描述符<code>task_struct</code>结构</p><p>在  <code>include/linux/sched.h</code>中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> &#123;</span></span><br><span class="line"><span class="comment">// 进程id</span></span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    <span class="comment">// 进程打开的文件信息</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span>  *<span class="title">files</span>;</span></span><br><span class="line">    <span class="comment">// 该进程的虚拟地址空间结构体指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span> *<span class="title">mm</span>;</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>在<code>include/linux/mm_types.h</code>中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> task_size;  <span class="comment">// 用户态和内核态的分界线</span></span><br><span class="line">    <span class="comment">// 使用如下属性定义虚拟内存中的不同区域</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> start_code, end_code, start_data, end_data;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> start_brk, brk, start_stack;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> arg_start, arg_end, env_start, env_end;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> mmap_base;  <span class="comment">/* base of mmap area */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> total_vm;    <span class="comment">/* Total pages mapped */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> locked_vm;  <span class="comment">/* Pages that have PG_mlocked set */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> pinned_vm;  <span class="comment">/* Refcount permanently increased */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> data_vm;    <span class="comment">/* VM_WRITE &amp; ~VM_SHARED &amp; ~VM_STACK */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> exec_vm;    <span class="comment">/* VM_EXEC &amp; ~VM_WRITE &amp; ~VM_STACK */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> stack_vm;    <span class="comment">/* VM_STACK */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>task_size定义了用户态地址空间与内核态地址空间之间的分界线。32 位系统中用户态虚拟内存空间为 3 GB，虚拟内存地址范围为：0x0000 0000 - 0xC000 000 。内核态虚拟内存空间为 1 GB，虚拟内存地址范围为：0xC000 000 - 0xFFFF FFFF。32 位系统中task_size 为 0xC000 000。同理，64 位系统中用户地址空间和内核地址空间的分界线在  0x0000 7FFF FFFF F000 地址处，那么自然进程的 mm_struct 结构中的 task_size 为 0x0000 7FFF FFFF F000 。</p><p>start_code 和 end_code 定义代码段的起始和结束位置，start_data 和 end_data 定义数据段的起始和结束位置；start_brk 定义堆的起始位置，brk 定义堆当前的结束位置，start_stack 是栈的起始位置在RBP寄存器中，栈的结束位置也就是栈顶指针 stack pointer 在 RSP 寄存器中存储；arg_start 和 arg_end 是参数列表的位置， env_start 和 env_end 是环境变量的位置。它们都位于栈中的最高地址处；mmap_base 定义内存映射区的起始地址</p><p>还定义了一些虚拟内存与物理内存映射内容相关的统计变量。</p><p>mm_struct 结构体中的 total_vm 表示在进程虚拟内存空间中总共与物理内存映射的页的总数。</p><p>当内存吃紧的时候，有些页可以换出到硬盘上，而有些页因为比较重要，不能换出。locked_vm 就是被锁定不能换出的内存页总数，pinned_vm  表示既不能换出，也不能移动的内存页总数。</p><p>data_vm 表示数据段中映射的内存页数目，exec_vm 是代码段中存放可执行文件的内存页数目，stack_vm 是栈中所映射的内存页数目，这些变量均是表示进程虚拟内存空间中的虚拟内存使用情况。</p><p>下图为一个总览图：</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251733977.png" alt="640 (5)"></p><h3 id="虚拟内存区域"><a href="#虚拟内存区域" class="headerlink" title="虚拟内存区域"></a>虚拟内存区域</h3><p>内核中使用结构体 <code>vm_area_struct</code>，来管理像代码段、数据段等不同的虚拟内存区域VMA</p><p>同样在<code>include/linux/mm_types.h</code>中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vm_area_struct</span> &#123;</span></span><br><span class="line">    <span class="comment">/*定义虚拟内存区域起始地址*/</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> vm_start;<span class="comment">/* Our start address within vm_mm. */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> vm_end;<span class="comment">/* The first byte after our end address</span></span><br><span class="line"><span class="comment">    /*省略*/</span></span><br><span class="line">    <span class="comment">/*定义访问权限*/</span></span><br><span class="line">    <span class="type">pgprot_t</span> vm_page_prot;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> vm_flags;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">anon_vma</span> *<span class="title">anon_vma</span>;</span> <span class="comment">/* Serialized by page_table_lock */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> * <span class="title">vm_file</span>;</span>  <span class="comment">/* File we map to (can be NULL). */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> vm_pgoff;  <span class="comment">/* Offset (within vm_file) in PAGE_SIZE</span></span><br><span class="line"><span class="comment">&#125;</span></span><br></pre></td></tr></table></figure><p>vm_start 指向了这块虚拟内存区域的起始地址（最低地址），vm_start 本身包含在这块虚拟内存区域内。vm_end 指向了这块虚拟内存区域的结束地址（最高地址），而 vm_end 本身包含在这块虚拟内存区域之外，所以 vm_area_struct 结构描述的是 [vm_start，vm_end) 这样一段左闭右开的虚拟内存区域。</p><p>vm_page_prot 和 vm_flags 都是用来标记 vm_area_struct 结构表示的这块虚拟内存区域的访问权限和行为规范。</p><p>接下来的三个属性 anon_vma，vm_file，vm_pgoff 分别和虚拟内存映射相关，虚拟内存区域可以映射到物理内存上，也可以映射到文件中，映射到物理内存上我们称之为匿名映射，映射到文件中我们称之为文件映射。</p><p>当我们调用 malloc 申请内存时，如果申请的是小块内存（低于 128K）则会使用 do_brk() 系统调用通过调整堆中的 brk 指针大小来增加或者回收堆内存。</p><p>如果申请的是比较大块的内存（超过 128K）时，则会调用 mmap 在上图虚拟内存空间中的文件映射与匿名映射区创建出一块 VMA 内存区域，如果进行匿名映射，其匿名映射区域就用 struct anon_vma 结构表示；如果进行文件映射，vm_file 属性就用来关联被映射的文件，vm_pgoff 则表示映射进虚拟内存中的文件内容，在文件中的偏移。</p><h3 id="将虚拟内存区域组织进虚拟内存中"><a href="#将虚拟内存区域组织进虚拟内存中" class="headerlink" title="将虚拟内存区域组织进虚拟内存中"></a>将虚拟内存区域组织进虚拟内存中</h3><p><strong>同一个进程的虚拟内存空间的不同虚拟内存区域是如何组织起来的呢？</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vm_area_struct</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vm_area_struct</span> *<span class="title">vm_next</span>, *<span class="title">vm_prev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">vm_rb</span>;</span>  <span class="comment">//红黑树节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在内核中使用两种方式对虚拟内存区域进行组织</p><p>一是通过一个 struct vm_area_struct 结构的<strong>双向链表</strong>将虚拟内存空间中的这些虚拟内存区域 VMA 串联起来的。</p><p>vm_area_struct 结构中的 vm_next ，vm_prev 指针分别指向 VMA 节点所在双向链表中的后继节点和前驱节点，内核中的这个 VMA 双向链表是有顺序的，所有 VMA 节点按照低地址到高地址的增长方向排序。双向链表中的最后一个 VMA 节点的 vm_next 指针指向 NULL，双向链表的头指针存储在内存描述符 struct mm_struct 结构中的 <strong>mmap</strong> 中，正是这个 mmap 串联起了整个虚拟内存空间中的虚拟内存区域。</p><p>二是为了高效查询，将VMA作为红黑数的节点，以红黑树来组织。</p><p>每个 VMA 区域都是红黑树中的一个节点，通过 struct vm_area_struct 结构中的 vm_rb 将自己连接到红黑树中。而红黑树中的根节点存储在内存描述符 struct mm_struct 中的 <strong>mm_rb</strong> 中</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312251734943.png" alt="640 (6)"></p><p>参考文献：<a href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247486732&idx=1&sn=435d5e834e9751036c96384f6965b328&chksm=ce77cb4bf900425d33d2adfa632a4684cf7a63beece166c1ffedc4fdacb807c9413e8c73f298&token=1468822011&lang=zh_CN&scene=21#wechat_redirect">参考文献</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux内核 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IO多路复用</title>
      <link href="/2023/12/14/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
      <url>/2023/12/14/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h1><h2 id="select"><a href="#select" class="headerlink" title="select"></a>select</h2><p><a href="https://www.cnblogs.com/alantu2018/p/8612722.html">内容介绍</a></p><p>代码</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">sockfd = socket(AF_INEF,SOCK_STREAM,<span class="number">0</span>);  <span class="comment">//服务器端监听套接字</span></span><br><span class="line"><span class="built_in">memset</span>(&amp;addr, <span class="number">0</span>, <span class="keyword">sizeof</span>(addr)); <span class="comment">//初始化addr_in类型</span></span><br><span class="line">addr.sin_family = AF_INET; <span class="comment">//IPV4</span></span><br><span class="line">addr.sin_port = hton(<span class="number">2000</span>);<span class="comment">//端口2000</span></span><br><span class="line">addr_sin_addr.s_addr = INADDR_ANY; <span class="comment">// </span></span><br><span class="line"></span><br><span class="line">bind(sockfd, (<span class="keyword">struct</span> sockaddr*)&amp;addr, <span class="keyword">sizeof</span>(addr)); <span class="comment">//绑定陶套接字和套接口地址</span></span><br><span class="line">listen(socfd, <span class="number">5</span>);<span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">memset</span>(&amp;client,<span class="number">0</span>,<span class="keyword">sizeof</span>(client)); <span class="comment">//初始化客户端套接字</span></span><br><span class="line">    addrlen = <span class="keyword">sizeof</span>(client);</span><br><span class="line">    fds[i] = accept(sockfd, (<span class="keyword">struct</span> sockaddr*)&amp;client, &amp;addrlen);</span><br><span class="line">    <span class="keyword">if</span>(fds[i] &gt; max)</span><br><span class="line">        max = fds[i];<span class="comment">//记录最大的文件描述符</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    fd_set rset;</span><br><span class="line">    FD_ZERO(&amp;rest); <span class="comment">//全部置为0</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)</span><br><span class="line">        FD_SET(fds[i],&amp;rset); <span class="comment">//将我们关心的文件描述符设为1</span></span><br><span class="line">    </span><br><span class="line">    select(max+<span class="number">1</span>, &amp;rest, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// select函数会将所有的文件描述符中，有数据到来的那些描述符的对应位置置位1，其余位置置位0，</span></span><br><span class="line">    <span class="comment">//通过for循环判断哪些文件描述符被置位，从而读取其中的数据</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(FD_ISSET(fds[i], &amp;rset))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">memset</span>(buffer,<span class="number">0</span>,MAXBUF);</span><br><span class="line">            read(fds[i],buffer,MAXBUF); <span class="comment">//读操作</span></span><br><span class="line">            <span class="built_in">puts</span>(buffer);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用内核态来判断那个套接字描述符有数据</p><p>缺点：有1024个文件描述符的限制；fd_set不可以重用，每次循环需要重新置位0；内核态复制文件描述符导致文件描述符列表越长需要复制的次数越多；O(n)遍历判断哪个位置的描述符被置位</p><h2 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h2><p>poll函数格式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;poll.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">poll</span> <span class="params">(<span class="keyword">struct</span> pollfd * fds, <span class="type">unsigned</span> <span class="type">int</span> nfds, <span class="type">int</span> timeout)</span>;</span><br></pre></td></tr></table></figure><p>参数：指向pollfd结构体类型的指针，数组指针</p><p>​            关注的文件描述符的个数</p><p>​             时间</p><p>poolfd结构体定义如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> fd;         <span class="comment">/* 文件描述符 */</span></span><br><span class="line">    <span class="type">short</span> events;         <span class="comment">/* 等待的事件 */</span></span><br><span class="line">    <span class="type">short</span> revents;       <span class="comment">/* 实际发生了的事件 */</span></span><br><span class="line">&#125; ; </span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">memset</span>(&amp;client,<span class="number">0</span>, <span class="keyword">sizeof</span>(client));</span><br><span class="line">    addrlen = <span class="keyword">sizeof</span>(client);</span><br><span class="line">    pollfds[i].fd = accept(sockfd, (<span class="keyword">struct</span> sockaddr*)&amp;client, &amp;addrlen);<span class="comment">//pollfds是pollfd类型的结构体数组</span></span><br><span class="line">    pollfds[i].events = POLLIN;<span class="comment">//关注的是有数据可读事件</span></span><br><span class="line">&#125;</span><br><span class="line">sleep(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    poll(pollfds, <span class="number">5</span>, <span class="number">50000</span>); <span class="comment">//调用poll函数，pollfds[i]发生了POLLIN事件，                                                  //把pollfds[i].revents对应于POLLIN置位为1</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(pollfds[i].revents &amp; POLLIN)  <span class="comment">//可能有多个关注事件，要与对应的事件做与操作</span></span><br><span class="line">        &#123;</span><br><span class="line">            pollfds[i].revents = <span class="number">0</span>;<span class="comment">//复位</span></span><br><span class="line">            <span class="comment">//处理数据</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h2><p><a href="https://zhuanlan.zhihu.com/p/406175793">epoll函数原理详解</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">struct epoll_event events[5];</span><br><span class="line">int c = epoll_create1(10);</span><br><span class="line">int epfd = epoll_create(10);//创建一个epoll对象，返回文件描述符,参数只要大于0即可</span><br><span class="line">.......</span><br><span class="line">.......</span><br><span class="line">for(int i=0;i&lt;5;i++)</span><br><span class="line">&#123;</span><br><span class="line">    static struct epoll_event ev;  //临时变量</span><br><span class="line">    memset(&amp;client, 0, sizeof(client));</span><br><span class="line">    addrlen = sizeof(client);</span><br><span class="line">    ev.data.fd = accept(sockfd, (struct sockaddr*)&amp;client, &amp;addrlen); //监听的套接字文件描述符</span><br><span class="line">    ev.events = EPOLLIN; //监听事件是读事件</span><br><span class="line">    epoll_ctl(epfd, EPOLL_CTL_ADD, ev.data.fd, &amp;ev);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">while(1)</span><br><span class="line">&#123;</span><br><span class="line">    nfds = epoll_wait(epfd, events, 5, 10000);</span><br><span class="line">    for(i=0;i&lt;ndfs;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        //处理数据</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>网络编程-Linux系统编程3</title>
      <link href="/2023/12/06/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3/"/>
      <url>/2023/12/06/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux系统编程3"><a href="#Linux系统编程3" class="headerlink" title="Linux系统编程3"></a>Linux系统编程3</h1><h2 id="dentry和inode"><a href="#dentry和inode" class="headerlink" title="dentry和inode"></a>dentry和inode</h2><p>参考：<a href="https://bean-li.github.io/vfs-inode-dentry/">https://bean-li.github.io/vfs-inode-dentry/</a></p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312031438241.png" alt="image-20231203143825104"></p><p><strong>innode：</strong></p><p>本质是结构体，<strong>存储文件的属性信息</strong>。如权限、类型、大小、时间、用户、盘块位置等。大多数的inode都存储在磁盘上，少量常用</p><p><strong>dentry：</strong></p><p>目录项，本质是结构体，存有<strong>文件名</strong>和<strong>inode指针</strong>。因此一个文件可以有多个dentry项</p><h2 id="stat函数"><a href="#stat函数" class="headerlink" title="stat函数"></a>stat函数</h2><p>stat函数，用于获取文件属性，即<strong>获取的就是inode的内容</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">int stat(const char *pathname, struct stat *statbuf);</span><br></pre></td></tr></table></figure><p><strong>参数</strong></p><p>path：文件路径</p><p>buf：传出参数，存放<strong>文件属性</strong></p><p><strong>返回值</strong></p><p>成功：0，失败：-1</p><p><strong>stat结构体如下</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stat</span> &#123;</span></span><br><span class="line">   <span class="type">dev_t</span>     st_dev;         <span class="comment">/* 设备号码 */</span></span><br><span class="line">   <span class="type">ino_t</span>     st_ino;         <span class="comment">/* Inode number */</span></span><br><span class="line">   <span class="type">mode_t</span>    st_mode;        <span class="comment">/* 文件模式，文件、目录 */</span></span><br><span class="line">   <span class="type">nlink_t</span>   st_nlink;       <span class="comment">/* Number of hard links */</span></span><br><span class="line">   <span class="type">uid_t</span>     st_uid;         <span class="comment">/* User ID of owner */</span></span><br><span class="line">   <span class="type">gid_t</span>     st_gid;         <span class="comment">/* Group ID of owner */</span></span><br><span class="line">   <span class="type">dev_t</span>     st_rdev;        <span class="comment">/* Device ID (if special file) */</span></span><br><span class="line">   <span class="type">off_t</span>     st_size;        <span class="comment">/* Total size, in bytes */</span></span><br><span class="line">   <span class="type">blksize_t</span> st_blksize;     <span class="comment">/* Block size for filesystem I/O */</span></span><br><span class="line">   <span class="type">blkcnt_t</span>  st_blocks;      <span class="comment">/* Number of 512B blocks allocated */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>判断文件类型</strong>，使用对应函数，传入stat结构体中的st_mode</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">stat</span> <span class="title">sb</span>;</span></span><br><span class="line">    <span class="type">int</span> ret = stat(argy[<span class="number">1</span>], &amp;sb);</span><br><span class="line">    <span class="keyword">if</span> (ret == <span class="number">-1</span>) </span><br><span class="line">    &#123;</span><br><span class="line">perror(<span class="string">&quot;stat eror&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (S_ISREG(sb.st_mode)) <span class="comment">//常规文件</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;It&#x27;s a regular(n&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (s ISDIR(sb.st mode) <span class="comment">//目录</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;It&#x27;s a dirln&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (S_ISFIFO(sb.st_mode)) <span class="comment">//管道</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;It&#x27;s a pipe n&quot;</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span> (S_ISLNK(sb.st_mode)) </span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;it&#x27;s a sym link n&quot;</span>); <span class="comment">//链接</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="link和unlink函数"><a href="#link和unlink函数" class="headerlink" title="link和unlink函数"></a>link和unlink函数</h2><p>Linux允许多个目录项共享一个inode，即共享盘块，从而使同一个文件有多个文件名。使用link函数，可以为已经存在的目录创建目录项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int link(const char *oldname, const char *newname);</span><br></pre></td></tr></table></figure><p>使用unlink可以删除一个文件的目录项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int unlink(const char* pathname);</span><br></pre></td></tr></table></figure><p>功能详解：unlink从文件系统中中删除一个dentry，若这个dentry是指向这个文件的最后一个链接，并且没有进程处于打开这个文件的状态，则删除这个文件，释放这个文件占用的空间。若这个dentry是指向这个文件的最后一个链接，但是有进程处于打开这个文件的状态，则暂时不删除文件，等到打开这个文件的进程关闭这个文件后，系统才择机删除这个文件。</p><h2 id="opendir、readdir函数"><a href="#opendir、readdir函数" class="headerlink" title="opendir、readdir函数"></a>opendir、readdir函数</h2><p>opendir打开一个目录文件</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span></span><br><span class="line">DIR *<span class="title function_">opendir</span><span class="params">(<span class="type">const</span> <span class="type">char</span>*name)</span>;</span><br></pre></td></tr></table></figure><p>DIR表示目录流类型。</p><p>opendir()用来打开参数name 指定的目录, 并<strong>返回目录流指针</strong>,（相当于文件描述符fd）</p><p>对应的关闭时<code>closedir(DIR *name)</code></p><p>readdir函数返回参数dir 目录流的下个目录进入点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">struct dirent *readdir(DIR *dirp);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct dirent</span><br><span class="line">&#123;</span><br><span class="line">    ino_t d_ino; //d_ino 此目录项的inode</span><br><span class="line">    ff_t d_off; //d_off  目录文件开头至此目录进入点的位移</span><br><span class="line">    signed short int d_reclen; //d_reclen _name 的长度, 不包含NULL 字符</span><br><span class="line">    unsigned char d_type; //d_type d_name 所指的文件类型 d_name 文件名</span><br><span class="line">    har d_name[256];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>返回值</strong>：成功则返回<strong>下个目录项指针</strong>。读取到目录文件尾则返回NULL,error不变，读取错误的话返回NULL，并且error被设置</p><p><strong>每次读一个项，就会有目录流读取位置就会往后偏移一项，使下次使用readdir可以读下一个目录项指针</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    DIR * dp;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dirent</span> *<span class="title">sdp</span>;</span></span><br><span class="line">    dp = opendir(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">if</span>(dp==<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;opendir error&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>((sdp = readdir(dp))!=<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">strcmp</span>(sdp-&gt;d_name,<span class="string">&quot;.&quot;</span>)==<span class="number">0</span>||<span class="built_in">strcmp</span>(sdp-&gt;d_name,<span class="string">&quot;..&quot;</span>)==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\t&quot;</span>,sdp-&gt;d_name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    closedir(dp);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>rewinddir函数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void rewinddir(DIR *dir)</span><br></pre></td></tr></table></figure><p>rewinddir()用来设置参数dir 目录流目前的读取位置为原来开头的读取位置.</p><p><strong>telldir函数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">off_t telldir(DIR *dir);</span><br></pre></td></tr></table></figure><p>telldir()返回参数dir 目录流目前的读取位置。此返回值代表距离目录文件开头的偏移量，返回值返回下个读取位置。</p><p><strong>seekdir函数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void seekdir(DIR * dir, off_t offset);</span><br></pre></td></tr></table></figure><p>seekdir()用来设置参数dir 目录流目前的读取位置, 在调用readdir()时便从此新位置开始读取. 参数offset 代表距离目录文件开头的偏移量。</p><h2 id="总结：实现ls功能"><a href="#总结：实现ls功能" class="headerlink" title="总结：实现ls功能"></a>总结：实现ls功能</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Read_file</span><span class="params">(<span class="type">char</span> *, <span class="type">const</span> <span class="type">int</span> )</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">is_file</span><span class="params">(<span class="type">char</span> *,<span class="type">const</span> <span class="type">int</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Read_file</span><span class="params">(<span class="type">char</span> *name, <span class="type">const</span> <span class="type">int</span> depth)</span> <span class="comment">//目录</span></span><br><span class="line">&#123;</span><br><span class="line">    DIR *dp;<span class="comment">//目录流指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dirent</span> *<span class="title">sdp</span>;</span> <span class="comment">//目录项指针</span></span><br><span class="line">    <span class="keyword">if</span>((dp = opendir(name)) == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;opendir error&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>((sdp = readdir(dp)) != <span class="literal">NULL</span>) <span class="comment">//对于目录中的文件，其打开路径都是：目录路径+文件名</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">strcmp</span>(sdp-&gt;d_name,<span class="string">&quot;.&quot;</span>)==<span class="number">0</span>||<span class="built_in">strcmp</span>(sdp-&gt;d_name,<span class="string">&quot;..&quot;</span>)==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        <span class="type">char</span> file_true_path[<span class="number">1000</span>];</span><br><span class="line">        <span class="type">char</span> lastChar =  name[<span class="built_in">strlen</span>(name)<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">if</span>(lastChar==<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">            <span class="built_in">sprintf</span>(file_true_path,<span class="string">&quot;%s%s&quot;</span>,name,sdp-&gt;d_name);<span class="comment">//拼接</span></span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">            <span class="built_in">sprintf</span>(file_true_path,<span class="string">&quot;%s/%s&quot;</span>,name,sdp-&gt;d_name);<span class="comment">//拼接</span></span><br><span class="line">        is_file(file_true_path,depth);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">is_file</span><span class="params">(<span class="type">char</span> *path, <span class="type">const</span> <span class="type">int</span> depth)</span> <span class="comment">//depth为文件层次</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">stat</span> <span class="title">sb</span>;</span></span><br><span class="line">    <span class="keyword">if</span>(stat(path, &amp;sb)==<span class="number">-1</span>) <span class="comment">//读文件属性，判断是否出错</span></span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;stat error&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(S_ISDIR(sb.st_mode))<span class="comment">//目录文件,打印目录</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">3</span>*depth;i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot; &quot;</span>); <span class="comment">//按深度打印空格</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>,path);</span><br><span class="line">        Read_file(path,depth+<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">3</span>*depth;i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot; &quot;</span>); <span class="comment">//按深度打印空格</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s %8ld\n&quot;</span>,path, sb.st_size);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> *argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(argc == <span class="number">1</span>)</span><br><span class="line">        is_file(<span class="string">&quot;.&quot;</span>,<span class="number">1</span>);</span><br><span class="line">    is_file(argv[<span class="number">1</span>],<span class="number">1</span>); <span class="comment">//目录根路径</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="重定向（dup和dup2）"><a href="#重定向（dup和dup2）" class="headerlink" title="重定向（dup和dup2）"></a>重定向（dup和dup2）</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">dup</span><span class="params">(<span class="type">int</span> oldfd)</span>;  <span class="comment">//oldfd是已有的文件描述符</span></span><br></pre></td></tr></table></figure><p>返回值：成功返回新的文件描述符</p><p>dup函数为oldfd指向的文件创建一个新的文件描述符副本，它们指向相同的打开文件描述符（参见 open(2)），因此共享文件偏移量和文件状态标志</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;string.h&gt;</span><br><span class="line">#include &lt;sys/stat.h&gt;</span><br><span class="line">#include &lt;pthread.h&gt;</span><br><span class="line">#include &lt;fcntl.h&gt;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    int fd;</span><br><span class="line">    if((fd = open(argv[1],O_RDWR|O_APPEND))==-1)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(&quot;open error&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int newfd = dup(fd);  //为一个相同文件返回新的文件描述符</span><br><span class="line">    printf(&quot;newfd = %d\n&quot;,newfd);</span><br><span class="line">    </span><br><span class="line">    if (write(newfd, &quot;1234567&quot;, 7) == -1) </span><br><span class="line">    &#123;</span><br><span class="line">        perror(&quot;write error&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">int dup(int oldfd, int newfd);  //oldfd是已有的文件描述符,newfd是新的文件描述符</span><br></pre></td></tr></table></figure><p><code>dup2()</code> 系统调用执行与 <code>dup()</code> 类似的任务，但是不使用未使用的最低文件描述符号，而是使用在 <code>newfd</code> 中指定的文件描述符号。如果文件描述符 <code>newfd</code> 之前已经打开，则在被重用之前会被静默关闭。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> fd;</span><br><span class="line">    <span class="keyword">if</span>((fd = open(argv[<span class="number">1</span>],O_RDWR|O_APPEND))==<span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;open error&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> newfd = dup2(fd,STDOUT_FILENO); <span class="comment">//标准输出的文件描述符所指向得的文件，重定向到fd所指的文件</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------------------\n&quot;</span>); <span class="comment">//向标准输出写的数据会写入txt文件中</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>网络编程-Linux系统编程2</title>
      <link href="/2023/12/03/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2/"/>
      <url>/2023/12/03/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux系统编程2"><a href="#Linux系统编程2" class="headerlink" title="Linux系统编程2"></a>Linux系统编程2</h1><h2 id="umask"><a href="#umask" class="headerlink" title="umask"></a>umask</h2><p>umask可用来设定[权限掩码]。[权限掩码]是由3个八进制的数字所组成，将<strong>现有的存取权限减掉权限掩码后</strong>，即可产生建立文件时预设的权限。</p><p>linux创建文件文件默认权限为644，目录默认权限为755，默认权限掩码为022。</p><h2 id="open函数"><a href="#open函数" class="headerlink" title="open函数"></a>open函数</h2><p><strong>定义</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int open(const char *pathname, int flags);</span><br><span class="line">int open(const char *pathname, int flags, mode_t mode);</span><br></pre></td></tr></table></figure><p>头文件</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br></pre></td></tr></table></figure><p><strong>参数</strong></p><p><strong>1、pathname：</strong></p><p>相对该文件的绝对路径</p><p><strong>2、flags</strong>：</p><p>flags参数表示打开文件所采用的操作</p><ul><li>O_RDONLY：只读模式</li><li>O_WRONLY：只写模式</li><li>O_RDWR：可读可写</li></ul><p>以上三个参数是<strong>必须的</strong>，下边的选项是选用的，使用时需要与必选参数<code>|</code>起来，如<code>O_RDONLY|O_CREAT</code></p><ul><li><p>O_APPEND 表示追加，如果原来文件里面有内容，则这次写入会写在文件的最末尾。</p></li><li><p>O_CREAT 如果指定文件不存在，则创建这个文件  <code>fd = open(&quot;./2.txt&quot;,O_RDONLY|O_CREAT,0644);</code></p></li><li><p>O_EXCL 表示如果要创建的文件已存在，则出错，同时返回 -1，并且修改 errno 的值。</p></li><li><p>O_TRUNC 表示截断，如果文件存在，并且以<strong>只写、读写</strong>方式打开，则将其长度截断为0。</p></li><li><p>O_NOCTTY 如果路径名指向终端设备，不要把这个设备用作控制终端。</p></li><li><p>O_NONBLOCK 如果路径名指向 FIFO&#x2F;块文件&#x2F;字符文件，则把文件的打开和后继 I&#x2F;O设置为非阻塞模式（nonblocking mode）</p></li></ul><p><strong>3、mode:</strong></p><p>mode参数表示设置文件访问权限的初始值，和用户掩码umask有关,用于创建文件时使用，即第二个参数flags为<code>O_CREAT</code>时才有用</p><p><strong>返回值</strong></p><p>正常则返回一个整数，即文件描述符（int型），出现错误返回-1，并且<code>errno</code>被设置成对应的值</p><p><strong>常见错误：</strong></p><ul><li>打开文件不存在</li><li>以写方式打开只读文件</li><li>以只写或读写方式打开目录，只能用只读方式打开目录</li></ul><h2 id="read和write函数"><a href="#read和write函数" class="headerlink" title="read和write函数"></a>read和write函数</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">read</span><span class="params">(<span class="type">int</span> fd, <span class="type">void</span> *buf, <span class="type">size_t</span> count)</span>;</span><br><span class="line"><span class="comment">// 参数：文件描述符，缓冲区指针，缓冲区大小</span></span><br></pre></td></tr></table></figure><p>成功：返回读到的字节数</p><p>错误，返回-1，设置<code>errno</code>为对应值</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// write() 将从 buf 开始的缓冲区中写入 count 个字节到文件描述符 fd 引用的文件。</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">write</span><span class="params">(<span class="type">int</span> fd, <span class="type">const</span> <span class="type">void</span> *buf, <span class="type">size_t</span> count)</span>;</span><br><span class="line"><span class="comment">// count为要写入的字节数</span></span><br></pre></td></tr></table></figure><p>使用read和write实现cp操作</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> buf[<span class="number">1024</span>];</span><br><span class="line"><span class="type">int</span> n;  <span class="comment">//每次读到的字节数</span></span><br><span class="line"><span class="type">int</span> fd_rd = open(<span class="string">&quot;./1.txt&quot;</span>,O_RDONLY);</span><br><span class="line"><span class="type">int</span> fd_wr = open(<span class="string">&quot;./2.txt&quot;</span>,O_WRONLY|O_CREAT|O_TRUNC,<span class="number">0644</span>);</span><br><span class="line"><span class="keyword">if</span>(fd_rd == <span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;open read_txt error&quot;</span>);<span class="comment">//输出错误提示，并输出strerror(errno)的系统错误信息</span></span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(fd_wr == <span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;open write_txt error&quot;</span>); </span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 先把数据读入缓冲区</span></span><br><span class="line"><span class="keyword">while</span>( (n = read(fd_rd,&amp;buf,<span class="keyword">sizeof</span>(buf))) != <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            perror(<span class="string">&quot;read error&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">write(fd_wr, buf, n); <span class="comment">//这里是n</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">close(fd_rd);</span><br><span class="line">close(fd_wr);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h2><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312012042842.png" alt="image-20231201204236724"></p><p>PCB进程控制块，本质是结构体。其中有个指针变量，指向文件描述符表。</p><p>文件描述符表是一个数组，其中的下标0、1、2、….1023就是文件描述符，而数组中存的是每个文件的每个文件结构体file的指针。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">文件的偏移量</span><br><span class="line">文件的访问权限</span><br><span class="line">文件的打开标志</span><br><span class="line">    文件在内核缓冲区的首地址</span><br><span class="line">....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中</p><p>0-STDIN_FILENO</p><p>1-STDOUT_FILENO</p><p>2-STDERR_FILENO</p><h2 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞"></a>阻塞和非阻塞</h2><p>读常规文件是不会阻塞的，不管读多少字节，read 一定会在有限的时间内返回。从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用 read 读终端设备就会阻塞，如果网络上没有接收到数据包，调用 read 从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。<br>产生阻塞的场景。设备文件、读网络文件</p><p>&#x2F;dev&#x2F;tty —–终端文件 <code>open(&quot;/dev/tty,O_RDWR|O_NONBLOCK&quot;)</code></p><h2 id="fcntl函数"><a href="#fcntl函数" class="headerlink" title="fcntl函数"></a>fcntl函数</h2><p>获取文件状态：F_GETFL <code>int flags = fctl(0,F_GETFL)</code></p><p>设置文件状态：F_SETFL  <code>fcntl(STDIN_FILENO,F_SETFL,flags)</code></p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202312021229678.png" alt="image-20231202122934603"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line"><span class="type">int</span> flags,n;</span><br><span class="line"><span class="keyword">if</span>((flags = fcntl(STDIN_FILENO,F_GETFL))==<span class="number">-1</span>) <span class="comment">//获取stdin属性信息</span></span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;fcntl error&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">flags |= O_NONBLOCK;  <span class="comment">//增加O_NONBLOCK位信息</span></span><br><span class="line"><span class="type">int</span> ret;</span><br><span class="line"><span class="keyword">if</span>((ret = fcntl(STDIN_FILENO,F_SETFL,flags))==<span class="number">-1</span>)  <span class="comment">//设置标准输入文件为非阻塞状态</span></span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;fcntl set error&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tryagain:</span><br><span class="line">n = read(STDIN_FILENO,buf,<span class="number">10</span>);</span><br><span class="line"><span class="keyword">if</span>(n&lt;<span class="number">0</span>) <span class="comment">//当以非阻塞状态读文件时，如果缓冲区中没有数据，则返回-1，同时设置errno为EGAIN，因此这样判断</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(errno != EAGAIN)&#123;</span><br><span class="line">perror(<span class="string">&quot;read /dev/tty&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">sleep(<span class="number">3</span>);</span><br><span class="line">write(STDOUT_FILENO, <span class="string">&quot;try again\n&quot;</span>, <span class="built_in">strlen</span>(<span class="string">&quot;try again\n&quot;</span>)); <span class="comment">//向标准输出中写入try again，表示一次尝试</span></span><br><span class="line"><span class="keyword">goto</span> tryagain;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果从缓冲区中读到数据，就写入标准输出文件中</span></span><br><span class="line">write(STDOUT_FILENO,buf,n);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="lseek函数"><a href="#lseek函数" class="headerlink" title="lseek函数"></a>lseek函数</h2><p>Linux系统中使用系统函数来修改文件偏移量（读写位置）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">off_t</span> <span class="title function_">lseek</span><span class="params">(<span class="type">int</span> fd, <span class="type">off_t</span> offset, <span class="type">int</span> whence)</span>;</span><br></pre></td></tr></table></figure><p>参数<code>whence</code></p><blockquote><p>SEEK_SET:  　　从文件头部开始偏移offset个字节。  </p><p>SEEK_CUR：  　从文件当前读写的指针位置开始，增加offset个字节的偏移量。  </p><p>SEEK_END：  　文件偏移量设置为文件的大小加上偏移量字节。</p></blockquote><p>返回值</p><blockquote><p>成功：返回值是较文件起始位置向后的偏移量</p><p>失败：返回-1</p></blockquote><p>注意：打开文件后，文件的读和写使用同一个偏移位置</p><p>应用场景：</p><ul><li><p>文件打开后，文件的读和写使用同一个偏移位置</p></li><li><p>使用lseek获取文件大小</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> agrc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> fd = open(argv[<span class="number">1</span>],O_RDWR);</span><br><span class="line"><span class="keyword">if</span>(fd==<span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;open error&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> len = lseek(fd, <span class="number">0</span>, SEEK_END);  <span class="comment">//获取文件大小，单位：字节</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;length=%d\n&quot;</span>,len);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用lseek拓展文件大小；要想使文件大小真正改变，必须使用IO操作</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> agrc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> fd = open(argv[<span class="number">1</span>],O_RDWR);</span><br><span class="line"><span class="keyword">if</span>(fd==<span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">perror(<span class="string">&quot;open error&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> len = lseek(fd, <span class="number">100</span>, SEEK_END); <span class="comment">//len增加100,此时ls -l Read.txt其大小没变</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;length=%d\n&quot;</span>,len);</span><br><span class="line">write(fd,<span class="string">&quot;\0&quot;</span>,<span class="number">1</span>);   <span class="comment">// 调用IO操作，写入磁盘。此时才发生变化</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用<code>act -A Read.txt</code>查看文件，包括特殊字符</p><p>也可以使用<code>truncate</code>函数直接拓展，<code>truncate(char *path,  off_t length)</code></p><blockquote><p>如果文件以前大于此大小，则多余的数据将丢失。 如果之前的文件较短，则会扩展它，扩展部分读取为空字节（’\0’）。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>网络编程-Linux系统编程1</title>
      <link href="/2023/11/28/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/"/>
      <url>/2023/11/28/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux系统编程1"><a href="#Linux系统编程1" class="headerlink" title="Linux系统编程1"></a>Linux系统编程1</h1><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><p><code>ctrl+a</code>:光标移到命令行最前面</p><p><code>ctrl+e</code>:光标移到命令行最后面</p><p><code>ctrl+u</code>:删除整行</p><h2 id="gcc编译的四个阶段"><a href="#gcc编译的四个阶段" class="headerlink" title="gcc编译的四个阶段"></a>gcc编译的四个阶段</h2><ul><li><p>预处理：<code>gcc -E helloworld.c -o helloworld.i</code></p></li><li><p>编译：<code>gcc -S helloworld.i -o helloworld.s</code>           <strong>编译阶段出错，会给出行号</strong></p></li><li><p>汇编：<code>gcc -c helloworld.s -o helloworld.o</code></p></li><li><p>链接：<code>gcc helloworld.o -o helloworld</code>                    <strong>链接阶段出错，会有<code>collect: error: ld</code></strong></p></li></ul><h2 id="gcc编译常用命令"><a href="#gcc编译常用命令" class="headerlink" title="gcc编译常用命令"></a>gcc编译常用命令</h2><ul><li><code>-o</code>：指定生成的文件</li><li><code>-I </code>：指定头文件的路径</li><li><code>-g</code>：编译时添加调试语句（要使用gdb调试时必须加这个参数）</li><li><code>-Wall</code>：显示所有警告信息</li><li><code>-D</code>：向当前程序中注册一个宏，如<code>gcc hello.c -D HELLO</code>就是注册了一个HELLO的宏用作开关来输出调试信息</li></ul><h2 id="静态库和动态库"><a href="#静态库和动态库" class="headerlink" title="静态库和动态库"></a>静态库和动态库</h2><p>静态库会在链接的时候直接把库文件复制到程序中，运行的时候不再依赖库文件。以<code>.a</code>为后缀</p><p>动态库是在运行时动态加载。以<code>.so</code>为后缀</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello 编程珠玑\n&quot;</span>);</span><br><span class="line">    <span class="type">int</span> b = <span class="number">2</span>;</span><br><span class="line">    <span class="type">double</span> a = <span class="built_in">exp</span>(b);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%lf\n&quot;</span>,a);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对于这个函数，使用了math.h中的exp函数</p><p>静态链接</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -<span class="type">static</span> main.c -o main -lm</span><br></pre></td></tr></table></figure><p>动态链接</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc main.c -o main -lm</span><br></pre></td></tr></table></figure><p>使用了<code>-l</code>参数，后边的<code>m</code>是<code>math.h</code>的基本名称</p><p>可以使用<code>ldd main</code>查看动态链接文件的都链接了哪些库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wufang@wufang:~/C++_base_learning$ ldd test1</span><br><span class="line">linux-vdso.so.1 (0x00007ffca1fc5000)</span><br><span class="line">libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2cb480f000)</span><br><span class="line">libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2cb4400000)</span><br><span class="line">/lib64/ld-linux-x86-64.so.2 (0x00007f2cb490b000)</span><br></pre></td></tr></table></figure><p>如何判断一个函数是否需要链接呢？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">man <span class="number">3</span> 函数名</span><br></pre></td></tr></table></figure><h2 id="静态库制作"><a href="#静态库制作" class="headerlink" title="静态库制作"></a>静态库制作</h2><ol><li>将.c文件编译生成.o文件  <code>gcc -c add.c -o add</code></li><li>使用ar工具制作静态库 <code>ar rcs lib库名.a add.o sub.o</code></li><li>编译静态库到可执行文件中<code>gcc main.c lib库名.a -o main </code></li></ol><p>按这样三部编译出可执行文件后，会出现如下警告</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test.c:<span class="number">8</span>:<span class="number">33</span>: warning: implicit declaration of function ‘add’ [-Wimplicit-function-declaration]</span><br><span class="line">    <span class="number">8</span> |         <span class="built_in">printf</span>(<span class="string">&quot;%d+%d=%d\n&quot;</span>,a,b,add(a,b));</span><br><span class="line">      |                                 ^~~</span><br><span class="line">test.c:<span class="number">9</span>:<span class="number">33</span>: warning: implicit declaration of function ‘sub’ [-Wimplicit-function-declaration]</span><br><span class="line">    <span class="number">9</span> |         <span class="built_in">printf</span>(<span class="string">&quot;%d-%d=%d\n&quot;</span>,a,b,sub(a,b));</span><br><span class="line">      |                                 ^~~</span><br><span class="line">wufang@wufang:~/C++_base_learning$ ./test</span><br></pre></td></tr></table></figure><p>这个警告告诉：<strong>对add的隐式声明</strong>，因此，我们需要额外对使用的库函数进行声明，写在一个<code>库名.h</code>文件中，文件格式如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _MYMATH_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _MMYMATH_H_</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span>,<span class="type">int</span>)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">sub</span><span class="params">(<span class="type">int</span>,<span class="type">int</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>这使用了头文件首位，目的是：防止重复引入和重复定义。<a href="https://www.cnblogs.com/flowingwind/p/8304668.html">https://www.cnblogs.com/flowingwind/p/8304668.html</a></p><p>制作好.h文件后，在.cpp文件中引入.h头文件（<code>#include &quot;mymath.h&quot;</code>）。此时的编译命令为</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc main.c ./lib/lib库名.a -o main.out -I ./inc</span><br></pre></td></tr></table></figure><p>静态库文件放在lib中，头文件放在inc中</p><h2 id="动态库制作"><a href="#动态库制作" class="headerlink" title="动态库制作"></a>动态库制作</h2><p>参考：<a href="https://cloud.tencent.com/developer/article/1711778">https://cloud.tencent.com/developer/article/1711778</a></p><ol><li><p>将.c文件编译生成与位置无关的二进制文件：<code>gcc -c add.c -o add.o -fPIC </code></p></li><li><p>使用<code>gcc -shared</code>制作动态库：<code>gcc -shared -o lib库名.so add.o sub.o div.o</code></p></li><li><p>编译可执行程序，指定所使用的动态库。 <code>-l</code>指定库名，<code>-L</code>指定动态库路径, <code>-I</code>指定库的头文件路径</p><p><code>gcc test.c -o test.out -l库名 -L./lib -I ./inc</code></p></li></ol><p><strong>注意：-l后边紧跟库名，-L后紧跟库路径，空格可有可无</strong></p><p>按上边步骤完成后，运行可执行文件，报错</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wufang@wufang:~/C++_base_learning/dynamic$ gcc test.c -o test.out -lmymath -L./lib -I./inc</span><br><span class="line">wufang@wufang:~/C++_base_learning/dynamic$ ./test.out </span><br><span class="line">./test.out: error <span class="keyword">while</span> loading shared libraries: libmymath.so: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure><p>这个报错是因为<strong>动态链接器</strong>在运行程序的时候找不到需要链接的库。解决办法有三种，如下给出视频中的方法：</p><p>即 将动态库的路径写入<strong>用户终端配置文件</strong><code>.bashrc</code>中，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bachrc  <span class="comment">#打开用户自己的终端配置文件</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=....  <span class="comment">#添加链接路径，最好使用绝对路径</span></span><br><span class="line"><span class="built_in">source</span> .bashrc   <span class="comment">#运行生效</span></span><br></pre></td></tr></table></figure><p>解决方法合集：<a href="https://www.jianshu.com/p/a3b2b6f5f0fc">https://www.jianshu.com/p/a3b2b6f5f0fc</a></p><h2 id="gdb调试工具"><a href="#gdb调试工具" class="headerlink" title="gdb调试工具"></a>gdb调试工具</h2><p>基础指令：</p><ul><li><code>-g</code>：使用该参数编译可执行文件，得到调试表</li><li><code>gdb ./a.out</code>：</li><li><code>set listsize 行数</code>：设置list打印行数</li><li><code>list 1</code>：从第一行开始打印</li><li><code>b/break</code>：设置断点，后边可以跟着行号或者函数名</li><li><code>run</code>：直接运行程序，如果设置断点了，会运行到断点，如果程序出错了，会直接运行到出错位置</li><li><code>s/step</code>：下一条指令（会进入函数）</li><li><code>n/next</code>：下一条指令（越过函数）</li><li><code>finish</code>：进入函数后，结束当前函数调用，即退出该函数</li><li><code>p/print</code>：p i 查看变量i的值</li><li><code>c/continue</code>：运行程序到下一个断点或者结束</li><li><code>quit</code>：退出gdb</li></ul><p>其它指令：</p><ul><li><p><code>start</code>：从main函数的第一行开始</p></li><li><p><code>set args</code>：设置main函数命令行参数</p></li><li><p><code>info b</code>：查看所有断点信息</p></li><li><p><code>b 20 if i = 5</code>设置条件断点，用在循环语句，嵌套递归中</p></li><li><p><code>bt</code>：查看程序中正在存活的栈帧</p></li><li><p><code>fram 栈帧编号</code>：切换栈帧</p></li><li><p><code>display 变量</code>：跟踪变量</p></li><li><p><code>undisplay 变量编号</code>：取消跟踪</p></li></ul><h2 id="Makefile"><a href="#Makefile" class="headerlink" title="Makefile"></a>Makefile</h2><h3 id="简易版"><a href="#简易版" class="headerlink" title="简易版"></a>简易版</h3><p>test.c中是这样的</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里将函数声明写在了main函数中，后续会给出将函数声明写在.h中</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span>,<span class="type">int</span>)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">sub</span><span class="params">(<span class="type">int</span>,<span class="type">int</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a = <span class="number">14</span>, b = <span class="number">7</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d+%d=%d\n&quot;</span>,a,b,add(a,b));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%d-%d=%d\n&quot;</span>,a,b,sub(a,b));</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>1个规则：</strong></p><p>目标：依赖条件</p><p>​（一个Tab缩进）命令</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">test:test.o add.o sub.o</span></span><br><span class="line">        gcc test.o add.o sub.o -o test</span><br><span class="line"></span><br><span class="line"><span class="section">test.o:test.c</span></span><br><span class="line">        gcc -c test.c -o test.o</span><br><span class="line"></span><br><span class="line"><span class="section">add.o:add.c</span></span><br><span class="line">        gcc -c add.c -o add.o</span><br><span class="line"></span><br><span class="line"><span class="section">sub.o:sub.c</span></span><br><span class="line">        gcc -c sub.c -o sub.o</span><br></pre></td></tr></table></figure><p>基本原则：</p><ol><li>若想生成目标文件，检查规则中的依赖条件是否存在，如不存在，则寻找是否有规则用来生成该依赖文件</li><li>检查规则中的目标是否需要更新，必须先检查它的所有依赖，依赖中有任何一项被更新，则目标更新</li></ol><p><strong>2个函数：</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> *.c)</span>   <span class="comment">#找到当前目录下所有后缀未.c的文件，赋值给src</span></span><br><span class="line">obj = <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o <span class="variable">$(src)</span>)</span>  <span class="comment">#将src变量中包含.c后缀的文件都替换成.o后缀</span></span><br><span class="line"></span><br><span class="line"><span class="section">test:@(obj)</span></span><br><span class="line">        gcc @(obj) -o test</span><br><span class="line"></span><br><span class="line"><span class="section">test.o:test.c</span></span><br><span class="line">        gcc -c test.c -o test.o</span><br><span class="line"></span><br><span class="line"><span class="section">add.o:add.c</span></span><br><span class="line">        gcc -c add.c -o add.o</span><br><span class="line"></span><br><span class="line"><span class="section">sub.o:sub.c</span></span><br><span class="line">        gcc -c sub.c -o sub.o</span><br><span class="line">        </span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">-rm -rf <span class="variable">$(obj)</span> test   <span class="comment">#将生成的.o文件和可执行文件都删了，rm前的&quot;-&quot;表示出错依然执行</span></span><br></pre></td></tr></table></figure><p><strong>3个变量：</strong></p><blockquote><p>$@：在一条规则的<strong>命令</strong>中，表示该规则的目标</p><p>$^：在一条规则的命令中使用，用于表示这条规则的所有依赖条件</p><p>$&lt;：在一条规则的命令中使用，用于表示这条规则的依赖条件列表中的第一个依赖条件</p></blockquote><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> *.c)</span>  </span><br><span class="line">obj = <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(src)</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="section">test:<span class="variable">$(obj)</span></span></span><br><span class="line">gcc <span class="variable">$^</span>  -o test</span><br><span class="line"></span><br><span class="line"><span class="section">test.o:test.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o test.o</span><br><span class="line"></span><br><span class="line"><span class="section">add.o:add.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o add.o</span><br><span class="line"></span><br><span class="line"><span class="section">sub.o:sub.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o sub.o</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">-rm -rf <span class="variable">$(obj)</span> test</span><br></pre></td></tr></table></figure><p><strong>模式规则：</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">test.o:test.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o test.o</span><br><span class="line"><span class="section">add.o:add.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o add.o</span><br><span class="line"><span class="section">sub.o:sub.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o sub.o</span><br><span class="line"><span class="comment"># 可以将上面的结构重复的代码做如下替换</span></span><br><span class="line"><span class="section">%.o:%.c</span></span><br><span class="line">gcc -c <span class="variable">$&lt;</span> -o <span class="variable">$@</span></span><br></pre></td></tr></table></figure><p>最终的makefile代码可以这样写</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> *.c)</span>  </span><br><span class="line">obj = <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(src)</span>)</span></span><br><span class="line"></span><br><span class="line">CXX = gcc  <span class="comment">#编译器，可以根据需要改成g++</span></span><br><span class="line">myArgs = -Wall -g <span class="comment">#调试选项，使得编译的文件可以进行调试</span></span><br><span class="line"></span><br><span class="line"><span class="section">test:<span class="variable">$(obj)</span></span></span><br><span class="line"><span class="variable">$(CXX)</span> <span class="variable">$^</span> -o <span class="variable">$@</span> <span class="variable">$(myArgs)</span></span><br><span class="line"><span class="section">%.o:%.c</span></span><br><span class="line"><span class="variable">$(CXX)</span> -c <span class="variable">$&lt;</span> -o <span class="variable">$@</span> <span class="variable">$(myArgs)</span></span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>:clean  #伪目标，因为文件夹中可能存在同名的clean文件</span></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">-rm -rf <span class="variable">$(obj)</span> test</span><br></pre></td></tr></table></figure><h3 id="重构版"><a href="#重构版" class="headerlink" title="重构版"></a>重构版</h3><p>项目文件夹下有如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inc       makefile  obj       src</span><br></pre></td></tr></table></figure><p>其中，<code>inc</code>文件夹存放<code>头文件</code>，<code>src</code>文件夹存放<code>.c或者.cpp源代码</code>，<code>obj</code>文件夹存放<code>.o目标文件</code></p><p><code>makefile</code>文件如下</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> ./src/*.c)</span></span><br><span class="line">obj = <span class="variable">$(<span class="built_in">patsubst</span> ./src/%.c, ./obj/%.o, <span class="variable">$(src)</span>)</span></span><br><span class="line"></span><br><span class="line">inc_path = ./inc  <span class="comment">#头文件所在位置</span></span><br><span class="line">myArgs = -Wall -g</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">test:<span class="variable">$(obj)</span></span></span><br><span class="line">        gcc <span class="variable">$^</span> -o test <span class="variable">$(myArgs)</span></span><br><span class="line">        </span><br><span class="line"><span class="variable">$(obj)</span>:./obj%.o:./src%.c</span><br><span class="line">        gcc -c <span class="variable">$&lt;</span> -o <span class="variable">$@</span> <span class="variable">$(myArgs)</span> -I <span class="variable">$(inc_path)</span>  <span class="comment">#在编译生成目标文件时需要指出头文件位置</span></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">        -rm -rf <span class="variable">$(obj)</span> test</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vscode调试Linux内核</title>
      <link href="/2023/11/20/Vscode%E8%B0%83%E8%AF%95Linux%E5%86%85%E6%A0%B8/"/>
      <url>/2023/11/20/Vscode%E8%B0%83%E8%AF%95Linux%E5%86%85%E6%A0%B8/</url>
      
        <content type="html"><![CDATA[<h1 id="使用Vscode调试Linux内核"><a href="#使用Vscode调试Linux内核" class="headerlink" title="使用Vscode调试Linux内核"></a>使用Vscode调试Linux内核</h1><p>上一篇博客我们在虚拟机中编译了Linux内核，并且使用Qemu和gdb进行调试，但是gdb的指令我还不熟练，还是想用vscode来调试，这样也更加方便</p><h2 id="Vscode插件安装"><a href="#Vscode插件安装" class="headerlink" title="Vscode插件安装"></a>Vscode插件安装</h2><h3 id="remote-ssh"><a href="#remote-ssh" class="headerlink" title="remote-ssh"></a>remote-ssh</h3><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201245007.png" alt="image-20231120124509960"></p><p>安装完成后右边工具栏会多出一个功能</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201246229.png" alt="image-20231120124653194"></p><p>按F1呼出对话框，输入<code>remote-ssh</code>，选择open ssh configuration file。</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201247886.png" alt="image-20231120124748850"></p><p>选择第一个配置文件</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201248231.png" alt="image-20231120124824202"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Host 自定义连接名称</span><br><span class="line">    HostName 服务器IP地址</span><br><span class="line">    User 用户名</span><br></pre></td></tr></table></figure><h3 id="C-C"><a href="#C-C" class="headerlink" title="C&#x2F;C++"></a>C&#x2F;C++</h3><p>安装C&#x2F;C++插件</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201251048.png" alt="image-20231120125110014"></p><p>依次点击【运行】-&gt;【打开配置】，将以下配置复制到launch.json中。</p><p><strong>该代码不需要更改，直接粘贴</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;kernel-debug&quot;</span><span class="punctuation">,</span>   <span class="comment">//随便起名</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;miDebuggerServerAddress&quot;</span><span class="punctuation">:</span> <span class="string">&quot;127.0.0.1:1234&quot;</span><span class="punctuation">,</span>  <span class="comment">//远端调试地址，1234为qemu的监视端口</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/vmlinux&quot;</span><span class="punctuation">,</span>     <span class="comment">//当前目录下的vmlinux</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;stopAtEntry&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;environment&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;externalConsole&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;logging&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;engineLogging&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Vscode调试"><a href="#Vscode调试" class="headerlink" title="Vscode调试"></a>Vscode调试</h2><h3 id="在虚拟机中启动qemu"><a href="#在虚拟机中启动qemu" class="headerlink" title="在虚拟机中启动qemu"></a>在虚拟机中启动qemu</h3><p>在<strong>Linux内核文件夹下</strong>运行此命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -kernel ./arch/x86/boot/bzImage -initrd ../initramfs.cpio.gz -append <span class="string">&quot;nokaslr console=ttyS0&quot;</span> -s -S -nographic</span><br></pre></td></tr></table></figure><h3 id="打断点"><a href="#打断点" class="headerlink" title="打断点"></a>打断点</h3><p>打开init&#x2F;main.c，我打了如下的断点</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201300424.png" alt="image-20231120130037370"></p><h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201305050.png" alt="image-20231120130522009"></p><p>然后在vscode中就可以看到调试结果了</p><h2 id="代码中标红的问题"><a href="#代码中标红的问题" class="headerlink" title="代码中标红的问题"></a>代码中标红的问题</h2><p>代码标红是缺少compile_commands.json文件</p><p>我在B站上学习的时候，是跟着这位up主来的（源码被猫吃了），他的解决方案如下：</p><p>在终端键入命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./scripts/clang-tools/gen_compile_commands.py</span><br></pre></td></tr></table></figure><p>在源码目录下就生成了<code>compile_commands.json</code>文件</p><p>在vscode中：<code>ctrl+shipt+p</code>选择C&#x2F;C++：Edit Coonfigurations,</p><p>在c_cpp_properties.json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linux&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;includePath&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;$&#123;workspaceFolder&#125;/**&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;defines&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;compilerPath&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/usr/bin/gcc&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cStandard&quot;</span><span class="punctuation">:</span> <span class="string">&quot;c17&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cppStandard&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gnu++17&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;intelliSenseMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;linux-gcc-x64&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;compileCommands&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/compile_commands.json&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">4</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>此后，main.c中的代码就不标红了</p>]]></content>
      
      
      <categories>
          
          <category> Linux内核 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用虚拟机进行基于qemu和gdb的Linux内核调试</title>
      <link href="/2023/11/20/%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9B%E8%A1%8C%E5%9F%BA%E4%BA%8Eqemu%E5%92%8Cgdb%E7%9A%84Linux%E5%86%85%E6%A0%B8%E8%B0%83%E8%AF%95/"/>
      <url>/2023/11/20/%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9B%E8%A1%8C%E5%9F%BA%E4%BA%8Eqemu%E5%92%8Cgdb%E7%9A%84Linux%E5%86%85%E6%A0%B8%E8%B0%83%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h1 id="使用虚拟机进行基于qemu和gdb的Linux内核调试"><a href="#使用虚拟机进行基于qemu和gdb的Linux内核调试" class="headerlink" title="使用虚拟机进行基于qemu和gdb的Linux内核调试"></a>使用虚拟机进行基于qemu和gdb的Linux内核调试</h1><h2 id="虚拟机配置"><a href="#虚拟机配置" class="headerlink" title="虚拟机配置"></a>虚拟机配置</h2><p>至少分8个核心（不然编译速度很慢，亲测）</p><p>磁盘大小分50G（编译后的内核大小有20多个G！）</p><h2 id="打开SSH"><a href="#打开SSH" class="headerlink" title="打开SSH"></a>打开SSH</h2><p>虚拟机中安装的是ubuntu22.04版本，默认没有安装和启用SSH服务</p><p><strong>更新软件源</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure><p><strong>安装SSH(OpenSSH)</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install openssh-server -y</span><br></pre></td></tr></table></figure><p><strong>启动SSH服务</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> --now ssh</span><br></pre></td></tr></table></figure><p><strong>检查是否启动成功</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status ssh</span><br></pre></td></tr></table></figure><h2 id="内核编译"><a href="#内核编译" class="headerlink" title="内核编译"></a>内核编译</h2><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装相关依赖</span></span><br><span class="line">sudo apt-get install libncurses5-dev libssl-dev bison flex libelf-dev gcc g++ make openssl libc6-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装gdb，这里使用apt安装（多次尝试的结果）</span></span><br><span class="line">sudo apt-get install gdb</span><br><span class="line">gdb --version <span class="comment"># gdb版本为12.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这里选择清华源，国内速度会快很多</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/kernel/v5.x/linux-5.14.tar.gz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -xvf linux-5.14.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置编译选项</span></span><br><span class="line">make menuconfig</span><br></pre></td></tr></table></figure><p>然后会在此文件夹下生成 <strong>.&#x2F;config</strong>文件</p><p><strong>进入该文件，并做以下2处修改</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ./.config</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201128412.png" alt="image-20231117212013850"></p><p><strong>安装dwarves软件包（编译报错得出结论）</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install dwarves</span><br></pre></td></tr></table></figure><p><strong>BTF报错解决</strong></p><p>如果仅仅只进行了上边的配置，会报如下错误（我个人是这样）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">  KSYMS   .tmp_vmlinux.kallsyms1.S</span><br><span class="line">  AS      .tmp_vmlinux.kallsyms1.S</span><br><span class="line">  LD      .tmp_vmlinux.kallsyms2</span><br><span class="line">  KSYMS   .tmp_vmlinux.kallsyms2.S</span><br><span class="line">  AS      .tmp_vmlinux.kallsyms2.S</span><br><span class="line">  LD      vmlinux</span><br><span class="line">  BTFIDS  vmlinux</span><br><span class="line">FAILED: load BTF from vmlinux: Invalid argument</span><br><span class="line">make: *** [Makefile:1187: vmlinux] Error 255</span><br><span class="line">make: *** Deleting file <span class="string">&#x27;vmlinux&#x27;</span></span><br></pre></td></tr></table></figure><p>查阅资料后，有三种解决方案：<a href="https://devkernel.io/posts/pahole-error/">https://devkernel.io/posts/pahole-error/</a></p><p>我使用的是<strong>第二种方法</strong>，对pahole软件包进行降级 :</p><p>查看pahole的版本，是1.25</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pahole --version  </span><br></pre></td></tr></table></figure><p>查看pahole的所有可用安装版本</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-cache policy pahole</span><br></pre></td></tr></table></figure><p>截图如下</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201127209.png" alt="1"></p><p>我们发现只有两个版本，因此只能降级为 1.22-8</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install pahole=1.22-8</span><br></pre></td></tr></table></figure><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8      <span class="comment">#8个线程并行编译，</span></span><br></pre></td></tr></table></figure><p>然后可能会弹出一个选择（1，2，3），直接选择1即可。等待一段时间，30分钟左右</p><h3 id="是否成功"><a href="#是否成功" class="headerlink" title="是否成功"></a>是否成功</h3><p>编译完成后，目录下会生成以下,那么就编译成功了</p><blockquote><p>.&#x2F;vmLinux</p><p>.&#x2F;arch&#x2F;x86&#x2F;boot&#x2F;bzImage</p><p>其中vmLinux为GDB所需的调试Map文件，bzImage为大内核文件</p></blockquote><h2 id="安装Qemu"><a href="#安装Qemu" class="headerlink" title="安装Qemu"></a>安装Qemu</h2><p>qemu是一款完全软件模拟(Binary translation)的虚拟化软件，在虚拟化的实现中性能相对较差。但利用它在测试环境中gdb调试Linux内核代码，是熟悉Linux内核代码的一个好方法。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装qemu</span></span><br><span class="line">sudo apt-get install qemu</span><br></pre></td></tr></table></figure><h2 id="安装编译busybox"><a href="#安装编译busybox" class="headerlink" title="安装编译busybox"></a>安装编译busybox</h2><p>安装busybox的目的是：借助BusyBox构建极简initramfs，提供基本的用户态可执行程序。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://busybox.net/downloads/busybox-1.36.1.tar.bz2  <span class="comment"># 去官网找最新版</span></span><br><span class="line">tar -xvf busybox-1.36.1.tar.bz2</span><br><span class="line"><span class="built_in">cd</span> busybox-1.36.1/</span><br><span class="line">make menuconfig</span><br></pre></td></tr></table></figure><p>在编译busybox之前，我们需要对其进行设置，执行<code>make menuconfig</code>，如下</p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201135953.png" alt="image-20231120113536905"></p><p><img src="https://raw.githubusercontent.com/wfloveiu/blogImage/main/img/202311201136740.png" alt="image-20231120113608696"></p><p>这里一定要选择<strong>静态编译</strong>，编译好的可执行文件<code>busybox</code>不依赖动态链接库，可以独立运行，方便构建initramfs。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make -j 8</span><br><span class="line">make &amp;&amp; make install <span class="comment"># 安装完成后生成的相关文件会在 _install 目录下</span></span><br></pre></td></tr></table></figure><h2 id="构建initramfs根文件系统"><a href="#构建initramfs根文件系统" class="headerlink" title="构建initramfs根文件系统"></a>构建initramfs根文件系统</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在busybox压缩包的下载目录下,创建的该文件夹，该文件夹下有</span></span><br><span class="line"><span class="comment"># wufang@wufang:~/linux_kernel/kernel_compile$ ls</span></span><br><span class="line"><span class="comment"># busybox-1.36.1   busybox-1.36.1.tar.bz2   linux-5.14  linux-5.14.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> initramfs</span><br><span class="line"><span class="built_in">cd</span> initramfs</span><br><span class="line"><span class="built_in">cp</span> ../busybox-1.29.0/_install/* -rf ./ <span class="comment">#将_install文件夹下的所有文件复制到initramfs文件夹下</span></span><br><span class="line"><span class="built_in">mkdir</span> dev proc sys</span><br><span class="line">sudo <span class="built_in">cp</span> -a /dev/&#123;null,console,<span class="built_in">tty</span>,tty1,tty2,tty3,tty4&#125; dev/</span><br><span class="line"><span class="built_in">rm</span> -f linuxrc</span><br><span class="line">vim init</span><br></pre></td></tr></table></figure><p>添加如下代码</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/busybox sh</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&#123;==DBG==&#125; INIT SCRIPT&quot;</span></span><br><span class="line">mount -t proc none /proc</span><br><span class="line">mount -t sysfs none /sys</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&#123;==DBG==&#125; Boot took <span class="subst">$(cut -d&#x27; &#x27; -f1 /proc/uptime)</span> seconds&quot;</span></span><br><span class="line"><span class="built_in">exec</span> /sbin/init</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> a+x init 修改文件权限</span><br><span class="line"><span class="comment"># 完成后，initrams下有如下文件</span></span><br><span class="line"><span class="comment"># bin   dev   init  proc  sbin  sys   usr</span></span><br></pre></td></tr></table></figure><p><strong>打包initramfs</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find . -print0 | cpio --null -ov --format=newc | gzip -9 &gt; ../initramfs.cpio.gz</span><br><span class="line"><span class="comment"># 此时在busybox压缩包的下载目录下，有如下文件</span></span><br><span class="line"><span class="comment"># busybox-1.36.1          initramfs               linux-5.14</span></span><br><span class="line"><span class="comment"># busybox-1.36.1.tar.bz2  initramfs.cpio.gz       linux-5.14.tar.gz</span></span><br></pre></td></tr></table></figure><h2 id="启动Qemu调试内核"><a href="#启动Qemu调试内核" class="headerlink" title="启动Qemu调试内核"></a>启动Qemu调试内核</h2><p>上述完成之后，就可以启动Qemu来调试内核了,启动代码如下（是一个指令）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -kernel ./arch/x86/boot/bzImage -initrd ../initramfs.cpio.gz -append <span class="string">&quot;nokaslr console=ttyS0&quot;</span> -s -S -nographic</span><br></pre></td></tr></table></figure><ul><li><code>qemu-system-x86_64</code>：指定是x86，64位;</li><li><code>-kernel ./arch/x86/boot/bzImage</code>：指定启用的内核镜像；</li><li><code>-initrd ../initramfs.cpio.gz</code>：指定启动的内存文件系统</li><li><code>-append &quot;nokaslr console=ttyS0&quot;</code> ：附加参数，其中 <code>nokaslr</code> 参数<strong>必须添加进来</strong>，防止内核起始地址随机化，这样会导致 gdb 断点不能命中；</li><li><code>-s</code> ：监听在 gdb 1234 端口；</li><li><code>-S</code> ：表示启动后就挂起，等待 gdb 连接；</li><li><code>-nographic</code>：不启动图形界面</li></ul><p>开启另一个命令行窗口，输入<strong>gdb</strong>，即可开启调试</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(gdb) target remote localhost:1234  <span class="comment">#连接qemu监听的端口</span></span><br><span class="line">(gdb) <span class="built_in">break</span> start_kernel      <span class="comment">#在start_kernel打断点</span></span><br><span class="line">(gdb) <span class="built_in">break</span>  rest_init        <span class="comment">#在res_init打断点</span></span><br><span class="line">(gdb) c                       <span class="comment">#运行到断点处</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux内核 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Butterfly中取消头像转动</title>
      <link href="/2023/11/18/hexo1/"/>
      <url>/2023/11/18/hexo1/</url>
      
        <content type="html"><![CDATA[<h2 id="Hexo-Butterfly中鼠标放到头像上头像会转动，如何取消转动"><a href="#Hexo-Butterfly中鼠标放到头像上头像会转动，如何取消转动" class="headerlink" title="Hexo+Butterfly中鼠标放到头像上头像会转动，如何取消转动"></a>Hexo+Butterfly中鼠标放到头像上头像会转动，如何取消转动</h2><p>这个在_config中改不了，经过查阅资料，发现在 hexo-theme-butterfly&#x2F;source&#x2F;css&#x2F;_layout&#x2F;aside.styl中进行更改,大约在324行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img</span><br><span class="line">  width: 100%</span><br><span class="line">  height: 100%</span><br><span class="line">  transition: filter 375ms ease-in .2s, transform .3s</span><br><span class="line">  object-fit: cover</span><br><span class="line"></span><br><span class="line">  &amp;:hover</span><br><span class="line">    transform: rotate(360deg)</span><br></pre></td></tr></table></figure><p>将后两行删掉</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img</span><br><span class="line">  width: 100%</span><br><span class="line">  height: 100%</span><br><span class="line">  transition: filter 375ms ease-in .2s, transform .3s</span><br><span class="line">  object-fit: cover</span><br></pre></td></tr></table></figure><p>这样头像就不会转动了</p><p>参考链接: <a href="https://github.com/jerryc127/hexo-theme-butterfly/discussions/878">https://github.com/jerryc127/hexo-theme-butterfly/discussions/878</a></p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 更改配置 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
